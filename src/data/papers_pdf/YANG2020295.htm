<!doctype html>
<!--[if IE 9]><html class="ie9" lang={defaultLocale}><![endif]-->
<html lang="en-US" class="Preview">
<head>
<meta name="citation_pii" content="S0925231220311693" />
<meta name="citation_issn" content="0925-2312" />
<meta name="citation_volume" content="415" />
<meta name="citation_lastpage" content="316" />
<meta name="citation_publisher" content="Elsevier" />
<meta name="citation_firstpage" content="295" />
<meta name="citation_journal_title" content="Neurocomputing" />
<meta name="citation_type" content="JOUR" />
<meta name="citation_doi" content="10.1016/j.neucom.2020.07.061" />
<meta name="dc.identifier" content="10.1016/j.neucom.2020.07.061" />
<meta name="citation_article_type" content="Full-length article" />
<meta property="og:description" content="Machine learning algorithms have been used widely in various applications and areas. To fit a machine learning model into different problems, its hypeâ€¦" />
<meta property="og:image" content="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220X00385-cov150h.gif" />
<meta name="citation_title" content="On hyperparameter optimization of machine learning algorithms: Theory and practice" />
<meta property="og:title" content="On hyperparameter optimization of machine learning algorithms: Theory and practice" />
<meta name="citation_publication_date" content="2020/11/20" />
<meta name="citation_online_date" content="2020/07/25" />
<meta name="robots" content="INDEX,FOLLOW,NOARCHIVE,NOCACHE,NOODP,NOYDIR" />
<title>On hyperparameter optimization of machine learning algorithms: Theory and practice - ScienceDirect</title>
<link rel="canonical" href="https://www.sciencedirect.com/science/article/abs/pii/S0925231220311693" />
<meta property="og:type" content="article" />
<meta name="viewport" content="initial-scale=1" />
<meta name="SDTech" content="Proudly brought to you by the SD Technology team in London, Dayton, and Amsterdam" />
<script type="47a3bd3f3a53d05185487be5-text/javascript">(function newRelicBrowserProSPA() {
  ;
  window.NREUM || (NREUM = {});
  NREUM.init = {
    privacy: {
      cookies_enabled: true
    },
    ajax: {
      deny_list: ["bam-cell.nr-data.net"]
    }
  };
  ;
  NREUM.loader_config = {
    accountID: "2128461",
    trustKey: "2038175",
    agentID: "1118783207",
    licenseKey: "7ac4127487",
    applicationID: "814813181"
  };
  ;
  NREUM.info = {
    beacon: "bam.nr-data.net",
    errorBeacon: "bam.nr-data.net",
    licenseKey: "7ac4127487",
    applicationID: "814813181",
    sa: 1
  };
  ; /*! For license information please see nr-loader-spa-1.238.0.min.js.LICENSE.txt */
  (() => {
    "use strict";

    var e,
      t,
      r = {
        5763: (e, t, r) => {
          r.d(t, {
            P_: () => f,
            Mt: () => p,
            C5: () => s,
            DL: () => v,
            OP: () => T,
            lF: () => D,
            Yu: () => y,
            Dg: () => h,
            CX: () => c,
            GE: () => b,
            sU: () => _
          });
          var n = r(8632),
            i = r(9567);
          const o = {
              beacon: n.ce.beacon,
              errorBeacon: n.ce.errorBeacon,
              licenseKey: void 0,
              applicationID: void 0,
              sa: void 0,
              queueTime: void 0,
              applicationTime: void 0,
              ttGuid: void 0,
              user: void 0,
              account: void 0,
              product: void 0,
              extra: void 0,
              jsAttributes: {},
              userAttributes: void 0,
              atts: void 0,
              transactionName: void 0,
              tNamePlain: void 0
            },
            a = {};
          function s(e) {
            if (!e) throw new Error("All info objects require an agent identifier!");
            if (!a[e]) throw new Error("Info for ".concat(e, " was never set"));
            return a[e];
          }
          function c(e, t) {
            if (!e) throw new Error("All info objects require an agent identifier!");
            a[e] = (0, i.D)(t, o), (0, n.Qy)(e, a[e], "info");
          }
          var u = r(7056);
          const d = () => {
              const e = {
                blockSelector: "[data-nr-block]",
                maskInputOptions: {
                  password: !0
                }
              };
              return {
                allow_bfcache: !0,
                privacy: {
                  cookies_enabled: !0
                },
                ajax: {
                  deny_list: void 0,
                  block_internal: !0,
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                distributed_tracing: {
                  enabled: void 0,
                  exclude_newrelic_header: void 0,
                  cors_use_newrelic_header: void 0,
                  cors_use_tracecontext_headers: void 0,
                  allowed_origins: void 0
                },
                session: {
                  domain: void 0,
                  expiresMs: u.oD,
                  inactiveMs: u.Hb
                },
                ssl: void 0,
                obfuscate: void 0,
                jserrors: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                metrics: {
                  enabled: !0
                },
                page_action: {
                  enabled: !0,
                  harvestTimeSeconds: 30
                },
                page_view_event: {
                  enabled: !0
                },
                page_view_timing: {
                  enabled: !0,
                  harvestTimeSeconds: 30,
                  long_task: !1
                },
                session_trace: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                },
                harvest: {
                  tooManyRequestsDelay: 60
                },
                session_replay: {
                  enabled: !1,
                  harvestTimeSeconds: 60,
                  sampleRate: .1,
                  errorSampleRate: .1,
                  maskTextSelector: "*",
                  maskAllInputs: !0,
                  get blockClass() {
                    return "nr-block";
                  },
                  get ignoreClass() {
                    return "nr-ignore";
                  },
                  get maskTextClass() {
                    return "nr-mask";
                  },
                  get blockSelector() {
                    return e.blockSelector;
                  },
                  set blockSelector(t) {
                    e.blockSelector += ",".concat(t);
                  },
                  get maskInputOptions() {
                    return e.maskInputOptions;
                  },
                  set maskInputOptions(t) {
                    e.maskInputOptions = {
                      ...t,
                      password: !0
                    };
                  }
                },
                spa: {
                  enabled: !0,
                  harvestTimeSeconds: 10
                }
              };
            },
            l = {};
          function f(e) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            if (!l[e]) throw new Error("Configuration for ".concat(e, " was never set"));
            return l[e];
          }
          function h(e, t) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            l[e] = (0, i.D)(t, d()), (0, n.Qy)(e, l[e], "config");
          }
          function p(e, t) {
            if (!e) throw new Error("All configuration objects require an agent identifier!");
            var r = f(e);
            if (r) {
              for (var n = t.split("."), i = 0; i < n.length - 1; i++) if ("object" != typeof (r = r[n[i]])) return;
              r = r[n[n.length - 1]];
            }
            return r;
          }
          const g = {
              accountID: void 0,
              trustKey: void 0,
              agentID: void 0,
              licenseKey: void 0,
              applicationID: void 0,
              xpid: void 0
            },
            m = {};
          function v(e) {
            if (!e) throw new Error("All loader-config objects require an agent identifier!");
            if (!m[e]) throw new Error("LoaderConfig for ".concat(e, " was never set"));
            return m[e];
          }
          function b(e, t) {
            if (!e) throw new Error("All loader-config objects require an agent identifier!");
            m[e] = (0, i.D)(t, g), (0, n.Qy)(e, m[e], "loader_config");
          }
          const y = (0, n.mF)().o;
          var w = r(385),
            A = r(6818);
          const x = {
              buildEnv: A.Re,
              bytesSent: {},
              queryBytesSent: {},
              customTransaction: void 0,
              disabled: !1,
              distMethod: A.gF,
              isolatedBacklog: !1,
              loaderType: void 0,
              maxBytes: 3e4,
              offset: Math.floor(w._A?.performance?.timeOrigin || w._A?.performance?.timing?.navigationStart || Date.now()),
              onerror: void 0,
              origin: "" + w._A.location,
              ptid: void 0,
              releaseIds: {},
              session: void 0,
              xhrWrappable: "function" == typeof w._A.XMLHttpRequest?.prototype?.addEventListener,
              version: A.q4,
              denyList: void 0
            },
            E = {};
          function T(e) {
            if (!e) throw new Error("All runtime objects require an agent identifier!");
            if (!E[e]) throw new Error("Runtime for ".concat(e, " was never set"));
            return E[e];
          }
          function _(e, t) {
            if (!e) throw new Error("All runtime objects require an agent identifier!");
            E[e] = (0, i.D)(t, x), (0, n.Qy)(e, E[e], "runtime");
          }
          function D(e) {
            return function (e) {
              try {
                const t = s(e);
                return !!t.licenseKey && !!t.errorBeacon && !!t.applicationID;
              } catch (e) {
                return !1;
              }
            }(e);
          }
        },
        9567: (e, t, r) => {
          r.d(t, {
            D: () => i
          });
          var n = r(50);
          function i(e, t) {
            try {
              if (!e || "object" != typeof e) return (0, n.Z)("Setting a Configurable requires an object as input");
              if (!t || "object" != typeof t) return (0, n.Z)("Setting a Configurable requires a model to set its initial properties");
              const r = Object.create(Object.getPrototypeOf(t), Object.getOwnPropertyDescriptors(t)),
                o = 0 === Object.keys(r).length ? e : r;
              for (let a in o) if (void 0 !== e[a]) try {
                "object" == typeof e[a] && "object" == typeof t[a] ? r[a] = i(e[a], t[a]) : r[a] = e[a];
              } catch (e) {
                (0, n.Z)("An error occurred while setting a property of a Configurable", e);
              }
              return r;
            } catch (e) {
              (0, n.Z)("An error occured while setting a Configurable", e);
            }
          }
        },
        6818: (e, t, r) => {
          r.d(t, {
            Re: () => i,
            gF: () => o,
            q4: () => n
          });
          const n = "1.238.0",
            i = "PROD",
            o = "CDN";
        },
        385: (e, t, r) => {
          r.d(t, {
            FN: () => a,
            IF: () => u,
            Nk: () => l,
            Tt: () => s,
            _A: () => o,
            il: () => n,
            pL: () => c,
            v6: () => i,
            w1: () => d
          });
          const n = "undefined" != typeof window && !!window.document,
            i = "undefined" != typeof WorkerGlobalScope && ("undefined" != typeof self && self instanceof WorkerGlobalScope && self.navigator instanceof WorkerNavigator || "undefined" != typeof globalThis && globalThis instanceof WorkerGlobalScope && globalThis.navigator instanceof WorkerNavigator),
            o = n ? window : "undefined" != typeof WorkerGlobalScope && ("undefined" != typeof self && self instanceof WorkerGlobalScope && self || "undefined" != typeof globalThis && globalThis instanceof WorkerGlobalScope && globalThis),
            a = "" + o?.location,
            s = /iPad|iPhone|iPod/.test(navigator.userAgent),
            c = s && "undefined" == typeof SharedWorker,
            u = (() => {
              const e = navigator.userAgent.match(/Firefox[/\s](\d+\.\d+)/);
              return Array.isArray(e) && e.length >= 2 ? +e[1] : 0;
            })(),
            d = Boolean(n && window.document.documentMode),
            l = !!navigator.sendBeacon;
        },
        1117: (e, t, r) => {
          r.d(t, {
            w: () => o
          });
          var n = r(50);
          const i = {
            agentIdentifier: "",
            ee: void 0
          };
          class o {
            constructor(e) {
              try {
                if ("object" != typeof e) return (0, n.Z)("shared context requires an object as input");
                this.sharedContext = {}, Object.assign(this.sharedContext, i), Object.entries(e).forEach(e => {
                  let [t, r] = e;
                  Object.keys(i).includes(t) && (this.sharedContext[t] = r);
                });
              } catch (e) {
                (0, n.Z)("An error occured while setting SharedContext", e);
              }
            }
          }
        },
        8e3: (e, t, r) => {
          r.d(t, {
            L: () => d,
            R: () => c
          });
          var n = r(8325),
            i = r(1284),
            o = r(4322),
            a = r(3325);
          const s = {};
          function c(e, t) {
            const r = {
              staged: !1,
              priority: a.p[t] || 0
            };
            u(e), s[e].get(t) || s[e].set(t, r);
          }
          function u(e) {
            e && (s[e] || (s[e] = new Map()));
          }
          function d() {
            let e = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : "",
              t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : "feature";
            if (u(e), !e || !s[e].get(t)) return a(t);
            s[e].get(t).staged = !0;
            const r = [...s[e]];
            function a(t) {
              const r = e ? n.ee.get(e) : n.ee,
                a = o.X.handlers;
              if (r.backlog && a) {
                var s = r.backlog[t],
                  c = a[t];
                if (c) {
                  for (var u = 0; s && u < s.length; ++u) l(s[u], c);
                  (0, i.D)(c, function (e, t) {
                    (0, i.D)(t, function (t, r) {
                      r[0].on(e, r[1]);
                    });
                  });
                }
                delete a[t], r.backlog[t] = null, r.emit("drain-" + t, []);
              }
            }
            r.every(e => {
              let [t, r] = e;
              return r.staged;
            }) && (r.sort((e, t) => e[1].priority - t[1].priority), r.forEach(e => {
              let [t] = e;
              a(t);
            }));
          }
          function l(e, t) {
            var r = e[1];
            (0, i.D)(t[r], function (t, r) {
              var n = e[0];
              if (r[0] === n) {
                var i = r[1],
                  o = e[3],
                  a = e[2];
                i.apply(o, a);
              }
            });
          }
        },
        8325: (e, t, r) => {
          r.d(t, {
            A: () => c,
            ee: () => u
          });
          var n = r(8632),
            i = r(2210),
            o = r(5763);
          class a {
            constructor(e) {
              this.contextId = e;
            }
          }
          var s = r(3117);
          const c = "nr@context:".concat(s.a),
            u = function e(t, r) {
              var n = {},
                s = {},
                d = {},
                f = !1;
              try {
                f = 16 === r.length && (0, o.OP)(r).isolatedBacklog;
              } catch (e) {}
              var h = {
                on: g,
                addEventListener: g,
                removeEventListener: function (e, t) {
                  var r = n[e];
                  if (!r) return;
                  for (var i = 0; i < r.length; i++) r[i] === t && r.splice(i, 1);
                },
                emit: function (e, r, n, i, o) {
                  !1 !== o && (o = !0);
                  if (u.aborted && !i) return;
                  t && o && t.emit(e, r, n);
                  for (var a = p(n), c = m(e), d = c.length, l = 0; l < d; l++) c[l].apply(a, r);
                  var f = b()[s[e]];
                  f && f.push([h, e, r, a]);
                  return a;
                },
                get: v,
                listeners: m,
                context: p,
                buffer: function (e, t) {
                  const r = b();
                  if (t = t || "feature", h.aborted) return;
                  Object.entries(e || {}).forEach(e => {
                    let [n, i] = e;
                    s[i] = t, t in r || (r[t] = []);
                  });
                },
                abort: l,
                aborted: !1,
                isBuffering: function (e) {
                  return !!b()[s[e]];
                },
                debugId: r,
                backlog: f ? {} : t && "object" == typeof t.backlog ? t.backlog : {}
              };
              return h;
              function p(e) {
                return e && e instanceof a ? e : e ? (0, i.X)(e, c, () => new a(c)) : new a(c);
              }
              function g(e, t) {
                n[e] = m(e).concat(t);
              }
              function m(e) {
                return n[e] || [];
              }
              function v(t) {
                return d[t] = d[t] || e(h, t);
              }
              function b() {
                return h.backlog;
              }
            }(void 0, "globalEE"),
            d = (0, n.fP)();
          function l() {
            u.aborted = !0, u.backlog = {};
          }
          d.ee || (d.ee = u);
        },
        5546: (e, t, r) => {
          r.d(t, {
            E: () => n,
            p: () => i
          });
          var n = r(8325).ee.get("handle");
          function i(e, t, r, i, o) {
            o ? (o.buffer([e], i), o.emit(e, t, r)) : (n.buffer([e], i), n.emit(e, t, r));
          }
        },
        4322: (e, t, r) => {
          r.d(t, {
            X: () => o
          });
          var n = r(5546);
          o.on = a;
          var i = o.handlers = {};
          function o(e, t, r, o) {
            a(o || n.E, i, e, t, r);
          }
          function a(e, t, r, i, o) {
            o || (o = "feature"), e || (e = n.E);
            var a = t[o] = t[o] || {};
            (a[r] = a[r] || []).push([e, i]);
          }
        },
        3239: (e, t, r) => {
          r.d(t, {
            bP: () => s,
            iz: () => c,
            m$: () => a
          });
          var n = r(385);
          let i = !1,
            o = !1;
          try {
            const e = {
              get passive() {
                return i = !0, !1;
              },
              get signal() {
                return o = !0, !1;
              }
            };
            n._A.addEventListener("test", null, e), n._A.removeEventListener("test", null, e);
          } catch (e) {}
          function a(e, t) {
            return i || o ? {
              capture: !!e,
              passive: i,
              signal: t
            } : !!e;
          }
          function s(e, t) {
            let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2],
              n = arguments.length > 3 ? arguments[3] : void 0;
            window.addEventListener(e, t, a(r, n));
          }
          function c(e, t) {
            let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2],
              n = arguments.length > 3 ? arguments[3] : void 0;
            document.addEventListener(e, t, a(r, n));
          }
        },
        3117: (e, t, r) => {
          r.d(t, {
            a: () => n
          });
          const n = (0, r(4402).Rl)();
        },
        4402: (e, t, r) => {
          r.d(t, {
            Ht: () => u,
            M: () => c,
            Rl: () => a,
            ky: () => s
          });
          var n = r(385);
          const i = "xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx";
          function o(e, t) {
            return e ? 15 & e[t] : 16 * Math.random() | 0;
          }
          function a() {
            const e = n._A?.crypto || n._A?.msCrypto;
            let t,
              r = 0;
            return e && e.getRandomValues && (t = e.getRandomValues(new Uint8Array(31))), i.split("").map(e => "x" === e ? o(t, ++r).toString(16) : "y" === e ? (3 & o() | 8).toString(16) : e).join("");
          }
          function s(e) {
            const t = n._A?.crypto || n._A?.msCrypto;
            let r,
              i = 0;
            t && t.getRandomValues && (r = t.getRandomValues(new Uint8Array(31)));
            const a = [];
            for (var s = 0; s < e; s++) a.push(o(r, ++i).toString(16));
            return a.join("");
          }
          function c() {
            return s(16);
          }
          function u() {
            return s(32);
          }
        },
        7056: (e, t, r) => {
          r.d(t, {
            Bq: () => n,
            Hb: () => o,
            oD: () => i
          });
          const n = "NRBA",
            i = 144e5,
            o = 18e5;
        },
        7894: (e, t, r) => {
          function n() {
            return Math.round(performance.now());
          }
          r.d(t, {
            z: () => n
          });
        },
        7243: (e, t, r) => {
          r.d(t, {
            e: () => o
          });
          var n = r(385),
            i = {};
          function o(e) {
            if (e in i) return i[e];
            if (0 === (e || "").indexOf("data:")) return {
              protocol: "data"
            };
            let t;
            var r = n._A?.location,
              o = {};
            if (n.il) t = document.createElement("a"), t.href = e;else try {
              t = new URL(e, r.href);
            } catch (e) {
              return o;
            }
            o.port = t.port;
            var a = t.href.split("://");
            !o.port && a[1] && (o.port = a[1].split("/")[0].split("@").pop().split(":")[1]), o.port && "0" !== o.port || (o.port = "https" === a[0] ? "443" : "80"), o.hostname = t.hostname || r.hostname, o.pathname = t.pathname, o.protocol = a[0], "/" !== o.pathname.charAt(0) && (o.pathname = "/" + o.pathname);
            var s = !t.protocol || ":" === t.protocol || t.protocol === r.protocol,
              c = t.hostname === r.hostname && t.port === r.port;
            return o.sameOrigin = s && (!t.hostname || c), "/" === o.pathname && (i[e] = o), o;
          }
        },
        50: (e, t, r) => {
          function n(e, t) {
            "function" == typeof console.warn && (console.warn("New Relic: ".concat(e)), t && console.warn(t));
          }
          r.d(t, {
            Z: () => n
          });
        },
        2587: (e, t, r) => {
          r.d(t, {
            N: () => c,
            T: () => u
          });
          var n = r(8325),
            i = r(5546),
            o = r(8e3),
            a = r(3325);
          const s = {
            stn: [a.D.sessionTrace],
            err: [a.D.jserrors, a.D.metrics],
            ins: [a.D.pageAction],
            spa: [a.D.spa],
            sr: [a.D.sessionReplay, a.D.sessionTrace]
          };
          function c(e, t) {
            const r = n.ee.get(t);
            e && "object" == typeof e && (Object.entries(e).forEach(e => {
              let [t, n] = e;
              void 0 === u[t] && (s[t] ? s[t].forEach(e => {
                n ? (0, i.p)("feat-" + t, [], void 0, e, r) : (0, i.p)("block-" + t, [], void 0, e, r), (0, i.p)("rumresp-" + t, [Boolean(n)], void 0, e, r);
              }) : n && (0, i.p)("feat-" + t, [], void 0, void 0, r), u[t] = Boolean(n));
            }), Object.keys(s).forEach(e => {
              void 0 === u[e] && (s[e]?.forEach(t => (0, i.p)("rumresp-" + e, [!1], void 0, t, r)), u[e] = !1);
            }), (0, o.L)(t, a.D.pageViewEvent));
          }
          const u = {};
        },
        2210: (e, t, r) => {
          r.d(t, {
            X: () => i
          });
          var n = Object.prototype.hasOwnProperty;
          function i(e, t, r) {
            if (n.call(e, t)) return e[t];
            var i = r();
            if (Object.defineProperty && Object.keys) try {
              return Object.defineProperty(e, t, {
                value: i,
                writable: !0,
                enumerable: !1
              }), i;
            } catch (e) {}
            return e[t] = i, i;
          }
        },
        1284: (e, t, r) => {
          r.d(t, {
            D: () => n
          });
          const n = (e, t) => Object.entries(e || {}).map(e => {
            let [r, n] = e;
            return t(r, n);
          });
        },
        4351: (e, t, r) => {
          r.d(t, {
            P: () => o
          });
          var n = r(8325);
          const i = () => {
            const e = new WeakSet();
            return (t, r) => {
              if ("object" == typeof r && null !== r) {
                if (e.has(r)) return;
                e.add(r);
              }
              return r;
            };
          };
          function o(e) {
            try {
              return JSON.stringify(e, i());
            } catch (e) {
              try {
                n.ee.emit("internal-error", [e]);
              } catch (e) {}
            }
          }
        },
        3960: (e, t, r) => {
          r.d(t, {
            K: () => a,
            b: () => o
          });
          var n = r(3239);
          function i() {
            return "undefined" == typeof document || "complete" === document.readyState;
          }
          function o(e, t) {
            if (i()) return e();
            (0, n.bP)("load", e, t);
          }
          function a(e) {
            if (i()) return e();
            (0, n.iz)("DOMContentLoaded", e);
          }
        },
        8632: (e, t, r) => {
          r.d(t, {
            EZ: () => u,
            Qy: () => c,
            ce: () => o,
            fP: () => a,
            gG: () => d,
            mF: () => s
          });
          var n = r(7894),
            i = r(385);
          const o = {
            beacon: "bam.nr-data.net",
            errorBeacon: "bam.nr-data.net"
          };
          function a() {
            return i._A.NREUM || (i._A.NREUM = {}), void 0 === i._A.newrelic && (i._A.newrelic = i._A.NREUM), i._A.NREUM;
          }
          function s() {
            let e = a();
            return e.o || (e.o = {
              ST: i._A.setTimeout,
              SI: i._A.setImmediate,
              CT: i._A.clearTimeout,
              XHR: i._A.XMLHttpRequest,
              REQ: i._A.Request,
              EV: i._A.Event,
              PR: i._A.Promise,
              MO: i._A.MutationObserver,
              FETCH: i._A.fetch
            }), e;
          }
          function c(e, t, r) {
            let i = a();
            const o = i.initializedAgents || {},
              s = o[e] || {};
            return Object.keys(s).length || (s.initializedAt = {
              ms: (0, n.z)(),
              date: new Date()
            }), i.initializedAgents = {
              ...o,
              [e]: {
                ...s,
                [r]: t
              }
            }, i;
          }
          function u(e, t) {
            a()[e] = t;
          }
          function d() {
            return function () {
              let e = a();
              const t = e.info || {};
              e.info = {
                beacon: o.beacon,
                errorBeacon: o.errorBeacon,
                ...t
              };
            }(), function () {
              let e = a();
              const t = e.init || {};
              e.init = {
                ...t
              };
            }(), s(), function () {
              let e = a();
              const t = e.loader_config || {};
              e.loader_config = {
                ...t
              };
            }(), a();
          }
        },
        7956: (e, t, r) => {
          r.d(t, {
            N: () => i
          });
          var n = r(3239);
          function i(e) {
            let t = arguments.length > 1 && void 0 !== arguments[1] && arguments[1],
              r = arguments.length > 2 ? arguments[2] : void 0,
              i = arguments.length > 3 ? arguments[3] : void 0;
            return void (0, n.iz)("visibilitychange", function () {
              if (t) return void ("hidden" == document.visibilityState && e());
              e(document.visibilityState);
            }, r, i);
          }
        },
        1214: (e, t, r) => {
          r.d(t, {
            em: () => b,
            u5: () => j,
            QU: () => O,
            _L: () => I,
            Gm: () => H,
            Lg: () => L,
            BV: () => G,
            Kf: () => K
          });
          var n = r(8325),
            i = r(3117);
          const o = "nr@original:".concat(i.a);
          var a = Object.prototype.hasOwnProperty,
            s = !1;
          function c(e, t) {
            return e || (e = n.ee), r.inPlace = function (e, t, n, i, o) {
              n || (n = "");
              const a = "-" === n.charAt(0);
              for (let s = 0; s < t.length; s++) {
                const c = t[s],
                  u = e[c];
                d(u) || (e[c] = r(u, a ? c + n : n, i, c, o));
              }
            }, r.flag = o, r;
            function r(t, r, n, s, c) {
              return d(t) ? t : (r || (r = ""), nrWrapper[o] = t, function (e, t, r) {
                if (Object.defineProperty && Object.keys) try {
                  return Object.keys(e).forEach(function (r) {
                    Object.defineProperty(t, r, {
                      get: function () {
                        return e[r];
                      },
                      set: function (t) {
                        return e[r] = t, t;
                      }
                    });
                  }), t;
                } catch (e) {
                  u([e], r);
                }
                for (var n in e) a.call(e, n) && (t[n] = e[n]);
              }(t, nrWrapper, e), nrWrapper);
              function nrWrapper() {
                var o, a, d, l;
                try {
                  a = this, o = [...arguments], d = "function" == typeof n ? n(o, a) : n || {};
                } catch (t) {
                  u([t, "", [o, a, s], d], e);
                }
                i(r + "start", [o, a, s], d, c);
                try {
                  return l = t.apply(a, o);
                } catch (e) {
                  throw i(r + "err", [o, a, e], d, c), e;
                } finally {
                  i(r + "end", [o, a, l], d, c);
                }
              }
            }
            function i(r, n, i, o) {
              if (!s || t) {
                var a = s;
                s = !0;
                try {
                  e.emit(r, n, i, t, o);
                } catch (t) {
                  u([t, r, n, i], e);
                }
                s = a;
              }
            }
          }
          function u(e, t) {
            t || (t = n.ee);
            try {
              t.emit("internal-error", e);
            } catch (e) {}
          }
          function d(e) {
            return !(e && e instanceof Function && e.apply && !e[o]);
          }
          var l = r(2210),
            f = r(385);
          const h = {},
            p = f._A.XMLHttpRequest,
            g = "addEventListener",
            m = "removeEventListener",
            v = "nr@wrapped:".concat(n.A);
          function b(e) {
            var t = function (e) {
              return (e || n.ee).get("events");
            }(e);
            if (h[t.debugId]++) return t;
            h[t.debugId] = 1;
            var r = c(t, !0);
            function i(e) {
              r.inPlace(e, [g, m], "-", o);
            }
            function o(e, t) {
              return e[1];
            }
            return "getPrototypeOf" in Object && (f.il && y(document, i), y(f._A, i), y(p.prototype, i)), t.on(g + "-start", function (e, t) {
              var n = e[1];
              if (null !== n && ("function" == typeof n || "object" == typeof n)) {
                var i = (0, l.X)(n, v, function () {
                  var e = {
                    object: function () {
                      if ("function" != typeof n.handleEvent) return;
                      return n.handleEvent.apply(n, arguments);
                    },
                    function: n
                  }[typeof n];
                  return e ? r(e, "fn-", null, e.name || "anonymous") : n;
                });
                this.wrapped = e[1] = i;
              }
            }), t.on(m + "-start", function (e) {
              e[1] = this.wrapped || e[1];
            }), t;
          }
          function y(e, t) {
            let r = e;
            for (; "object" == typeof r && !Object.prototype.hasOwnProperty.call(r, g);) r = Object.getPrototypeOf(r);
            for (var n = arguments.length, i = new Array(n > 2 ? n - 2 : 0), o = 2; o < n; o++) i[o - 2] = arguments[o];
            r && t(r, ...i);
          }
          var w = "fetch-",
            A = w + "body-",
            x = ["arrayBuffer", "blob", "json", "text", "formData"],
            E = f._A.Request,
            T = f._A.Response,
            _ = "prototype";
          const D = {};
          function j(e) {
            const t = function (e) {
              return (e || n.ee).get("fetch");
            }(e);
            if (!(E && T && f._A.fetch)) return t;
            if (D[t.debugId]++) return t;
            function r(e, r, i) {
              var o = e[r];
              "function" == typeof o && (e[r] = function () {
                var e,
                  r = [...arguments],
                  a = {};
                t.emit(i + "before-start", [r], a), a[n.A] && a[n.A].dt && (e = a[n.A].dt);
                var s = o.apply(this, r);
                return t.emit(i + "start", [r, e], s), s.then(function (e) {
                  return t.emit(i + "end", [null, e], s), e;
                }, function (e) {
                  throw t.emit(i + "end", [e], s), e;
                });
              });
            }
            return D[t.debugId] = 1, x.forEach(e => {
              r(E[_], e, A), r(T[_], e, A);
            }), r(f._A, "fetch", w), t.on(w + "end", function (e, r) {
              var n = this;
              if (r) {
                var i = r.headers.get("content-length");
                null !== i && (n.rxSize = i), t.emit(w + "done", [null, r], n);
              } else t.emit(w + "done", [e], n);
            }), t;
          }
          const C = {},
            N = ["pushState", "replaceState"];
          function O(e) {
            const t = function (e) {
              return (e || n.ee).get("history");
            }(e);
            return !f.il || C[t.debugId]++ || (C[t.debugId] = 1, c(t).inPlace(window.history, N, "-")), t;
          }
          var S = r(3239);
          const P = {},
            R = ["appendChild", "insertBefore", "replaceChild"];
          function I(e) {
            const t = function (e) {
              return (e || n.ee).get("jsonp");
            }(e);
            if (!f.il || P[t.debugId]) return t;
            P[t.debugId] = !0;
            var r = c(t),
              i = /[?&](?:callback|cb)=([^&#]+)/,
              o = /(.*)\.([^.]+)/,
              a = /^(\w+)(\.|$)(.*)$/;
            function s(e, t) {
              if (!e) return t;
              const r = e.match(a),
                n = r[1];
              return s(r[3], t[n]);
            }
            return r.inPlace(Node.prototype, R, "dom-"), t.on("dom-start", function (e) {
              !function (e) {
                if (!e || "string" != typeof e.nodeName || "script" !== e.nodeName.toLowerCase()) return;
                if ("function" != typeof e.addEventListener) return;
                var n = (a = e.src, c = a.match(i), c ? c[1] : null);
                var a, c;
                if (!n) return;
                var u = function (e) {
                  var t = e.match(o);
                  if (t && t.length >= 3) return {
                    key: t[2],
                    parent: s(t[1], window)
                  };
                  return {
                    key: e,
                    parent: window
                  };
                }(n);
                if ("function" != typeof u.parent[u.key]) return;
                var d = {};
                function l() {
                  t.emit("jsonp-end", [], d), e.removeEventListener("load", l, (0, S.m$)(!1)), e.removeEventListener("error", f, (0, S.m$)(!1));
                }
                function f() {
                  t.emit("jsonp-error", [], d), t.emit("jsonp-end", [], d), e.removeEventListener("load", l, (0, S.m$)(!1)), e.removeEventListener("error", f, (0, S.m$)(!1));
                }
                r.inPlace(u.parent, [u.key], "cb-", d), e.addEventListener("load", l, (0, S.m$)(!1)), e.addEventListener("error", f, (0, S.m$)(!1)), t.emit("new-jsonp", [e.src], d);
              }(e[0]);
            }), t;
          }
          const k = {};
          function H(e) {
            const t = function (e) {
              return (e || n.ee).get("mutation");
            }(e);
            if (!f.il || k[t.debugId]) return t;
            k[t.debugId] = !0;
            var r = c(t),
              i = f._A.MutationObserver;
            return i && (window.MutationObserver = function (e) {
              return this instanceof i ? new i(r(e, "fn-")) : i.apply(this, arguments);
            }, MutationObserver.prototype = i.prototype), t;
          }
          const z = {};
          function L(e) {
            const t = function (e) {
              return (e || n.ee).get("promise");
            }(e);
            if (z[t.debugId]) return t;
            z[t.debugId] = !0;
            var r = t.context,
              i = c(t),
              a = f._A.Promise;
            return a && function () {
              function e(r) {
                var n = t.context(),
                  o = i(r, "executor-", n, null, !1);
                const s = Reflect.construct(a, [o], e);
                return t.context(s).getCtx = function () {
                  return n;
                }, s;
              }
              f._A.Promise = e, Object.defineProperty(e, "name", {
                value: "Promise"
              }), e.toString = function () {
                return a.toString();
              }, Object.setPrototypeOf(e, a), ["all", "race"].forEach(function (r) {
                const n = a[r];
                e[r] = function (e) {
                  let i = !1;
                  [...(e || [])].forEach(e => {
                    this.resolve(e).then(a("all" === r), a(!1));
                  });
                  const o = n.apply(this, arguments);
                  return o;
                  function a(e) {
                    return function () {
                      t.emit("propagate", [null, !i], o, !1, !1), i = i || !e;
                    };
                  }
                };
              }), ["resolve", "reject"].forEach(function (r) {
                const n = a[r];
                e[r] = function (e) {
                  const r = n.apply(this, arguments);
                  return e !== r && t.emit("propagate", [e, !0], r, !1, !1), r;
                };
              }), e.prototype = a.prototype;
              const n = a.prototype.then;
              a.prototype.then = function () {
                var e = this,
                  o = r(e);
                o.promise = e;
                for (var a = arguments.length, s = new Array(a), c = 0; c < a; c++) s[c] = arguments[c];
                s[0] = i(s[0], "cb-", o, null, !1), s[1] = i(s[1], "cb-", o, null, !1);
                const u = n.apply(this, s);
                return o.nextPromise = u, t.emit("propagate", [e, !0], u, !1, !1), u;
              }, a.prototype.then[o] = n, t.on("executor-start", function (e) {
                e[0] = i(e[0], "resolve-", this, null, !1), e[1] = i(e[1], "resolve-", this, null, !1);
              }), t.on("executor-err", function (e, t, r) {
                e[1](r);
              }), t.on("cb-end", function (e, r, n) {
                t.emit("propagate", [n, !0], this.nextPromise, !1, !1);
              }), t.on("propagate", function (e, r, n) {
                this.getCtx && !r || (this.getCtx = function () {
                  if (e instanceof Promise) var r = t.context(e);
                  return r && r.getCtx ? r.getCtx() : this;
                });
              });
            }(), t;
          }
          const M = {},
            B = "setTimeout",
            F = "setInterval",
            U = "clearTimeout",
            q = "-start",
            Z = "-",
            V = [B, "setImmediate", F, U, "clearImmediate"];
          function G(e) {
            const t = function (e) {
              return (e || n.ee).get("timer");
            }(e);
            if (M[t.debugId]++) return t;
            M[t.debugId] = 1;
            var r = c(t);
            return r.inPlace(f._A, V.slice(0, 2), B + Z), r.inPlace(f._A, V.slice(2, 3), F + Z), r.inPlace(f._A, V.slice(3), U + Z), t.on(F + q, function (e, t, n) {
              e[0] = r(e[0], "fn-", null, n);
            }), t.on(B + q, function (e, t, n) {
              this.method = n, this.timerDuration = isNaN(e[1]) ? 0 : +e[1], e[0] = r(e[0], "fn-", this, n);
            }), t;
          }
          var W = r(50);
          const X = {},
            Q = ["open", "send"];
          function K(e) {
            var t = e || n.ee;
            const r = function (e) {
              return (e || n.ee).get("xhr");
            }(t);
            if (X[r.debugId]++) return r;
            X[r.debugId] = 1, b(t);
            var i = c(r),
              o = f._A.XMLHttpRequest,
              a = f._A.MutationObserver,
              s = f._A.Promise,
              u = f._A.setInterval,
              d = "readystatechange",
              l = ["onload", "onerror", "onabort", "onloadstart", "onloadend", "onprogress", "ontimeout"],
              h = [],
              p = f._A.XMLHttpRequest = function (e) {
                const t = new o(e),
                  n = r.context(t);
                try {
                  r.emit("new-xhr", [t], n), t.addEventListener(d, (a = n, function () {
                    var e = this;
                    e.readyState > 3 && !a.resolved && (a.resolved = !0, r.emit("xhr-resolved", [], e)), i.inPlace(e, l, "fn-", A);
                  }), (0, S.m$)(!1));
                } catch (e) {
                  (0, W.Z)("An error occurred while intercepting XHR", e);
                  try {
                    r.emit("internal-error", [e]);
                  } catch (e) {}
                }
                var a;
                return t;
              };
            function g(e, t) {
              i.inPlace(t, ["onreadystatechange"], "fn-", A);
            }
            if (function (e, t) {
              for (var r in e) t[r] = e[r];
            }(o, p), p.prototype = o.prototype, i.inPlace(p.prototype, Q, "-xhr-", A), r.on("send-xhr-start", function (e, t) {
              g(e, t), function (e) {
                h.push(e), a && (m ? m.then(w) : u ? u(w) : (v = -v, y.data = v));
              }(t);
            }), r.on("open-xhr-start", g), a) {
              var m = s && s.resolve();
              if (!u && !s) {
                var v = 1,
                  y = document.createTextNode(v);
                new a(w).observe(y, {
                  characterData: !0
                });
              }
            } else t.on("fn-end", function (e) {
              e[0] && e[0].type === d || w();
            });
            function w() {
              for (var e = 0; e < h.length; e++) g(0, h[e]);
              h.length && (h = []);
            }
            function A(e, t) {
              return t;
            }
            return r;
          }
        },
        7825: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.ajax;
        },
        6660: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.jserrors;
        },
        3081: (e, t, r) => {
          r.d(t, {
            gF: () => o,
            mY: () => i,
            t9: () => n,
            vz: () => s,
            xS: () => a
          });
          const n = r(3325).D.metrics,
            i = "sm",
            o = "cm",
            a = "storeSupportabilityMetrics",
            s = "storeEventMetrics";
        },
        4649: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.pageAction;
        },
        7633: (e, t, r) => {
          r.d(t, {
            Dz: () => i,
            OJ: () => a,
            qw: () => o,
            t9: () => n
          });
          const n = r(3325).D.pageViewEvent,
            i = "firstbyte",
            o = "domcontent",
            a = "windowload";
        },
        9251: (e, t, r) => {
          r.d(t, {
            t: () => n
          });
          const n = r(3325).D.pageViewTiming;
        },
        3614: (e, t, r) => {
          r.d(t, {
            BST_RESOURCE: () => i,
            END: () => s,
            FEATURE_NAME: () => n,
            FN_END: () => u,
            FN_START: () => c,
            PUSH_STATE: () => d,
            RESOURCE: () => o,
            START: () => a
          });
          const n = r(3325).D.sessionTrace,
            i = "bstResource",
            o = "resource",
            a = "-start",
            s = "-end",
            c = "fn" + a,
            u = "fn" + s,
            d = "pushState";
        },
        7836: (e, t, r) => {
          r.d(t, {
            BODY: () => x,
            CB_END: () => E,
            CB_START: () => u,
            END: () => A,
            FEATURE_NAME: () => i,
            FETCH: () => _,
            FETCH_BODY: () => v,
            FETCH_DONE: () => m,
            FETCH_START: () => g,
            FN_END: () => c,
            FN_START: () => s,
            INTERACTION: () => f,
            INTERACTION_API: () => d,
            INTERACTION_EVENTS: () => o,
            JSONP_END: () => b,
            JSONP_NODE: () => p,
            JS_TIME: () => T,
            MAX_TIMER_BUDGET: () => a,
            REMAINING: () => l,
            SPA_NODE: () => h,
            START: () => w,
            originalSetTimeout: () => y
          });
          var n = r(5763);
          const i = r(3325).D.spa,
            o = ["click", "submit", "keypress", "keydown", "keyup", "change"],
            a = 999,
            s = "fn-start",
            c = "fn-end",
            u = "cb-start",
            d = "api-ixn-",
            l = "remaining",
            f = "interaction",
            h = "spaNode",
            p = "jsonpNode",
            g = "fetch-start",
            m = "fetch-done",
            v = "fetch-body-",
            b = "jsonp-end",
            y = n.Yu.ST,
            w = "-start",
            A = "-end",
            x = "-body",
            E = "cb" + A,
            T = "jsTime",
            _ = "fetch";
        },
        5938: (e, t, r) => {
          r.d(t, {
            W: () => o
          });
          var n = r(5763),
            i = r(8325);
          class o {
            constructor(e, t, r) {
              this.agentIdentifier = e, this.aggregator = t, this.ee = i.ee.get(e, (0, n.OP)(this.agentIdentifier).isolatedBacklog), this.featureName = r, this.blocked = !1;
            }
          }
        },
        9144: (e, t, r) => {
          r.d(t, {
            j: () => m
          });
          var n = r(3325),
            i = r(5763),
            o = r(5546),
            a = r(8325),
            s = r(7894),
            c = r(8e3),
            u = r(3960),
            d = r(385),
            l = r(50),
            f = r(3081),
            h = r(8632);
          function p() {
            const e = (0, h.gG)();
            ["setErrorHandler", "finished", "addToTrace", "inlineHit", "addRelease", "addPageAction", "setCurrentRouteName", "setPageViewName", "setCustomAttribute", "interaction", "noticeError", "setUserId", "setApplicationVersion"].forEach(t => {
              e[t] = function () {
                for (var r = arguments.length, n = new Array(r), i = 0; i < r; i++) n[i] = arguments[i];
                return function (t) {
                  for (var r = arguments.length, n = new Array(r > 1 ? r - 1 : 0), i = 1; i < r; i++) n[i - 1] = arguments[i];
                  let o = [];
                  return Object.values(e.initializedAgents).forEach(e => {
                    e.exposed && e.api[t] && o.push(e.api[t](...n));
                  }), o.length > 1 ? o : o[0];
                }(t, ...n);
              };
            });
          }
          var g = r(2587);
          function m(e) {
            let t = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : {},
              m = arguments.length > 2 ? arguments[2] : void 0,
              v = arguments.length > 3 ? arguments[3] : void 0,
              {
                init: b,
                info: y,
                loader_config: w,
                runtime: A = {
                  loaderType: m
                },
                exposed: x = !0
              } = t;
            const E = (0, h.gG)();
            y || (b = E.init, y = E.info, w = E.loader_config), (0, i.Dg)(e, b || {}), (0, i.GE)(e, w || {}), y.jsAttributes ??= {}, d.v6 && (y.jsAttributes.isWorker = !0), (0, i.CX)(e, y);
            const T = (0, i.P_)(e);
            A.denyList = [...(T.ajax?.deny_list || []), ...(T.ajax?.block_internal ? [y.beacon, y.errorBeacon] : [])], (0, i.sU)(e, A), p();
            const _ = function (e, t) {
              t || (0, c.R)(e, "api");
              const h = {};
              var p = a.ee.get(e),
                g = p.get("tracer"),
                m = "api-",
                v = m + "ixn-";
              function b(t, r, n, o) {
                const a = (0, i.C5)(e);
                return null === r ? delete a.jsAttributes[t] : (0, i.CX)(e, {
                  ...a,
                  jsAttributes: {
                    ...a.jsAttributes,
                    [t]: r
                  }
                }), A(m, n, !0, o || null === r ? "session" : void 0)(t, r);
              }
              function y() {}
              ["setErrorHandler", "finished", "addToTrace", "inlineHit", "addRelease"].forEach(e => h[e] = A(m, e, !0, "api")), h.addPageAction = A(m, "addPageAction", !0, n.D.pageAction), h.setCurrentRouteName = A(m, "routeName", !0, n.D.spa), h.setPageViewName = function (t, r) {
                if ("string" == typeof t) return "/" !== t.charAt(0) && (t = "/" + t), (0, i.OP)(e).customTransaction = (r || "http://custom.transaction") + t, A(m, "setPageViewName", !0)();
              }, h.setCustomAttribute = function (e, t) {
                let r = arguments.length > 2 && void 0 !== arguments[2] && arguments[2];
                if ("string" == typeof e) {
                  if (["string", "number"].includes(typeof t) || null === t) return b(e, t, "setCustomAttribute", r);
                  (0, l.Z)("Failed to execute setCustomAttribute.\nNon-null value must be a string or number type, but a type of <".concat(typeof t, "> was provided."));
                } else (0, l.Z)("Failed to execute setCustomAttribute.\nName must be a string type, but a type of <".concat(typeof e, "> was provided."));
              }, h.setUserId = function (e) {
                if ("string" == typeof e || null === e) return b("enduser.id", e, "setUserId", !0);
                (0, l.Z)("Failed to execute setUserId.\nNon-null value must be a string type, but a type of <".concat(typeof e, "> was provided."));
              }, h.setApplicationVersion = function (e) {
                if ("string" == typeof e || null === e) return b("application.version", e, "setApplicationVersion", !1);
                (0, l.Z)("Failed to execute setApplicationVersion. Expected <String | null>, but got <".concat(typeof e, ">."));
              }, h.interaction = function () {
                return new y().get();
              };
              var w = y.prototype = {
                createTracer: function (e, t) {
                  var r = {},
                    i = this,
                    a = "function" == typeof t;
                  return (0, o.p)(v + "tracer", [(0, s.z)(), e, r], i, n.D.spa, p), function () {
                    if (g.emit((a ? "" : "no-") + "fn-start", [(0, s.z)(), i, a], r), a) try {
                      return t.apply(this, arguments);
                    } catch (e) {
                      throw g.emit("fn-err", [arguments, this, e], r), e;
                    } finally {
                      g.emit("fn-end", [(0, s.z)()], r);
                    }
                  };
                }
              };
              function A(e, t, r, i) {
                return function () {
                  return (0, o.p)(f.xS, ["API/" + t + "/called"], void 0, n.D.metrics, p), i && (0, o.p)(e + t, [(0, s.z)(), ...arguments], r ? null : this, i, p), r ? void 0 : this;
                };
              }
              function x() {
                r.e(111).then(r.bind(r, 7438)).then(t => {
                  let {
                    setAPI: r
                  } = t;
                  r(e), (0, c.L)(e, "api");
                }).catch(() => (0, l.Z)("Downloading runtime APIs failed..."));
              }
              return ["actionText", "setName", "setAttribute", "save", "ignore", "onEnd", "getContext", "end", "get"].forEach(e => {
                w[e] = A(v, e, void 0, n.D.spa);
              }), h.noticeError = function (e, t) {
                "string" == typeof e && (e = new Error(e)), (0, o.p)(f.xS, ["API/noticeError/called"], void 0, n.D.metrics, p), (0, o.p)("err", [e, (0, s.z)(), !1, t], void 0, n.D.jserrors, p);
              }, d.il ? (0, u.b)(() => x(), !0) : x(), h;
            }(e, v);
            return (0, h.Qy)(e, _, "api"), (0, h.Qy)(e, x, "exposed"), (0, h.EZ)("activatedFeatures", g.T), _;
          }
        },
        3325: (e, t, r) => {
          r.d(t, {
            D: () => n,
            p: () => i
          });
          const n = {
              ajax: "ajax",
              jserrors: "jserrors",
              metrics: "metrics",
              pageAction: "page_action",
              pageViewEvent: "page_view_event",
              pageViewTiming: "page_view_timing",
              sessionReplay: "session_replay",
              sessionTrace: "session_trace",
              spa: "spa"
            },
            i = {
              [n.pageViewEvent]: 1,
              [n.pageViewTiming]: 2,
              [n.metrics]: 3,
              [n.jserrors]: 4,
              [n.ajax]: 5,
              [n.sessionTrace]: 6,
              [n.pageAction]: 7,
              [n.spa]: 8,
              [n.sessionReplay]: 9
            };
        }
      },
      n = {};
    function i(e) {
      var t = n[e];
      if (void 0 !== t) return t.exports;
      var o = n[e] = {
        exports: {}
      };
      return r[e](o, o.exports, i), o.exports;
    }
    i.m = r, i.d = (e, t) => {
      for (var r in t) i.o(t, r) && !i.o(e, r) && Object.defineProperty(e, r, {
        enumerable: !0,
        get: t[r]
      });
    }, i.f = {}, i.e = e => Promise.all(Object.keys(i.f).reduce((t, r) => (i.f[r](e, t), t), [])), i.u = e => "nr-spa.1097a448-1.238.0.min.js", i.o = (e, t) => Object.prototype.hasOwnProperty.call(e, t), e = {}, t = "NRBA-1.238.0.PROD:", i.l = (r, n, o, a) => {
      if (e[r]) e[r].push(n);else {
        var s, c;
        if (void 0 !== o) for (var u = document.getElementsByTagName("script"), d = 0; d < u.length; d++) {
          var l = u[d];
          if (l.getAttribute("src") == r || l.getAttribute("data-webpack") == t + o) {
            s = l;
            break;
          }
        }
        s || (c = !0, (s = document.createElement("script")).charset = "utf-8", s.timeout = 120, i.nc && s.setAttribute("nonce", i.nc), s.setAttribute("data-webpack", t + o), s.src = r), e[r] = [n];
        var f = (t, n) => {
            s.onerror = s.onload = null, clearTimeout(h);
            var i = e[r];
            if (delete e[r], s.parentNode && s.parentNode.removeChild(s), i && i.forEach(e => e(n)), t) return t(n);
          },
          h = setTimeout(f.bind(null, void 0, {
            type: "timeout",
            target: s
          }), 12e4);
        s.onerror = f.bind(null, s.onerror), s.onload = f.bind(null, s.onload), c && document.head.appendChild(s);
      }
    }, i.r = e => {
      "undefined" != typeof Symbol && Symbol.toStringTag && Object.defineProperty(e, Symbol.toStringTag, {
        value: "Module"
      }), Object.defineProperty(e, "__esModule", {
        value: !0
      });
    }, i.p = "https://js-agent.newrelic.com/", (() => {
      var e = {
        801: 0,
        92: 0
      };
      i.f.j = (t, r) => {
        var n = i.o(e, t) ? e[t] : void 0;
        if (0 !== n) if (n) r.push(n[2]);else {
          var o = new Promise((r, i) => n = e[t] = [r, i]);
          r.push(n[2] = o);
          var a = i.p + i.u(t),
            s = new Error();
          i.l(a, r => {
            if (i.o(e, t) && (0 !== (n = e[t]) && (e[t] = void 0), n)) {
              var o = r && ("load" === r.type ? "missing" : r.type),
                a = r && r.target && r.target.src;
              s.message = "Loading chunk " + t + " failed.\n(" + o + ": " + a + ")", s.name = "ChunkLoadError", s.type = o, s.request = a, n[1](s);
            }
          }, "chunk-" + t, t);
        }
      };
      var t = (t, r) => {
          var n,
            o,
            [a, s, c] = r,
            u = 0;
          if (a.some(t => 0 !== e[t])) {
            for (n in s) i.o(s, n) && (i.m[n] = s[n]);
            if (c) c(i);
          }
          for (t && t(r); u < a.length; u++) o = a[u], i.o(e, o) && e[o] && e[o][0](), e[o] = 0;
        },
        r = self["webpackChunk:NRBA-1.238.0.PROD"] = self["webpackChunk:NRBA-1.238.0.PROD"] || [];
      r.forEach(t.bind(null, 0)), r.push = t.bind(null, r.push.bind(r));
    })(), (() => {
      var e = i(50);
      class t {
        addPageAction(t, r) {
          (0, e.Z)("Call to agent api addPageAction failed. The session trace feature is not currently initialized.");
        }
        setPageViewName(t, r) {
          (0, e.Z)("Call to agent api setPageViewName failed. The page view feature is not currently initialized.");
        }
        setCustomAttribute(t, r, n) {
          (0, e.Z)("Call to agent api setCustomAttribute failed. The js errors feature is not currently initialized.");
        }
        noticeError(t, r) {
          (0, e.Z)("Call to agent api noticeError failed. The js errors feature is not currently initialized.");
        }
        setUserId(t) {
          (0, e.Z)("Call to agent api setUserId failed. The js errors feature is not currently initialized.");
        }
        setApplicationVersion(t) {
          (0, e.Z)("Call to agent api setApplicationVersion failed. The agent is not currently initialized.");
        }
        setErrorHandler(t) {
          (0, e.Z)("Call to agent api setErrorHandler failed. The js errors feature is not currently initialized.");
        }
        finished(t) {
          (0, e.Z)("Call to agent api finished failed. The page action feature is not currently initialized.");
        }
        addRelease(t, r) {
          (0, e.Z)("Call to agent api addRelease failed. The agent is not currently initialized.");
        }
      }
      var r = i(3325),
        n = i(5763);
      const o = Object.values(r.D);
      function a(e) {
        const t = {};
        return o.forEach(r => {
          t[r] = function (e, t) {
            return !1 !== (0, n.Mt)(t, "".concat(e, ".enabled"));
          }(r, e);
        }), t;
      }
      var s = i(9144);
      var c = i(5546),
        u = i(385),
        d = i(8e3),
        l = i(5938),
        f = i(3960);
      class h extends l.W {
        constructor(e, t, r) {
          let n = !(arguments.length > 3 && void 0 !== arguments[3]) || arguments[3];
          super(e, t, r), this.auto = n, this.abortHandler, this.featAggregate, this.onAggregateImported, n && (0, d.R)(e, r);
        }
        importAggregator() {
          let t = arguments.length > 0 && void 0 !== arguments[0] ? arguments[0] : {};
          if (this.featAggregate || !this.auto) return;
          const r = u.il && !0 === (0, n.Mt)(this.agentIdentifier, "privacy.cookies_enabled");
          let o;
          this.onAggregateImported = new Promise(e => {
            o = e;
          });
          const a = async () => {
            let n;
            try {
              if (r) {
                const {
                  setupAgentSession: e
                } = await i.e(111).then(i.bind(i, 3228));
                n = e(this.agentIdentifier);
              }
            } catch (t) {
              (0, e.Z)("A problem occurred when starting up session manager. This page will not start or extend any session.", t);
            }
            try {
              if (!this.shouldImportAgg(this.featureName, n)) return (0, d.L)(this.agentIdentifier, this.featureName), void o(!1);
              const {
                  lazyFeatureLoader: e
                } = await i.e(111).then(i.bind(i, 8582)),
                {
                  Aggregate: r
                } = await e(this.featureName, "aggregate");
              this.featAggregate = new r(this.agentIdentifier, this.aggregator, t), o(!0);
            } catch (t) {
              (0, e.Z)("Downloading and initializing ".concat(this.featureName, " failed..."), t), this.abortHandler?.(), o(!1);
            }
          };
          u.il ? (0, f.b)(() => a(), !0) : a();
        }
        shouldImportAgg(e, t) {
          return e !== r.D.sessionReplay || !!n.Yu.MO && !1 !== (0, n.Mt)(this.agentIdentifier, "session_trace.enabled") && (!!t?.isNew || !!t?.state.sessionReplay);
        }
      }
      var p = i(7633),
        g = i(7894);
      class m extends h {
        static featureName = p.t9;
        constructor(e, t) {
          let i = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          if (super(e, t, p.t9, i), ("undefined" == typeof PerformanceNavigationTiming || u.Tt) && "undefined" != typeof PerformanceTiming) {
            const t = (0, n.OP)(e);
            t[p.Dz] = Math.max(Date.now() - t.offset, 0), (0, f.K)(() => t[p.qw] = Math.max((0, g.z)() - t[p.Dz], 0)), (0, f.b)(() => {
              const e = (0, g.z)();
              t[p.OJ] = Math.max(e - t[p.Dz], 0), (0, c.p)("timing", ["load", e], void 0, r.D.pageViewTiming, this.ee);
            });
          }
          this.importAggregator();
        }
      }
      var v = i(1117),
        b = i(1284);
      class y extends v.w {
        constructor(e) {
          super(e), this.aggregatedData = {};
        }
        store(e, t, r, n, i) {
          var o = this.getBucket(e, t, r, i);
          return o.metrics = function (e, t) {
            t || (t = {
              count: 0
            });
            return t.count += 1, (0, b.D)(e, function (e, r) {
              t[e] = w(r, t[e]);
            }), t;
          }(n, o.metrics), o;
        }
        merge(e, t, r, n, i) {
          var o = this.getBucket(e, t, n, i);
          if (o.metrics) {
            var a = o.metrics;
            a.count += r.count, (0, b.D)(r, function (e, t) {
              if ("count" !== e) {
                var n = a[e],
                  i = r[e];
                i && !i.c ? a[e] = w(i.t, n) : a[e] = function (e, t) {
                  if (!t) return e;
                  t.c || (t = A(t.t));
                  return t.min = Math.min(e.min, t.min), t.max = Math.max(e.max, t.max), t.t += e.t, t.sos += e.sos, t.c += e.c, t;
                }(i, a[e]);
              }
            });
          } else o.metrics = r;
        }
        storeMetric(e, t, r, n) {
          var i = this.getBucket(e, t, r);
          return i.stats = w(n, i.stats), i;
        }
        getBucket(e, t, r, n) {
          this.aggregatedData[e] || (this.aggregatedData[e] = {});
          var i = this.aggregatedData[e][t];
          return i || (i = this.aggregatedData[e][t] = {
            params: r || {}
          }, n && (i.custom = n)), i;
        }
        get(e, t) {
          return t ? this.aggregatedData[e] && this.aggregatedData[e][t] : this.aggregatedData[e];
        }
        take(e) {
          for (var t = {}, r = "", n = !1, i = 0; i < e.length; i++) t[r = e[i]] = x(this.aggregatedData[r]), t[r].length && (n = !0), delete this.aggregatedData[r];
          return n ? t : null;
        }
      }
      function w(e, t) {
        return null == e ? function (e) {
          e ? e.c++ : e = {
            c: 1
          };
          return e;
        }(t) : t ? (t.c || (t = A(t.t)), t.c += 1, t.t += e, t.sos += e * e, e > t.max && (t.max = e), e < t.min && (t.min = e), t) : {
          t: e
        };
      }
      function A(e) {
        return {
          t: e,
          min: e,
          max: e,
          sos: e * e,
          c: 1
        };
      }
      function x(e) {
        return "object" != typeof e ? [] : (0, b.D)(e, E);
      }
      function E(e, t) {
        return t;
      }
      var T = i(8632),
        _ = i(4402),
        D = i(4351);
      var j = i(7956),
        C = i(3239),
        N = i(9251);
      class O extends h {
        static featureName = N.t;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, N.t, r), u.il && ((0, n.OP)(e).initHidden = Boolean("hidden" === document.visibilityState), (0, j.N)(() => (0, c.p)("docHidden", [(0, g.z)()], void 0, N.t, this.ee), !0), (0, C.bP)("pagehide", () => (0, c.p)("winPagehide", [(0, g.z)()], void 0, N.t, this.ee)), this.importAggregator());
        }
      }
      var S = i(3081);
      class P extends h {
        static featureName = S.t9;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, S.t9, r), this.importAggregator();
        }
      }
      var R = i(6660);
      class I {
        constructor(e, t, r, n) {
          this.name = "UncaughtError", this.message = e, this.sourceURL = t, this.line = r, this.column = n;
        }
      }
      class k extends h {
        static featureName = R.t;
        #e = new Set();
        constructor(e, t) {
          let n = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, R.t, n);
          try {
            this.removeOnAbort = new AbortController();
          } catch (e) {}
          this.ee.on("fn-err", (e, t, n) => {
            this.abortHandler && !this.#e.has(n) && (this.#e.add(n), (0, c.p)("err", [this.#t(n), (0, g.z)()], void 0, r.D.jserrors, this.ee));
          }), this.ee.on("internal-error", e => {
            this.abortHandler && (0, c.p)("ierr", [this.#t(e), (0, g.z)(), !0], void 0, r.D.jserrors, this.ee);
          }), u._A.addEventListener("unhandledrejection", e => {
            this.abortHandler && (0, c.p)("err", [this.#r(e), (0, g.z)(), !1, {
              unhandledPromiseRejection: 1
            }], void 0, r.D.jserrors, this.ee);
          }, (0, C.m$)(!1, this.removeOnAbort?.signal)), u._A.addEventListener("error", e => {
            this.abortHandler && (this.#e.has(e.error) ? this.#e.delete(e.error) : (0, c.p)("err", [this.#n(e), (0, g.z)()], void 0, r.D.jserrors, this.ee));
          }, (0, C.m$)(!1, this.removeOnAbort?.signal)), this.abortHandler = this.#i, this.importAggregator();
        }
        #i() {
          this.removeOnAbort?.abort(), this.#e.clear(), this.abortHandler = void 0;
        }
        #t(e) {
          return e instanceof Error ? e : void 0 !== e?.message ? new I(e.message, e.filename || e.sourceURL, e.lineno || e.line, e.colno || e.col) : new I("string" == typeof e ? e : (0, D.P)(e));
        }
        #r(e) {
          let t = "Unhandled Promise Rejection: ";
          if (e?.reason instanceof Error) try {
            return e.reason.message = t + e.reason.message, e.reason;
          } catch (t) {
            return e.reason;
          }
          if (void 0 === e.reason) return new I(t);
          const r = this.#t(e.reason);
          return r.message = t + r.message, r;
        }
        #n(e) {
          return e.error instanceof Error ? e.error : new I(e.message, e.filename, e.lineno, e.colno);
        }
      }
      var H = i(2210);
      let z = 1;
      const L = "nr@id";
      function M(e) {
        const t = typeof e;
        return !e || "object" !== t && "function" !== t ? -1 : e === u._A ? 0 : (0, H.X)(e, L, function () {
          return z++;
        });
      }
      function B(e) {
        if ("string" == typeof e && e.length) return e.length;
        if ("object" == typeof e) {
          if ("undefined" != typeof ArrayBuffer && e instanceof ArrayBuffer && e.byteLength) return e.byteLength;
          if ("undefined" != typeof Blob && e instanceof Blob && e.size) return e.size;
          if (!("undefined" != typeof FormData && e instanceof FormData)) try {
            return (0, D.P)(e).length;
          } catch (e) {
            return;
          }
        }
      }
      var F = i(1214),
        U = i(7243);
      class q {
        constructor(e) {
          this.agentIdentifier = e;
        }
        generateTracePayload(e) {
          if (!this.shouldGenerateTrace(e)) return null;
          var t = (0, n.DL)(this.agentIdentifier);
          if (!t) return null;
          var r = (t.accountID || "").toString() || null,
            i = (t.agentID || "").toString() || null,
            o = (t.trustKey || "").toString() || null;
          if (!r || !i) return null;
          var a = (0, _.M)(),
            s = (0, _.Ht)(),
            c = Date.now(),
            u = {
              spanId: a,
              traceId: s,
              timestamp: c
            };
          return (e.sameOrigin || this.isAllowedOrigin(e) && this.useTraceContextHeadersForCors()) && (u.traceContextParentHeader = this.generateTraceContextParentHeader(a, s), u.traceContextStateHeader = this.generateTraceContextStateHeader(a, c, r, i, o)), (e.sameOrigin && !this.excludeNewrelicHeader() || !e.sameOrigin && this.isAllowedOrigin(e) && this.useNewrelicHeaderForCors()) && (u.newrelicHeader = this.generateTraceHeader(a, s, c, r, i, o)), u;
        }
        generateTraceContextParentHeader(e, t) {
          return "00-" + t + "-" + e + "-01";
        }
        generateTraceContextStateHeader(e, t, r, n, i) {
          return i + "@nr=0-1-" + r + "-" + n + "-" + e + "----" + t;
        }
        generateTraceHeader(e, t, r, n, i, o) {
          if (!("function" == typeof u._A?.btoa)) return null;
          var a = {
            v: [0, 1],
            d: {
              ty: "Browser",
              ac: n,
              ap: i,
              id: e,
              tr: t,
              ti: r
            }
          };
          return o && n !== o && (a.d.tk = o), btoa((0, D.P)(a));
        }
        shouldGenerateTrace(e) {
          return this.isDtEnabled() && this.isAllowedOrigin(e);
        }
        isAllowedOrigin(e) {
          var t = !1,
            r = {};
          if ((0, n.Mt)(this.agentIdentifier, "distributed_tracing") && (r = (0, n.P_)(this.agentIdentifier).distributed_tracing), e.sameOrigin) t = !0;else if (r.allowed_origins instanceof Array) for (var i = 0; i < r.allowed_origins.length; i++) {
            var o = (0, U.e)(r.allowed_origins[i]);
            if (e.hostname === o.hostname && e.protocol === o.protocol && e.port === o.port) {
              t = !0;
              break;
            }
          }
          return t;
        }
        isDtEnabled() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.enabled;
        }
        excludeNewrelicHeader() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.exclude_newrelic_header;
        }
        useNewrelicHeaderForCors() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !1 !== e.cors_use_newrelic_header;
        }
        useTraceContextHeadersForCors() {
          var e = (0, n.Mt)(this.agentIdentifier, "distributed_tracing");
          return !!e && !!e.cors_use_tracecontext_headers;
        }
      }
      var Z = i(7825),
        V = ["load", "error", "abort", "timeout"],
        G = V.length,
        W = n.Yu.REQ,
        X = n.Yu.XHR;
      class Q extends h {
        static featureName = Z.t;
        constructor(e, t) {
          let i = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, Z.t, i), (0, n.OP)(e).xhrWrappable && (this.dt = new q(e), this.handler = (e, t, r, n) => (0, c.p)(e, t, r, n, this.ee), (0, F.u5)(this.ee), (0, F.Kf)(this.ee), function (e, t, i, o) {
            function a(e) {
              var t = this;
              t.totalCbs = 0, t.called = 0, t.cbTime = 0, t.end = E, t.ended = !1, t.xhrGuids = {}, t.lastSize = null, t.loadCaptureCalled = !1, t.params = this.params || {}, t.metrics = this.metrics || {}, e.addEventListener("load", function (r) {
                _(t, e);
              }, (0, C.m$)(!1)), u.IF || e.addEventListener("progress", function (e) {
                t.lastSize = e.loaded;
              }, (0, C.m$)(!1));
            }
            function s(e) {
              this.params = {
                method: e[0]
              }, T(this, e[1]), this.metrics = {};
            }
            function c(t, r) {
              var i = (0, n.DL)(e);
              i.xpid && this.sameOrigin && r.setRequestHeader("X-NewRelic-ID", i.xpid);
              var a = o.generateTracePayload(this.parsedOrigin);
              if (a) {
                var s = !1;
                a.newrelicHeader && (r.setRequestHeader("newrelic", a.newrelicHeader), s = !0), a.traceContextParentHeader && (r.setRequestHeader("traceparent", a.traceContextParentHeader), a.traceContextStateHeader && r.setRequestHeader("tracestate", a.traceContextStateHeader), s = !0), s && (this.dt = a);
              }
            }
            function d(e, r) {
              var n = this.metrics,
                i = e[0],
                o = this;
              if (n && i) {
                var a = B(i);
                a && (n.txSize = a);
              }
              this.startTime = (0, g.z)(), this.listener = function (e) {
                try {
                  "abort" !== e.type || o.loadCaptureCalled || (o.params.aborted = !0), ("load" !== e.type || o.called === o.totalCbs && (o.onloadCalled || "function" != typeof r.onload) && "function" == typeof o.end) && o.end(r);
                } catch (e) {
                  try {
                    t.emit("internal-error", [e]);
                  } catch (e) {}
                }
              };
              for (var s = 0; s < G; s++) r.addEventListener(V[s], this.listener, (0, C.m$)(!1));
            }
            function l(e, t, r) {
              this.cbTime += e, t ? this.onloadCalled = !0 : this.called += 1, this.called !== this.totalCbs || !this.onloadCalled && "function" == typeof r.onload || "function" != typeof this.end || this.end(r);
            }
            function f(e, t) {
              var r = "" + M(e) + !!t;
              this.xhrGuids && !this.xhrGuids[r] && (this.xhrGuids[r] = !0, this.totalCbs += 1);
            }
            function h(e, t) {
              var r = "" + M(e) + !!t;
              this.xhrGuids && this.xhrGuids[r] && (delete this.xhrGuids[r], this.totalCbs -= 1);
            }
            function p() {
              this.endTime = (0, g.z)();
            }
            function m(e, r) {
              r instanceof X && "load" === e[0] && t.emit("xhr-load-added", [e[1], e[2]], r);
            }
            function v(e, r) {
              r instanceof X && "load" === e[0] && t.emit("xhr-load-removed", [e[1], e[2]], r);
            }
            function b(e, t, r) {
              t instanceof X && ("onload" === r && (this.onload = !0), ("load" === (e[0] && e[0].type) || this.onload) && (this.xhrCbStart = (0, g.z)()));
            }
            function y(e, r) {
              this.xhrCbStart && t.emit("xhr-cb-time", [(0, g.z)() - this.xhrCbStart, this.onload, r], r);
            }
            function w(e) {
              var t,
                r = e[1] || {};
              if ("string" == typeof e[0] ? 0 === (t = e[0]).length && u.il && (t = "" + u._A.location.href) : e[0] && e[0].url ? t = e[0].url : u._A?.URL && e[0] && e[0] instanceof URL ? t = e[0].href : "function" == typeof e[0].toString && (t = e[0].toString()), "string" == typeof t && 0 !== t.length) {
                t && (this.parsedOrigin = (0, U.e)(t), this.sameOrigin = this.parsedOrigin.sameOrigin);
                var n = o.generateTracePayload(this.parsedOrigin);
                if (n && (n.newrelicHeader || n.traceContextParentHeader)) if (e[0] && e[0].headers) s(e[0].headers, n) && (this.dt = n);else {
                  var i = {};
                  for (var a in r) i[a] = r[a];
                  i.headers = new Headers(r.headers || {}), s(i.headers, n) && (this.dt = n), e.length > 1 ? e[1] = i : e.push(i);
                }
              }
              function s(e, t) {
                var r = !1;
                return t.newrelicHeader && (e.set("newrelic", t.newrelicHeader), r = !0), t.traceContextParentHeader && (e.set("traceparent", t.traceContextParentHeader), t.traceContextStateHeader && e.set("tracestate", t.traceContextStateHeader), r = !0), r;
              }
            }
            function A(e, t) {
              this.params = {}, this.metrics = {}, this.startTime = (0, g.z)(), this.dt = t, e.length >= 1 && (this.target = e[0]), e.length >= 2 && (this.opts = e[1]);
              var r,
                n = this.opts || {},
                i = this.target;
              "string" == typeof i ? r = i : "object" == typeof i && i instanceof W ? r = i.url : u._A?.URL && "object" == typeof i && i instanceof URL && (r = i.href), T(this, r);
              var o = ("" + (i && i instanceof W && i.method || n.method || "GET")).toUpperCase();
              this.params.method = o, this.txSize = B(n.body) || 0;
            }
            function x(e, t) {
              var n;
              this.endTime = (0, g.z)(), this.params || (this.params = {}), this.params.status = t ? t.status : 0, "string" == typeof this.rxSize && this.rxSize.length > 0 && (n = +this.rxSize);
              var o = {
                txSize: this.txSize,
                rxSize: n,
                duration: (0, g.z)() - this.startTime
              };
              i("xhr", [this.params, o, this.startTime, this.endTime, "fetch"], this, r.D.ajax);
            }
            function E(e) {
              var t = this.params,
                n = this.metrics;
              if (!this.ended) {
                this.ended = !0;
                for (var o = 0; o < G; o++) e.removeEventListener(V[o], this.listener, !1);
                t.aborted || (n.duration = (0, g.z)() - this.startTime, this.loadCaptureCalled || 4 !== e.readyState ? null == t.status && (t.status = 0) : _(this, e), n.cbTime = this.cbTime, i("xhr", [t, n, this.startTime, this.endTime, "xhr"], this, r.D.ajax));
              }
            }
            function T(e, t) {
              var r = (0, U.e)(t),
                n = e.params;
              n.hostname = r.hostname, n.port = r.port, n.protocol = r.protocol, n.host = r.hostname + ":" + r.port, n.pathname = r.pathname, e.parsedOrigin = r, e.sameOrigin = r.sameOrigin;
            }
            function _(e, t) {
              e.params.status = t.status;
              var r = function (e, t) {
                var r = e.responseType;
                return "json" === r && null !== t ? t : "arraybuffer" === r || "blob" === r || "json" === r ? B(e.response) : "text" === r || "" === r || void 0 === r ? B(e.responseText) : void 0;
              }(t, e.lastSize);
              if (r && (e.metrics.rxSize = r), e.sameOrigin) {
                var n = t.getResponseHeader("X-NewRelic-App-Data");
                n && (e.params.cat = n.split(", ").pop());
              }
              e.loadCaptureCalled = !0;
            }
            t.on("new-xhr", a), t.on("open-xhr-start", s), t.on("open-xhr-end", c), t.on("send-xhr-start", d), t.on("xhr-cb-time", l), t.on("xhr-load-added", f), t.on("xhr-load-removed", h), t.on("xhr-resolved", p), t.on("addEventListener-end", m), t.on("removeEventListener-end", v), t.on("fn-end", y), t.on("fetch-before-start", w), t.on("fetch-start", A), t.on("fn-start", b), t.on("fetch-done", x);
          }(e, this.ee, this.handler, this.dt), this.importAggregator());
        }
      }
      var K = i(3614);
      const {
        BST_RESOURCE: Y,
        RESOURCE: J,
        START: ee,
        END: te,
        FEATURE_NAME: re,
        FN_END: ne,
        FN_START: ie,
        PUSH_STATE: oe
      } = K;
      var ae = i(7836);
      const {
        FEATURE_NAME: se,
        START: ce,
        END: ue,
        BODY: de,
        CB_END: le,
        JS_TIME: fe,
        FETCH: he,
        FN_START: pe,
        CB_START: ge,
        FN_END: me
      } = ae;
      var ve = i(4649);
      class be extends h {
        static featureName = ve.t;
        constructor(e, t) {
          let r = !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2];
          super(e, t, ve.t, r), this.importAggregator();
        }
      }
      new class extends t {
        constructor(t) {
          let r = arguments.length > 1 && void 0 !== arguments[1] ? arguments[1] : (0, _.ky)(16);
          super(), u._A ? (this.agentIdentifier = r, this.sharedAggregator = new y({
            agentIdentifier: this.agentIdentifier
          }), this.features = {}, this.desiredFeatures = new Set(t.features || []), this.desiredFeatures.add(m), Object.assign(this, (0, s.j)(this.agentIdentifier, t, t.loaderType || "agent")), this.start()) : (0, e.Z)("Failed to initial the agent. Could not determine the runtime environment.");
        }
        get config() {
          return {
            info: (0, n.C5)(this.agentIdentifier),
            init: (0, n.P_)(this.agentIdentifier),
            loader_config: (0, n.DL)(this.agentIdentifier),
            runtime: (0, n.OP)(this.agentIdentifier)
          };
        }
        start() {
          const t = "features";
          try {
            const n = a(this.agentIdentifier),
              i = [...this.desiredFeatures];
            i.sort((e, t) => r.p[e.featureName] - r.p[t.featureName]), i.forEach(t => {
              if (n[t.featureName] || t.featureName === r.D.pageViewEvent) {
                const i = function (e) {
                  switch (e) {
                    case r.D.ajax:
                      return [r.D.jserrors];
                    case r.D.sessionTrace:
                      return [r.D.ajax, r.D.pageViewEvent];
                    case r.D.sessionReplay:
                      return [r.D.sessionTrace];
                    case r.D.pageViewTiming:
                      return [r.D.pageViewEvent];
                    default:
                      return [];
                  }
                }(t.featureName);
                i.every(e => n[e]) || (0, e.Z)("".concat(t.featureName, " is enabled but one or more dependent features has been disabled (").concat((0, D.P)(i), "). This may cause unintended consequences or missing data...")), this.features[t.featureName] = new t(this.agentIdentifier, this.sharedAggregator);
              }
            }), (0, T.Qy)(this.agentIdentifier, this.features, t);
          } catch (r) {
            (0, e.Z)("Failed to initialize all enabled instrument classes (agent aborted) -", r);
            for (const e in this.features) this.features[e].abortHandler?.();
            const n = (0, T.fP)();
            return delete n.initializedAgents[this.agentIdentifier]?.api, delete n.initializedAgents[this.agentIdentifier]?.[t], delete this.sharedAggregator, n.ee?.abort(), delete n.ee?.get(this.agentIdentifier), !1;
          }
        }
        addToTrace(t) {
          (0, e.Z)("Call to agent api addToTrace failed. The page action feature is not currently initialized.");
        }
        setCurrentRouteName(t) {
          (0, e.Z)("Call to agent api setCurrentRouteName failed. The spa feature is not currently initialized.");
        }
        interaction() {
          (0, e.Z)("Call to agent api interaction failed. The spa feature is not currently initialized.");
        }
      }({
        features: [Q, m, O, class extends h {
          static featureName = re;
          constructor(e, t) {
            if (super(e, t, re, !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2]), !u.il) return;
            const n = this.ee;
            let i;
            (0, F.QU)(n), this.eventsEE = (0, F.em)(n), this.eventsEE.on(ie, function (e, t) {
              this.bstStart = (0, g.z)();
            }), this.eventsEE.on(ne, function (e, t) {
              (0, c.p)("bst", [e[0], t, this.bstStart, (0, g.z)()], void 0, r.D.sessionTrace, n);
            }), n.on(oe + ee, function (e) {
              this.time = (0, g.z)(), this.startPath = location.pathname + location.hash;
            }), n.on(oe + te, function (e) {
              (0, c.p)("bstHist", [location.pathname + location.hash, this.startPath, this.time], void 0, r.D.sessionTrace, n);
            });
            try {
              i = new PerformanceObserver(e => {
                const t = e.getEntries();
                (0, c.p)(Y, [t], void 0, r.D.sessionTrace, n);
              }), i.observe({
                type: J,
                buffered: !0
              });
            } catch (e) {}
            this.importAggregator({
              resourceObserver: i
            });
          }
        }, P, be, k, class extends h {
          static featureName = se;
          constructor(e, t) {
            if (super(e, t, se, !(arguments.length > 2 && void 0 !== arguments[2]) || arguments[2]), !u.il) return;
            if (!(0, n.OP)(e).xhrWrappable) return;
            try {
              this.removeOnAbort = new AbortController();
            } catch (e) {}
            let r,
              i = 0;
            const o = this.ee.get("tracer"),
              a = (0, F._L)(this.ee),
              s = (0, F.Lg)(this.ee),
              c = (0, F.BV)(this.ee),
              d = (0, F.Kf)(this.ee),
              l = this.ee.get("events"),
              f = (0, F.u5)(this.ee),
              h = (0, F.QU)(this.ee),
              p = (0, F.Gm)(this.ee);
            function m(e, t) {
              h.emit("newURL", ["" + window.location, t]);
            }
            function v() {
              i++, r = window.location.hash, this[pe] = (0, g.z)();
            }
            function b() {
              i--, window.location.hash !== r && m(0, !0);
              var e = (0, g.z)();
              this[fe] = ~~this[fe] + e - this[pe], this[me] = e;
            }
            function y(e, t) {
              e.on(t, function () {
                this[t] = (0, g.z)();
              });
            }
            this.ee.on(pe, v), s.on(ge, v), a.on(ge, v), this.ee.on(me, b), s.on(le, b), a.on(le, b), this.ee.buffer([pe, me, "xhr-resolved"], this.featureName), l.buffer([pe], this.featureName), c.buffer(["setTimeout" + ue, "clearTimeout" + ce, pe], this.featureName), d.buffer([pe, "new-xhr", "send-xhr" + ce], this.featureName), f.buffer([he + ce, he + "-done", he + de + ce, he + de + ue], this.featureName), h.buffer(["newURL"], this.featureName), p.buffer([pe], this.featureName), s.buffer(["propagate", ge, le, "executor-err", "resolve" + ce], this.featureName), o.buffer([pe, "no-" + pe], this.featureName), a.buffer(["new-jsonp", "cb-start", "jsonp-error", "jsonp-end"], this.featureName), y(f, he + ce), y(f, he + "-done"), y(a, "new-jsonp"), y(a, "jsonp-end"), y(a, "cb-start"), h.on("pushState-end", m), h.on("replaceState-end", m), window.addEventListener("hashchange", m, (0, C.m$)(!0, this.removeOnAbort?.signal)), window.addEventListener("load", m, (0, C.m$)(!0, this.removeOnAbort?.signal)), window.addEventListener("popstate", function () {
              m(0, i > 1);
            }, (0, C.m$)(!0, this.removeOnAbort?.signal)), this.abortHandler = this.#i, this.importAggregator();
          }
          #i() {
            this.removeOnAbort?.abort(), this.abortHandler = void 0;
          }
        }],
        loaderType: "spa"
      });
    })();
  })();
})()</script>
<link rel="shortcut icon" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico" type="image/x-icon" />
<link rel="icon" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/103/images/favSD.ico" type="image/x-icon">
<link rel="stylesheet" href="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/402a3f5c247cf997723622b5a8bc17cc2004f90c/arp.css">
<link href="//cdn.pendo.io" rel="dns-prefetch" />
<link href="https://cdn.pendo.io" rel="preconnect" crossorigin="anonymous" />
<link rel="dns-prefetch" href="https://smetrics.elsevier.com">
<script type="47a3bd3f3a53d05185487be5-text/javascript">
        var targetServerState = JSON.stringify({"4D6368F454EC41940A4C98A6@AdobeOrg":{"sdid":{"supplementalDataIDCurrent":"5170E31C17EAD1AF-6B39617B8AE5F636","supplementalDataIDCurrentConsumed":{"payload:target-global-mbox":true},"supplementalDataIDLastConsumed":{}}}});
        window.appData = window.appData || [];
        window.pageTargeting = {"region":"eu-west-1","platform":"sdtech","entitled":false,"crawler":"","journal":"Neurocomputing","auth":"AE"};
        window.arp = {
          config: {"adobeSuite":"elsevier-sd-prod","arsUrl":"https://ars.els-cdn.com","enableReadingAssistant":false,"recommendationsFeedback":{"enabled":true,"url":"https://feedback.recs.d.elsevier.com/raw/events","timeout":60000},"googleMapsApiKey":"AIzaSyCBYU6I6lrbEU6wQXUEIte3NwGtm3jwHQc","mediaBaseUrl":"https://ars.els-cdn.com/content/image/","strictMode":false,"seamlessAccess":{"enableSeamlessAccess":true,"scriptUrl":"https://unpkg.com/@theidentityselector/thiss-ds@1.0.13/dist/thiss-ds.js","persistenceUrl":"https://service.seamlessaccess.org/ps/","persistenceContext":"seamlessaccess.org","scienceDirectUrl":"https://www.sciencedirect.com","shibAuthUrl":"https://auth.elsevier.com/ShibAuth/institutionLogin"},"universalPdf":{"enableUniversalPdf":true,"universalPdfUrl":"https://static.mendeley.com/view-pdf-component/0.8.9/dist/view-pdf-element.js","integratorId":{"other":8301,"accessbar":10879}},"reaxys":{"apiUrl":"https://reaxys-sdlc.reaxys.com","origin":"sciencedirect","queryBuilderHostPath":"https://www.reaxys.com/reaxys/secured/hopinto.do","url":"https://www.reaxys.com"},"oneTrustCookie":{"enabled":true},"ssrn":{"url":"https://papers.ssrn.com","path":"/sol3/papers.cfm"},"assetRoute":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/402a3f5c247cf997723622b5a8bc17cc2004f90c"},
          subscriptions: [],
          subscribe: function(cb) {
            var self = this;
            var i = this.subscriptions.push(cb) - 1;
            return function unsubscribe() {
              self.subscriptions.splice(i, 1);
            }
          },
        };
        window.addEventListener('beforeprint', () => pendo.onGuideDismissed());
      </script>
</head>
<body>
<noscript>
      JavaScript is disabled on your browser.
      Please enable JavaScript to use all the features on this page.
      <img src=https://smetrics.elsevier.com/b/ss/elsevier-sd-prod/1/G.4--NS/1715929731101?pageName=sd%3Aproduct%3Ajournal%3Aarticle&c16=els%3Arp%3Ast&c2=sd&v185=img&v33=ae%3AANON_GUEST&c1=ae%3A228598&c12=ae%3A12975512 />
    </noscript>
<a class="anchor sr-only sr-only-focusable u-display-inline anchor-default" href="#screen-reader-main-content" data-reactroot><span class="anchor-text">Skip to main content</span></a><a class="anchor sr-only sr-only-focusable u-display-inline anchor-default" href="#screen-reader-main-title" data-reactroot><span class="anchor-text">Skip to article</span></a>
<div data-iso-key="_0"><div class="App" id="app" data-aa-name="root"><div class="page"><div class="sd-flex-container"><div class="sd-flex-content"><header id="gh-cnt"><div id="gh-main-cnt" class="u-flex-center-ver u-position-relative u-padding-s-hor u-padding-l-hor-from-xl"><a id="gh-branding" class="u-flex-center-ver" href="/" aria-label="ScienceDirect home page" data-aa-region="header" data-aa-name="ScienceDirect"><img class="gh-logo" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/24/images/elsevier-non-solus-new-grey.svg" alt="Elsevier logo" height="48" width="54" /><svg xmlns="http://www.w3.org/2000/svg" version="1.1" height="15" viewBox="0 0 190 23" role="img" class="gh-wordmark u-margin-s-left" aria-labelledby="gh-wm-science-direct" focusable="false" aria-hidden="true" alt="ScienceDirect Wordmark"><title id="gh-wm-science-direct">ScienceDirect</title><g><path fill="#EB6500" d="M3.81 6.9c0-1.48 0.86-3.04 3.7-3.04 1.42 0 3.1 0.43 4.65 1.32l0.13-2.64c-1.42-0.63-2.97-0.96-4.78-0.96 -4.62 0-6.6 2.44-6.6 5.45 0 5.61 8.78 6.14 8.78 9.93 0 1.48-1.15 3.04-3.86 3.04 -1.72 0-3.4-0.56-4.72-1.39l-0.36 2.64c1.55 0.76 3.57 1.06 5.15 1.06 4.26 0 6.7-2.48 6.7-5.51C12.59 11.49 3.81 10.76 3.81 6.9M20.27 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.15-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.68 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.14 0-4.55-1.71-4.55-5.91C17.93 10.2 20.01 9.18 20.27 9.01"></path><rect x="29.42" y="6.97" fill="#EB6500" width="2.54" height="14.95"></rect><path fill="#EB6500" d="M30.67 0.7c-0.92 0-1.65 0.92-1.65 1.81 0 0.93 0.76 1.85 1.65 1.85 0.89 0 1.68-0.96 1.68-1.88C32.35 1.55 31.56 0.7 30.67 0.7M48.06 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.88-1.95-4.88-5.51v-0.49H48.06M39.91 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C38.56 10.27 39.71 9.37 39.91 9.18zM58.82 6.57c-2.24 0-3.63 1.12-4.85 2.61l-0.4-2.21h-2.34l0.13 1.19c0.1 0.76 0.13 1.78 0.13 2.97v10.79h2.54V11.88c0.69-0.96 2.15-2.48 2.48-2.64 0.23-0.13 1.29-0.4 2.08-0.4 2.28 0 2.48 1.15 2.54 3.43 0.03 1.19 0.03 3.17 0.03 3.17 0.03 3-0.1 6.47-0.1 6.47h2.54c0 0 0.07-4.49 0.07-6.96 0-1.48 0.03-2.97-0.1-4.46C63.31 7.43 61.49 6.57 58.82 6.57M72.12 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.15-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.68 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.15 0-4.55-1.71-4.55-5.91C69.77 10.2 71.85 9.18 72.12 9.01M92.74 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.88-1.95-4.88-5.51v-0.49H92.74M84.59 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C83.24 10.27 84.39 9.37 84.59 9.18zM103.9 1.98h-7.13v19.93h6.83c7.26 0 9.77-5.68 9.77-10.03C113.37 7.33 110.93 1.98 103.9 1.98M103.14 19.8h-3.76V4.1h4.09c5.38 0 6.96 4.39 6.96 7.79C110.43 16.87 108.19 19.8 103.14 19.8zM118.38 0.7c-0.92 0-1.65 0.92-1.65 1.81 0 0.93 0.76 1.85 1.65 1.85 0.89 0 1.69-0.96 1.69-1.88C120.07 1.55 119.28 0.7 118.38 0.7"></path><rect x="117.13" y="6.97" fill="#EB6500" width="2.54" height="14.95"></rect><path fill="#EB6500" d="M130.2 6.6c-1.62 0-2.87 1.45-3.4 2.74l-0.43-2.37h-2.34l0.13 1.19c0.1 0.76 0.13 1.75 0.13 2.9v10.86h2.54v-9.51c0.53-1.29 1.72-3.7 3.17-3.7 0.96 0 1.06 0.99 1.06 1.22l2.08-0.6V9.18c0-0.03-0.03-0.17-0.06-0.4C132.8 7.36 131.91 6.6 130.2 6.6M145.87 14.13c0-5.18-1.42-7.56-6.01-7.56 -3.86 0-6.67 2.77-6.67 7.92 0 4.92 2.97 7.82 6.73 7.82 2.81 0 4.36-0.63 5.68-1.42l-0.2-2.31c-0.89 0.79-2.94 1.55-4.69 1.55 -3.14 0-4.89-1.95-4.89-5.51v-0.49H145.87M137.72 9.18c0.17-0.17 1.29-0.46 1.98-0.46 2.48 0 3.76 0.53 3.86 3.43h-7.46C136.37 10.27 137.52 9.37 137.72 9.18zM153.23 9.01c0.23-0.13 0.69-0.26 1.72-0.26 1.72 0 2.41 0.3 2.41 1.58h2.38c0-0.36 0-0.79-0.03-1.09 -0.23-1.98-2.14-2.67-4.88-2.67 -3 0-6.7 2.31-6.7 7.76 0 5.22 2.77 7.99 6.63 7.99 1.69 0 3.47-0.36 4.95-1.39l-0.2-2.31c-0.99 0.82-2.84 1.52-4.06 1.52 -2.15 0-4.55-1.71-4.55-5.91C150.89 10.2 152.97 9.18 153.23 9.01M170 19.44c-0.92 0.36-1.72 0.69-2.51 0.69 -1.16 0-1.58-0.66-1.58-2.34V8.95h3.93V6.97h-3.93V2.97h-2.48v3.99h-2.71v1.98h2.71v9.67c0 2.64 1.39 3.73 3.33 3.73 1.15 0 2.54-0.39 3.43-0.79L170 19.44M173.68 5.96c-1.09 0-2-0.87-2-1.97 0-1.1 0.91-1.97 2-1.97s1.98 0.88 1.98 1.98C175.66 5.09 174.77 5.96 173.68 5.96zM173.67 2.46c-0.85 0-1.54 0.67-1.54 1.52 0 0.85 0.69 1.54 1.54 1.54 0.85 0 1.54-0.69 1.54-1.54C175.21 3.13 174.52 2.46 173.67 2.46zM174.17 5.05c-0.09-0.09-0.17-0.19-0.25-0.3l-0.41-0.56h-0.16v0.87h-0.39V2.92c0.22-0.01 0.47-0.03 0.66-0.03 0.41 0 0.82 0.16 0.82 0.64 0 0.29-0.21 0.55-0.49 0.63 0.23 0.32 0.45 0.62 0.73 0.91H174.17zM173.56 3.22l-0.22 0.01v0.63h0.22c0.26 0 0.43-0.05 0.43-0.34C174 3.28 173.83 3.21 173.56 3.22z"></path></g></svg></a><div class="gh-nav-cnt u-hide-from-print"><div class="gh-nav-links-container gh-nav-links-container-h u-hide-from-print gh-nav-content-container"><nav aria-label="links" class="gh-nav gh-nav-links gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-nav-item gh-move-to-spine"><a class="anchor gh-nav-action anchor-default" href="/browse/journals-and-books" data-aa-region="header" data-aa-name="Journals &amp; Books"><span class="anchor-text">Journals &amp; Books</span></a></li></ul></nav><nav aria-label="utilities" class="gh-nav gh-nav-utilities gh-nav-h"><ul class="gh-nav-list u-list-reset"><li class="gh-move-to-spine gh-help-button gh-help-icon gh-nav-item"><div class="popover" id="gh-help-icon-popover"><div id="popover-trigger-gh-help-icon-popover"><input type="hidden" /><button class="button-link gh-nav-help-icon gh-icon-btn button-link-primary button-link-icon-only" type="button" aria-expanded="false" aria-label="ScienceDirect Support Center links"><svg focusable="false" viewBox="0 0 114 128" aria-hidden="true" alt="ScienceDirect help page" width="21.375" height="24" class="icon icon-help gh-icon"><path d="m57 8c-14.7 0-28.5 5.72-38.9 16.1-10.38 10.4-16.1 24.22-16.1 38.9 0 30.32 24.68 55 55 55 14.68 0 28.5-5.72 38.88-16.1 10.4-10.4 16.12-24.2 16.12-38.9 0-30.32-24.68-55-55-55zm0 1e1c24.82 0 45 20.18 45 45 0 12.02-4.68 23.32-13.18 31.82s-19.8 13.18-31.82 13.18c-24.82 0-45-20.18-45-45 0-12.02 4.68-23.32 13.18-31.82s19.8-13.18 31.82-13.18zm-0.14 14c-11.55 0.26-16.86 8.43-16.86 18v2h1e1v-2c0-4.22 2.22-9.66 8-9.24 5.5 0.4 6.32 5.14 5.78 8.14-1.1 6.16-11.78 9.5-11.78 20.5v6.6h1e1v-5.56c0-8.16 11.22-11.52 12-21.7 0.74-9.86-5.56-16.52-16-16.74-0.39-0.01-0.76-0.01-1.14 0zm-4.86 5e1v1e1h1e1v-1e1h-1e1z"></path></svg></button></div></div></li><li class="gh-search-toggle gh-nav-item search-button-link search-with-button-link"><a class="anchor button-link-primary gh-nav-action gh-icon-btn search-input-fallback-link anchor-default anchor-icon-only" href="/search" data-aa-button="search-in-header-opened-from-article" aria-label="Search ScienceDirect" role="button"><svg focusable="false" viewBox="0 0 100 128" aria-hidden="true" alt="Search" width="18.75" height="24" class="icon icon-search gh-icon"><path d="m19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6l-26.32-26.32c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96s-21.17 4.25-28.88 11.96c-7.72 7.71-11.97 17.97-11.97 28.88s4.25 21.17 11.97 28.88c7.71 7.71 17.97 11.96 28.88 11.96 9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg></a><a class="link-button link-button-small search-button-outline link-button-primary link-button-icon-right" href="/search" data-aa-button="search-in-header-opened-from-article" aria-label="Search ScienceDirect" role="button"><span class="link-button-text">Search</span><svg focusable="false" viewBox="0 0 100 128" aria-hidden="true" alt="Search" width="18.75" height="24" class="icon icon-search"><path d="m19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6l-26.32-26.32c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96s-21.17 4.25-28.88 11.96c-7.72 7.71-11.97 17.97-11.97 28.88s4.25 21.17 11.97 28.88c7.71 7.71 17.97 11.96 28.88 11.96 9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg></a></li></ul></nav></div></div><div class="gh-profile-container gh-move-to-spine u-hide-from-print"><a class="link-button link-button-secondary link-button-small u-margin-s-right link-button-icon-left" href="/user/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS0925231220311693&amp;from=globalheader" id="gh-myaccount-btn" data-aa-region="header" data-aa-name="personalsignin"><svg focusable="false" viewBox="0 0 106 128" aria-hidden="true" width="19.875" height="24" class="icon icon-person"><path d="m11.07 1.2e2l0.84-9.29c1.97-18.79 23.34-22.93 41.09-22.93 17.74 0 39.11 4.13 41.08 22.84l0.84 9.38h10.04l-0.93-10.34c-2.15-20.43-20.14-31.66-51.03-31.66s-48.89 11.22-51.05 31.73l-0.91 10.27h10.03m41.93-102.29c-9.72 0-18.24 8.69-18.24 18.59 0 13.67 7.84 23.98 18.24 23.98s18.24-10.31 18.24-23.98c0-9.9-8.52-18.59-18.24-18.59zm0 52.29c-15.96 0-28-14.48-28-33.67 0-15.36 12.82-28.33 28-28.33s28 12.97 28 28.33c0 19.19-12.04 33.67-28 33.67"></path></svg><span class="link-button-text">My Account</span></a><a class="link-button link-button-primary link-button-small link-button-icon-left" href="/user/institution/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS0925231220311693" id="gh-institutionalsignin-btn" data-aa-region="header" data-aa-name="institutionalsignin"><svg focusable="false" viewBox="0 0 106 128" aria-hidden="true" width="19.875" height="24" class="icon icon-institution"><path d="m84 98h1e1v1e1h-82v-1e1h1e1v-46h14v46h1e1v-46h14v46h1e1v-46h14v46zm-72-61.14l41-20.84 41 20.84v5.14h-82v-5.14zm92 15.14v-21.26l-51-25.94-51 25.94v21.26h1e1v36h-1e1v3e1h102v-3e1h-1e1v-36h1e1z"></path></svg><span class="link-button-text">Sign in</span></a></div><div id="gh-mobile-menu" class="mobile-menu u-hide-from-print"><div class="gh-hamburger u-fill-grey7 u-margin-m-left"><button class="button-link u-flex-center-ver button-link-primary button-link-icon-only" type="button" aria-label="Toggle mobile menu" aria-expanded="false"><svg class="gh-hamburger-svg-el gh-hamburger-closed" role="img" aria-hidden="true" height="18" width="40"><path d="M0 14h40v2H0zm0-7h40v2H0zm0-7h40v2H0z"></path></svg></button></div><div id="gh-overlay" class="mobile-menu-overlay u-overlay u-display-none" role="button" tabindex="-1"></div><div id="gh-drawer" aria-label="Mobile menu" class role="navigation"></div></div></div></header><div class="Article Preview" id="mathjax-container" role="main"><div class="accessbar-sticky"><div id="screen-reader-main-content"></div><div role="region" aria-label="Download options and search"><div class="accessbar"><div class="accessbar-label"></div><ul aria-label="PDF Options"><li class="accessbar-item-show-from-initial accessbar-item-show-from-xs accessbar-item-show-from-md RemoteAccess"><a class="link-button RemoteAccessButton accessbar-utility-component accessbar-utility-link link-button-primary link-button-icon-left" href="https://auth.elsevier.com/ShibAuth/institutionLogin?entityID=https%3A%2F%2Fidp.nottingham.edu.cn%2Fidp%2Fshibboleth&amp;appReturnURL=https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fabs%2Fpii%2FS0925231220311693%3Ffr%3DRR-2%26ref%3Dpdf_download%26rr%3D8851c74ebed560e3" aria-label="Access through University of Nottingham Ningbo, China"><svg focusable="false" viewBox="0 0 253.88 253.99" aria-label="Seamless access" width="10" height="20" role="img" class="icon icon-seamless-access inst-icon"><g><path d="M37.58,97.76h178.73c5.7,0,10.68-3.56,12.46-8.9c1.42-5.34-0.36-11.04-4.99-14.24l-89.37-64.09 c-4.63-3.2-10.68-3.2-14.95,0L30.11,74.61c-3.2,2.49-5.34,6.05-5.34,10.33C24.77,92.06,30.46,97.76,37.58,97.76z M126.95,36.87 l49.49,35.25H77.46L126.95,36.87z"></path><polygon points="109.45,185.4 109.85,127.82 80.25,113.55 80.25,199.67"></polygon><polygon points="174.19,199.26 174.19,114.37 144.99,128.64 144.99,186.21"></polygon><path d="M242.07,226.42c-0.01,0-0.03,0-0.04,0h-10.75v-10.74c0-3.71-3.01-6.72-6.72-6.72l-10.1,0v-86.21 c0-8.2-6.71-14.9-14.9-14.9c-8.2,0-14.9,6.71-14.9,14.9v86.21l-115.42-0.02v-86.19c0-8.2-6.71-14.9-14.9-14.9 c-8.2,0-14.9,6.71-14.9,14.9v86.18l-10.08,0c-3.71,0-6.72,3.01-6.72,6.72v10.74H11.86c-3.71,0-6.72,3.01-6.72,6.72v11.68h243.62 v-11.63C248.77,229.45,245.78,226.43,242.07,226.42z"></path></g></svg><span class="link-button-text"><span>Access through&nbsp;<strong>University of Nottingham â€¦</strong></span></span></a></li><li class="accessbar-item-hide-from-initial accessbar-item-hide-from-xs accessbar-item-show-from-md PurchasePDF"><a class="link-button accessbar-utility-component accessbar-utility-link link-button-anchor link-button-text-only" href="/getaccess/pii/S0925231220311693/purchase" target="_blank" aria-label="Purchase PDF" rel="noreferrer noopener"><span class="link-button-text"><span>Purchase PDF</span></span></a></li><li class="accessbar-item-hide-from-initial accessbar-item-hide-from-xs accessbar-item-show-from-md Divider"><span class="accessbar-divider"></span></li><li class="accessbar-item-hide-from-initial accessbar-item-hide-from-xs accessbar-item-show-from-md RemoteAccessOther"><a class="link-button accessbar-utility-component accessbar-utility-link link-button-anchor link-button-text-only" href="/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0925231220311693" aria-label="Access through another institution"><span class="link-button-text"><span>Access through another institution</span></span></a></li><li class="accessbar-item-show-from-initial accessbar-item-show-from-xs accessbar-item-hide-from-md OverflowPopover"><div class="popover accessbar-overflow-popover" id="OverflowPopoverAnchor"><div id="popover-trigger-OverflowPopoverAnchor"><button type="button" class="button accessbar-utility-component accessbar-utility-button button-anchor button-icon-right" aria-disabled="false" aria-label="Other access options"><span class="button-text"><span>Other access options</span></span><svg focusable="false" viewBox="0 0 92 128" height="20" width="17.25" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div></div></li></ul><form class="QuickSearch" action="/search#submit" method="get" aria-label="form"><div class="search-input"><div class="search-input-container search-input-container-no-label"><label class="search-input-label u-hide-visually" for="article-quick-search">Search ScienceDirect</label><input type="search" id="article-quick-search" name="qs" value class="search-input-field" aria-label="Search ScienceDirect" aria-describedby="article-quick-search-description-message" placeholder="Search ScienceDirect" /></div><div class="search-input-message-container"><div aria-live="polite" class="search-input-validation-error"></div><div id="article-quick-search-description-message"></div></div></div><button type="submit" class="button small u-margin-xs-left button-primary button-icon-only" aria-disabled="false" aria-label="Submit search"><svg focusable="false" viewBox="0 0 100 128" height="20" width="18.75" class="icon icon-search"><path d="m19.22 76.91c-5.84-5.84-9.05-13.6-9.05-21.85s3.21-16.01 9.05-21.85c5.84-5.83 13.59-9.05 21.85-9.05 8.25 0 16.01 3.22 21.84 9.05 5.84 5.84 9.05 13.6 9.05 21.85s-3.21 16.01-9.05 21.85c-5.83 5.83-13.59 9.05-21.84 9.05-8.26 0-16.01-3.22-21.85-9.05zm80.33 29.6l-26.32-26.32c5.61-7.15 8.68-15.9 8.68-25.13 0-10.91-4.25-21.17-11.96-28.88-7.72-7.71-17.97-11.96-28.88-11.96s-21.17 4.25-28.88 11.96c-7.72 7.71-11.97 17.97-11.97 28.88s4.25 21.17 11.97 28.88c7.71 7.71 17.97 11.96 28.88 11.96 9.23 0 17.98-3.07 25.13-8.68l26.32 26.32 7.03-7.03"></path></svg></button><input type="hidden" name="origin" value="article" /><input type="hidden" name="zone" value="qSearch" /></form></div></div></div><div class="article-wrapper u-padding-s-top grid row"><div role="navigation" aria-label="Table of Contents" class="preview-sidebar u-show-from-lg col-lg-6"><div class="PreviewTableOfContents text-s"><h2 class="u-h4 preview-table-of-contents-title">Article preview</h2><ul class="preview-table-of-contents-list"><li id="preview-section-abstract-item" class><a class="anchor anchor-default" href="#preview-section-abstract"><span class="anchor-text">Abstract</span></a></li><li id="preview-section-introduction-item" class><a class="anchor anchor-default" href="#preview-section-introduction"><span class="anchor-text">Introduction</span></a></li><li id="preview-section-snippets-item" class><a class="anchor anchor-default" href="#preview-section-snippets"><span class="anchor-text">Section snippets</span></a></li><li id="preview-section-references-item" class><a class="anchor anchor-default" href="#preview-section-references"><span class="anchor-text">References (132)</span></a></li><li id="preview-section-cited-by-item" class><a class="anchor anchor-default" href="#preview-section-cited-by"><span class="anchor-text">Cited by (1304)</span></a></li></ul></div></div><article class="col-lg-12 col-md-16 pad-left pad-right" lang="en"><div class="Publication" id="publication"><div class="publication-brand u-show-from-sm"><a class="anchor anchor-default" href="/journal/neurocomputing" title="Go to Neurocomputing on ScienceDirect"><span class="anchor-text"><img class="publication-brand-image" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/402a3f5c247cf997723622b5a8bc17cc2004f90c/image/elsevier-non-solus.png" alt="Elsevier" /></span></a></div><div class="publication-volume u-text-center"><h2 class="publication-title u-h3" id="publication-title"><a class="anchor publication-title-link anchor-navigation" href="/journal/neurocomputing" title="Go to Neurocomputing on ScienceDirect"><span class="anchor-text">Neurocomputing</span></a></h2><div class="text-xs"><a class="anchor anchor-default" href="/journal/neurocomputing/vol/415/suppl/C" title="Go to table of contents for this volume/issue"><span class="anchor-text">Volume 415</span></a>, <!-- -->20 November 2020<!-- -->, Pages 295-316</div></div><div class="publication-cover u-show-from-sm"><a class="anchor anchor-default" href="/journal/neurocomputing/vol/415/suppl/C"><span class="anchor-text"><img class="publication-cover-image" src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220X00385-cov150h.gif" alt="Neurocomputing" /></span></a></div></div><div class="PageDivider"></div><h1 id="screen-reader-main-title" class="Head u-font-serif u-h2 u-margin-s-ver"><span class="title-text">On hyperparameter optimization of machine learning algorithms: Theory and practice</span></h1><div class="Banner" id="banner"><div class="wrapper truncated"><div class="AuthorGroups text-s"><div class="author-group" id="author-group"><span class="sr-only">Author links open overlay panel</span><button class="button-link button-link-primary" type="button" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au005"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Li</span> <span class="text surname">Yang</span></span><svg focusable="false" viewBox="0 0 102 128" title="Author email or social media contact details icon" width="20" height="20" class="icon icon-envelope react-xocs-author-icon"><path d="m55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0l-31.32-23.2h69.54l-31.32 23.19zm-55.8-24.78l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-0.98 9.42-2.93l40.24-30.7v-10.34h-102zm92 56.48l-18.06-22.74-8.04 5.95 17.38 21.89h-64.54l18.38-23.12-8.04-5.96-19.08 24.02v-37.58l-1e1 -8.46v61.1h102v-59.18l-1e1 8.46v35.62"></path></svg></span></button>, <button class="button-link button-link-primary" type="button" data-sd-ui-side-panel-opener="true" data-xocs-content-type="author" data-xocs-content-id="au010"><span class="button-link-text"><span class="react-xocs-alternative-link"><span class="given-name">Abdallah</span> <span class="text surname">Shami</span></span><svg focusable="false" viewBox="0 0 102 128" title="Author email or social media contact details icon" width="20" height="20" class="icon icon-envelope react-xocs-author-icon"><path d="m55.8 57.2c-1.78 1.31-5.14 1.31-6.9 0l-31.32-23.2h69.54l-31.32 23.19zm-55.8-24.78l42.94 32.62c2.64 1.95 6.02 2.93 9.4 2.93s6.78-0.98 9.42-2.93l40.24-30.7v-10.34h-102zm92 56.48l-18.06-22.74-8.04 5.95 17.38 21.89h-64.54l18.38-23.12-8.04-5.96-19.08 24.02v-37.58l-1e1 -8.46v61.1h102v-59.18l-1e1 8.46v35.62"></path></svg></span></button></div></div></div><button class="button-link button-link-secondary u-margin-s-ver text-s show-more-button button-link-icon-right" type="button" id="show-more-btn" data-aa-button="icon-expand"><span class="button-link-text">Show more</span><svg focusable="false" viewBox="0 0 92 128" height="20" width="17.25" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button><div class="banner-options u-padding-xs-bottom text-s"><button class="button-link AddToMendeley u-margin-s-right u-show-inline-from-md button-link-primary button-link-icon-left" type="button"><svg focusable="false" viewBox="0 0 86 128" height="16" width="16" class="icon icon-plus"><path d="m48 58v-38h-1e1v38h-38v1e1h38v38h1e1v-38h38v-1e1z"></path></svg><span class="button-link-text">Add to Mendeley</span></button><div class="Social u-display-inline-block" id="social"><div class="popover social-popover" id="social-popover"><div id="popover-trigger-social-popover"><button class="button-link u-margin-s-right button-link-primary button-link-icon-left" type="button" aria-expanded="false" aria-haspopup="true"><svg focusable="false" viewBox="0 0 128 128" height="16" width="16" class="icon icon-share"><path d="m9e1 112c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zm-66-36c-6.62 0-12-5.38-12-12s5.38-12 12-12 12 5.38 12 12-5.38 12-12 12zm66-6e1c6.62 0 12 5.38 12 12s-5.38 12-12 12-12-5.38-12-12 5.38-12 12-12zm0 62c-6.56 0-12.44 2.9-16.48 7.48l-28.42-15.28c0.58-1.98 0.9-4.04 0.9-6.2s-0.32-4.22-0.9-6.2l28.42-15.28c4.04 4.58 9.92 7.48 16.48 7.48 12.14 0 22-9.86 22-22s-9.86-22-22-22-22 9.86-22 22c0 1.98 0.28 3.9 0.78 5.72l-28.64 15.38c-4.02-4.34-9.76-7.1-16.14-7.1-12.14 0-22 9.86-22 22s9.86 22 22 22c6.38 0 12.12-2.76 16.14-7.12l28.64 15.38c-0.5 1.84-0.78 3.76-0.78 5.74 0 12.14 9.86 22 22 22s22-9.86 22-22-9.86-22-22-22z"></path></svg><span class="button-link-text">Share</span></button></div></div></div><div class="ExportCitation u-display-inline-block" id="export-citation"><div class="popover export-citation-popover" id="export-citation-popover"><div id="popover-trigger-export-citation-popover"><button class="button-link button-link-primary button-link-icon-left" type="button" aria-expanded="false" aria-haspopup="true"><svg focusable="false" viewBox="0 0 106 128" height="16" width="16" class="icon icon-cited-by-66"><path xmlns="http://www.w3.org/2000/svg" d="m2 58.78v47.22h44v-42h-34v-5.22c0-18.5 17.08-26.78 34-26.78v-1e1c-25.9 0-44 15.12-44 36.78zm1e2 -26.78v-1e1c-25.9 0-44 15.12-44 36.78v47.22h44v-42h-34v-5.22c0-18.5 17.08-26.78 34-26.78z"></path></svg><span class="button-link-text">Cite</span></button></div></div></div></div></div><div class="ArticleIdentifierLinks u-margin-xs-bottom text-xs" id="article-identifier-links"><a class="anchor doi anchor-default" href="https://doi.org/10.1016/j.neucom.2020.07.061" target="_blank" rel="noreferrer noopener" aria-label="Persistent link using digital object identifier" title="Persistent link using digital object identifier"><span class="anchor-text">https://doi.org/10.1016/j.neucom.2020.07.061</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em" class="icon icon-arrow-up-right arrow-external-link"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a><a class="anchor rights-and-content anchor-default" href="https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&amp;contentID=S0925231220311693&amp;orderBeanReset=true" target="_blank" rel="noreferrer noopener"><span class="anchor-text">Get rights and content</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em" class="icon icon-arrow-up-right arrow-external-link"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a></div><section class="ReferencedArticles"></section><section class="ReferencedArticles"></section><div id="preview-section-abstract"><div class="PageDivider"></div><div class="Abstracts u-font-serif text-s" id="abstracts"><div class="abstract author" id="ab005" lang="en"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Abstract</h2><div id="as005"><p id="sp005"><span><a href="/topics/neuroscience/machine-learning-algorithm" title="Learn more about Machine learning algorithms from ScienceDirect&#x27;s AI-generated Topic Pages" class="topic-link">Machine learning algorithms</a> have been used widely in various applications and areas. To fit a </span><a href="/topics/computer-science/machine-learning" title="Learn more about machine learning from ScienceDirect&#x27;s AI-generated Topic Pages" class="topic-link">machine learning</a><span> model into different problems, its hyper-parameters must be tuned. Selecting the best hyper-parameter configuration for machine learning models has a direct impact on the modelâ€™s performance. It often requires deep knowledge of machine learning algorithms and appropriate hyper-parameter optimization techniques. Although several automatic optimization techniques exist, they have different strengths and drawbacks when applied to different types of problems. In this paper, optimizing the hyper-parameters of common machine learning models is studied. We introduce several state-of-the-art optimization techniques and discuss how to apply them to machine learning algorithms. Many available libraries and frameworks developed for hyper-parameter <a href="/topics/computer-science/optimization-problem" title="Learn more about optimization problems from ScienceDirect&#x27;s AI-generated Topic Pages" class="topic-link">optimization problems</a> are provided, and some open challenges of hyper-parameter optimization research are also discussed in this paper. Moreover, experiments are conducted on benchmark datasets to compare the performance of different optimization methods and provide practical examples of hyper-parameter optimization. This survey paper will help industrial users, data analysts, and researchers to better develop machine learning models by identifying the proper hyper-parameter configurations effectively.</span></p></div></div></div></div><div id="preview-section-introduction"><div class="PageDivider"></div><div class="Introduction u-font-serif text-s u-margin-l-ver"><h2 class="u-h4 u-margin-s-bottom">Introduction</h2><section id="s0005"><p id="p0005">Machine learning (ML) algorithms have been widely used in many applications domains, including advertising, recommendation systems, computer vision, natural language processing, and user behavior analytics [1]. This is because they are generic and demonstrate high performance in data analytics problems. Different ML algorithms are suitable for different types of problems or datasets [2]. In general, building an effective machine learning model is a complex and time-consuming process that involves determining the appropriate algorithm and obtaining an optimal model architecture by tuning its hyper-parameters (HPs) [3]. Two types of parameters exist in machine learning models: one that can be initialized and updated through the data learning process (<em>e.g.</em>, the weights of neurons in neural networks), named model parameters; while the other, named hyper-parameters, cannot be directly estimated from data learning and must be set before training a ML model because they define the model architecture [4]. Hyper-parameters are the parameters that are used to either configure a ML model (<em>e.g.</em>, the penalty parameter <em>C</em> in a support vector machine, and the learning rate to train a neural network) or to specify the algorithm used to minimize the loss function (<em>e.g.</em>, the activation function and optimizer types in a neural network, and the kernel type in a support vector machine) [5].</p><p id="p0010">To build an optimal ML model, a range of possibilities must be explored. The process of designing the ideal model architecture with an optimal hyper-parameter configuration is named hyper-parameter tuning. Tuning hyper-parameters is considered a key component of building an effective ML model, especially for tree-based ML models and deep neural networks, which have many hyper-parameters [6]. Hyper-parameter tuning process is different among different ML algorithms due to their different types of hyper-parameters, including categorical, discrete, and continuous hyper-parameters [7]. Manual testing is a traditional way to tune hyper-parameters and is still prevalent in graduate student research, although it requires a deep understanding of the used ML algorithms and their hyper-parameter value settings [8]. However, manual tuning is ineffective for many problems due to certain factors, including a large number of hyper-parameters, complex models, time-consuming model evaluations, and non-linear hyper-parameter interactions. These factors have inspired increased research in techniques for automatic optimization of hyper-parameters; so-called hyper-parameter optimization (HPO) [9]. The main aim of HPO is to automate hyper-parameter tuning process and make it possible for users to apply machine learning models to practical problems effectively [3]. The optimal model architecture of a ML model is expected to be obtained after a HPO process. Some important reasons for applying HPO techniques to ML models are as follows [6]:<ul class="list"><li class="react-xocs-list-item"><span class="list-label">1.</span><span><p id="p1055">It reduces the human effort required, since many ML developers spend considerable time tuning the hyper-parameters, especially for large datasets or complex ML algorithms with a large number of hyper-parameters.</p></span></li><li class="react-xocs-list-item"><span class="list-label">2.</span><span><p id="p1060">It improves the performance of ML models. Many ML hyper-parameters have different optimums to achieve best performance in different datasets or problems.</p></span></li><li class="react-xocs-list-item"><span class="list-label">3.</span><span><p id="p1065">It makes the models and research more reproducible. Only when the same level of hyper-parameter tuning process is implemented can different ML algorithms be compared fairly; hence, using a same HPO method on different ML algorithms also helps to determine the most suitable ML model for a specific problem.</p></span></li></ul></p><p id="p0015">It is crucial to select an appropriate optimization technique to detect optimal hyper-parameters. Traditional optimization techniques may be unsuitable for HPO problems, since many HPO problems are non-convex or non-differentiable optimization problems, and may result in a local instead of a global optimum [10]. Gradient descent-based methods are a common type of traditional optimization algorithm that can be used to tune continuous hyper-parameters by calculating their gradients [11]. For example, the learning rate in a neural network can be optimized by a gradient-based method.</p><p id="p0020">Compared with traditional optimization methods like gradient descent, many other optimization techniques are more suitable for HPO problems, including decision-theoretic approaches, Bayesian optimization models, multi-fidelity optimization techniques, and metaheuristics algorithms [7]. Apart from detecting continuous hyper-parameters, many of these algorithms also have the capacity to effectively identify discrete, categorical, and conditional hyper-parameters.</p><p id="p0025">Decision-theoretic methods are based on the concept of defining a hyper-parameter search space and then detecting the hyper-parameter combinations in the search space, ultimately selecting the best-performing hyper-parameter combination. Grid search (GS) [12] is a decision-theoretic approach that exhaustively searches the optimal configuration in a fixed domain of hyper-parameters. Random search (RS) [13] is another decision-theoretic method that randomly selects hyper-parameter combinations in the search space, given limited execution time and resources. In GS and RS, each hyper-parameter configuration is treated independently.</p><p id="p0030">Unlike GS and RS, Bayesian optimization (BO) [14] models determine the next hyper-parameter value based on the previous results of tested hyper-parameter values, which avoids many unnecessary evaluations; thus, BO can detect the optimal hyper-parameter combination within fewer iterations than GS and RS. To be applied to different problems, BO can model the distribution of the objective function using different models as the surrogate function, including Gaussian process (GP), random forest (RF), and tree-structured Parzen estimators (TPE) models [15]. BO-RF and BO-TPE can retain the conditionality of variables [15]. Thus, they can be used to optimize conditional hyper-parameters, like the kernel type and the penalty parameter <em>C</em> in a support vector machine (SVM). However, since BO models work sequentially to balance the exploration of unexplored areas and the exploitation of currently-tested regions, it is difficult to parallelize them.</p><p id="p0035">Training a ML model often takes considerable time and space. Multi-fidelity optimization algorithms are developed to tackle problems with limited resources, and the most common ones being bandit-based algorithms. Hyperband [16] is a popular bandit-based optimization technique that can be considered an improved version of RS. It generates small versions of datasets and allocates a same budget to each hyper-parameter combination. In each iteration of Hyperband, poorly-performing hyper-parameter configurations are eliminated to save time and resources.</p><p id="p0040">Metaheuristic algorithms are a set of techniques used to solve complex, large search space and non-convex optimization problems to which HPO problems belong [17]. Among all metaheuristic methods, genetic algorithm (GA) [18] and particle swarm optimization (PSO) [19] are the two most prevalent metaheuristic algorithms used for HPO problems. Genetic algorithms detect well-performing hyper-parameter combinations in each generation, and pass them to the next generation until the best-performing combination is identified. In PSO algorithms, each particle communicates with other particles to detect and update the current global optimum in each iteration until the final optimum is detected. Metaheuristics can efficiently explore the search space to detect optimal or near-optimal solutions. Hence, they are particularly suitable for the HPO problems with large configuration space due to their high efficiency. For instance, they can be used in deep neural networks (DNNs) which have a large configuration space with multiple hyper-parameters, including the activation and optimizer types, the learning rate, drop-out rate, etc.</p><p id="p0045">Although using HPO algorithms to tune the hyper-parameters of ML models greatly improves the model performance, certain other aspects, like their computational complexity, still have much room for improvement. On the other hand, since different HPO models have their own advantages and suitable problems, overviewing them is necessary for proper optimization algorithm selection in terms of different types of ML models and problems.</p><p id="p0050">This paper makes the following contributions:<ul class="list"><li class="react-xocs-list-item"><span class="list-label">1.</span><span><p id="p1070">It reviews common ML algorithms and their important hyper-parameters.</p></span></li><li class="react-xocs-list-item"><span class="list-label">2.</span><span><p id="p1075">It analyzes common HPO techniques, including their benefits and drawbacks, to help apply them to different ML models by appropriate algorithm selection in practical problems.</p></span></li><li class="react-xocs-list-item"><span class="list-label">3.</span><span><p id="p1080">It surveys common HPO libraries and frameworks for practical use.</p></span></li><li class="react-xocs-list-item"><span class="list-label">4.</span><span><p id="p1085">It discusses the open challenges and research directions of the HPO research domain.</p></span></li></ul></p><p id="p0055">In this survey paper, we begin with a comprehensive introduction of the common optimization techniques used in ML hyper-parameter tuning problems. Section 2 introduces the main concepts of mathematical optimization and hyper-parameter optimization, as well as the general HPO process. In Section 3, we discuss the key hyper-parameters of common ML models that need to be tuned. Section 4 covers the various state-of-the-art optimization approaches that have been proposed for tackling HPO problems. In Section 5, we analyze different HPO methods and discuss how they can be applied to ML algorithms. In Section 6, we provide an introduction to various public libraries and frameworks that are developed to implement HPO. Section 7 presents and discusses the experimental results of using HPO on benchmark datasets for HPO method comparison and practical use case demonstration. In Section 8, we discuss several research directions and open challenges that should be considered to improve current HPO models or develop new HPO approaches. We conclude the paper in Section 9.</p></section></div></div><div id="preview-section-snippets"><div class="PageDivider"></div><div class="Snippets u-font-serif text-s"><h2 class="u-h4 u-margin-l-ver">Section snippets</h2><section><section id="s0010"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Mathematical optimization and hyper-parameter optimization problems</h2><p id="p0060">The key process of machine learning is to solve optimization problems. To build a ML model, its weight parameters are initialized and optimized by an optimization method until the objective function approaches a minimum value or the accuracy approaches a maximum value [20]. Similarly, hyper-parameter optimization methods aim to optimize the architecture of a ML model by detecting the optimal hyper-parameter configurations. In this section, the main concepts of mathematical optimization and</p></section></section><section><section id="s0025"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Hyper-parameters in machine learning models</h2><p id="p0155">To boost ML models by HPO, firstly, we need to find out what the key hyper-parameters are that people need to tune to fit the ML models into specific problems or datasets.</p><p id="p0160">In general, ML models can be classified as supervised and unsupervised learning algorithms, based on whether they are built to model labeled or unlabeled datasets [127]. Supervised learning algorithms are a set of machine learning algorithms that map input features to a target by training on labeled data, and mainly include</p></section></section><section><section id="s0085"><section id="s0090"><section id="s0095"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Babysitting</h2><p id="p0375">Babysitting, also called â€˜Trial and Errorâ€™ or grad student descent (GSD), is a basic hyper-parameter tuning method [8]. This method is implemented by 100% manual tuning and widely used by students and researchers. The workflow is simple: after building a ML model, a student tests many possible hyper-parameter values based on experience, guessing, or the analysis of previously-evaluated results; the process is repeated until this student runs out of time (often reaching a deadline) or is</p></section></section></section></section><section><section id="s0170"><section id="s0175"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Optimization techniques analysis</h2><p id="p0610">Grid search (GS) is a simple method, its major limitation being that it is time-consuming and impacted by the curse of dimensionality [79]. Thus, it is unsuitable for a large number of hyper-parameters. Moreover, GS is often not able to detect the global optimum of continuous parameters, since it requires a pre-defined, finite set of hyper-parameter values. It is also unrealistic for GS to be used to identify integer and continuous hyper-parameter optimums with limited time and resources.</p></section></section></section><section><section id="s0210"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Existing HPO frameworks</h2><p id="p0700">To tackle HPO problems, many open-source libraries exist to apply theory into practice and lower the threshold for ML developers. In this section, we provide a brief introduction to some popular open-source HPO libraries or frameworks mainly for Python programming. The principles behind the involved optimization algorithms are provided in Section 4.</p></section></section><section><section id="s0300"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Experiments</h2><p id="p0790">To summarize the content of Sections 3 Hyper-parameters in machine learning models, 4 Hyper-parameter optimization techniques, 5 Applying optimization techniques to machine learning algorithms, 6 Existing HPO frameworks, a comprehensive overview of applying hyper-parameter optimization techniques to ML models is shown in Table 2. It provides a summary of common ML algorithms, their hyper-parameters, suitable optimization methods, and available Python libraries; thus, data analysts and</p></section></section><section><section id="s0315"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Open issues, challenges, and future research directions</h2><p id="p0865">Although there have been many existing HPO algorithms and practical frameworks, some issues still need to be addressed, and several aspects in this domain could be improved. In this section, we discuss the open challenges, current research questions, and potential research directions in the future. They can be classified as model complexity challenges and model performance challenges, as summarized in Table 10.</p></section></section><section><section id="s0370"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">Conclusion</h2><p id="p0940">Machine learning has become the primary strategy for tackling data-related problems and has been widely used in various applications. To apply ML models to practical problems, their hyper-parameters need to be tuned to fit specific datasets. However, since the scale of produced data is greatly increased in real-life, and manually tuning hyper-parameters is extremely computationally expensive, it has become crucial to optimize hyper-parameters by an automatic process. In this survey paper, we</p></section></section><section><section id="s0380"><h2 class="section-title u-h4 u-margin-l-top u-margin-xs-bottom">CRediT authorship contribution statement</h2><p id="p0950"><strong>Li Yang:</strong> Conceptualization, Methodology, Software, Validation, Formal analysis, Investigation, Data curation, Writing - original draft, Visualization. <strong>Abdallah Shami:</strong> Conceptualization, Resources, Writing - review &amp; editing, Supervision, Project administration, Funding acquisition.</p></section></section><section><section id="coi005"><h2 id="st700" class="u-h4 u-margin-l-top u-margin-xs-bottom">Declaration of Competing Interest</h2><p id="p0945">The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.</p></section></section><section><div class="article-biography text-s article-biography-has-image" id="bg005"><div class="article-biography-image"></div><div class="article-biography-text"><p id="sp010"><strong>Li Yang</strong> received the B.E. degree in computer science from Wuhan University of Science and Technology, Wuhan, China in 2016 and the MASc degree in Engineering from University of Guelph, Guelph, Canada, 2018. Since 2018 he has been working toward the Ph.D. degree in the Department of Electrical and Computer Engineering, Western University, London, Canada. His research interests include cybersecurity, machine learning, data analytics, and intelligent transportation systems.</p></div></div></section></div></div><div class="related-content-links u-hide-from-md"><button type="button" class="button button-anchor" aria-disabled="false"><span class="button-text">Recommended articles</span></button></div><div class="Tail text-s"></div><div id="preview-section-references"><div class="paginatedReferences u-font-serif text-s"><div class="PageDivider"></div><header><h2 class="u-h4 u-margin-l-ver"><span>References</span><span> (132)</span></h2></header><ul><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>L.E. </span>Melkumova</span><em> et al.</em></span><h3><a class="anchor title anchor-default" href="/science/article/pii/S1877705817341474" target="_self"><span class="anchor-text">Comparing ridge and LASSO estimators for data analysis</span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Procedia Eng.</h3></div><div class="series">(2017)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>Y. </span>Xia</span><em> et al.</em></span><h3><a class="anchor title anchor-default" href="/science/article/pii/S0957417417301008" target="_self"><span class="anchor-text">A boosted decision tree approach using Bayesian hyper-parameter optimization for credit scoring</span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Expert Syst. Appl.</h3></div><div class="series">(2017)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>D. </span>Han</span><em> et al.</em></span><h3><a class="anchor title anchor-default" href="/science/article/pii/S0957417417307844" target="_self"><span class="anchor-text">A new image classification method using CNN transfer learning and web data augmentation</span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Expert Syst. Appl.</h3></div><div class="series">(2018)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>C. </span>Di Francescomarino</span><em> et al.</em></span><h3><a class="anchor title anchor-default" href="/science/article/pii/S0306437916305695" target="_self"><span class="anchor-text">Genetic algorithms for hyperparameter optimization in predictive business process monitoring</span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Inf. Syst.</h3></div><div class="series">(2018)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>P. </span>Howland</span><em> et al.</em></span><h3><a class="anchor title anchor-default" href="/science/article/pii/S0031320305002670" target="_self"><span class="anchor-text">Solving the small sample size problem in face recognition using generalized discriminant analysis</span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Pattern Recognit.</h3></div><div class="series">(2006)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>S. </span>Rahnamayan</span><em> et al.</em></span><h3><a class="anchor title anchor-default" href="/science/article/pii/S0898122107001344" target="_self"><span class="anchor-text">A novel population initialization method for accelerating evolutionary algorithms</span></a></h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Comput. Math. Appl.</h3></div><div class="series">(2007)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>M.I. </span>Jordan</span><em> et al.</em></span><h3 class="title">Machine learning: trends, perspectives, and prospects</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Science</h3></div><div class="series">(2015)</div></span></li><li class="bib-reference u-margin-s-bottom"><span>M.-A. ZÃ¶ller, M.F. Huber, Benchmark and Survey of Automated Machine Learning Frameworks, arXiv preprint...</span></li><li class="bib-reference u-margin-s-bottom"><span>R.E. Shawi, M. Maher, S. Sakr, Automated machine learning: State-of-the-art and open challenges, arXiv preprint...</span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>M. </span>Kuhn</span><em> et al.</em></span><h3 class="title">Applied Predictive Modeling</h3><span class="host u-clr-grey6 u-font-sans"><div class="series">(2013)</div></span></li></ul><div class="u-display-none"><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>G.I. </span>Diaz</span><em> et al.</em></span><h3 class="title">An effective algorithm for hyperparameter optimization of neural networks</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">IBM J. Res. Dev.</h3></div><div class="series">(2017)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="host u-clr-grey6 u-font-sans"></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>N. </span>Decastro-GarcÃ­a</span><em> et al.</em></span><h3 class="title">Effect of the sampling of a dataset in the hyperparameter optimization phase over the efficiency of a machine learning algorithm</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Complexity</h3></div><div class="series">(2019 (2019).)</div></span></li><li class="bib-reference u-margin-s-bottom"><span>S. Abreu, Automated Architecture Design for Deep Neural Networks, arXiv preprint arXiv:1908.10714, (2019)....</span></li><li class="bib-reference u-margin-s-bottom"><span>O.S. Steinholtz, A Comparative Study of Black-box Optimization Algorithms for Tuning of Hyper-parameters in Deep Neural...</span></li><li class="bib-reference u-margin-s-bottom"><span class="author u-font-sans"><span>G. </span>Luo</span><h3 class="title">A review of automatic selection methods for machine learning algorithms and hyper-parameter values</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Netw. Model. Anal. Heal. Inf. Bioinf.</h3></div><div class="series">(2016)</div></span></li><li class="bib-reference u-margin-s-bottom"><span>D. Maclaurin, D. Duvenaud, R.P. Adams, Gradient-based Hyperparameter Optimization through Reversible Learning, arXiv...</span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>J. </span>Bergstra</span><em> et al.</em></span><h3 class="title">Algorithms for hyper-parameter optimization</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Proc. Adv. Neural Inf. Process. Syst.</h3></div><div class="series">(2011)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>B. </span>James</span><em> et al.</em></span><h3 class="title">Random search for hyper-parameter optimization</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">J. Mach. Learn. Res.</h3></div><div class="series">(2012)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>K. </span>Eggensperger</span><em> et al.</em></span><h3 class="title">Towards an empirical foundation for assessing Bayesian optimization of hyperparameters</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">BayesOpt Work</h3></div><div class="series">(2013)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>K. </span>Eggensperger</span><em> et al.</em></span><h3 class="title">Efficient benchmarking of hyperparameter optimizers via surrogates</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Proc. Natl. Conf. Artif. Intell.</h3></div><div class="series">(2015)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>L. </span>Li</span><em> et al.</em></span><h3 class="title">Hyperband: a novel bandit-based approach to hyperparameter optimization</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">J. Mach. Learn. Res.</h3></div><div class="series">(2012)</div></span></li><li class="bib-reference u-margin-s-bottom"><span>Q. Yao, et al., Taking Human out of Learning Applications: A Survey on Automated Machine Learning, arXiv preprint...</span></li><li class="bib-reference u-margin-s-bottom"><span>S. Lessmann, R. Stahlbock, S.F. Crone, Optimizing hyperparameters of support vector machines by genetic algorithms,...</span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>P.R. </span>Lorenzo</span><em> et al.</em></span><h3 class="title">Particle swarm optimization for hyper-parameter selection in deep neural networks</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Proc. ACM Int. Conf. Genet. Evol. Comput.</h3></div><div class="series">(2017)</div></span></li><li class="bib-reference u-margin-s-bottom"><span>S. Sun, Z. Cao, H. Zhu, J. Zhao, A Survey of Optimization Methods from a Machine Learning Perspective, arXiv preprint...</span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>T.M.S. </span>Bradley</span><em> et al.</em></span><h3 class="title">Applied Mathematical Programming</h3><span class="host u-clr-grey6 u-font-sans"><div class="series">(1977)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="author u-font-sans"><span>S. </span>Bubeck</span><h3 class="title">Convex optimization: algorithms and complexity</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Found. Trends Mach. Learn.</h3></div><div class="series">(2015)</div></span></li><li class="bib-reference u-margin-s-bottom"><span>B. Shahriari, A. Bouchard-CÃ´tÃ©, N. de Freitas, Unbounded Bayesian optimization via regularization, Proc. Artif. Intell....</span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>G.I. </span>Diaz</span><em> et al.</em></span><h3 class="title">An effective algorithm for hyperparameter optimization of neural networks</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">IBM J. Res. Dev.</h3></div><div class="series">(2017)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>C. </span>Gambella</span><em> et al.</em></span><h3 class="title">Optimization Models for Machine Learning: A Survey, arXiv preprint arXiv:1901.05331</h3><span class="host u-clr-grey6 u-font-sans"><div class="series">(2019)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>E.R. </span>Sparks</span><em> et al.</em></span><h3 class="title">Automating model search for large scale machine learning</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Proc. 6th ACM Symp. Cloud Comput.</h3></div><div class="series">(2015)</div></span></li><li class="bib-reference u-margin-s-bottom"><span>J. Nocedal, S. Wright, Numerical Optimization, 2006, Springer-Verlag, ISBN:...</span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>R. </span>Caruana</span><em> et al.</em></span><h3 class="title">An empirical comparison of supervised learning algorithms</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">ACM Int. Conf. Proc. Ser.</h3></div><div class="series">(2006)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="author u-font-sans"><span>O. </span>Kramer</span><h3 class="title">Scikit-Learn, in Machine Learning for Evolution Strategies</h3><span class="host u-clr-grey6 u-font-sans"><div class="series">(2016)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="author u-font-sans"><span>F. </span>Pedregosa</span><h3 class="title">Scikit-learn: machine learning in Python</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">J. Mach. Learn. Res.</h3></div><div class="series">(2011)</div></span></li><li class="bib-reference u-margin-s-bottom"><span>T. Chen, C.Guestrin, XGBoost: a scalable tree boosting system, arXiv preprint arXiv:1603.02754, (2016)....</span></li><li class="bib-reference u-margin-s-bottom"><span>F. Chollet, Keras, 2015....</span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>C. </span>Gambella</span><em> et al.</em></span><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Optimization Models for Machine Learning: A Survey</h3></div><div class="series">(2019)</div></span></li><li class="bib-reference u-margin-s-bottom"><span>C.M. Bishop, Pattern Recognition and Machine Learning, 2006, Springer, ISBN:...</span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>A.E. </span>Hoerl</span><em> et al.</em></span><h3 class="title">Ridge regression: applications to nonorthogonal problems</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Technometrics</h3></div><div class="series">(1970)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="author u-font-sans"><span>R. </span>Tibshirani</span><h3 class="title">Regression shrinkage and selection via the Lasso</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">J. R. Stat. Soc. Ser. B</h3></div><div class="series">(1996)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>D.W. </span>Hosmer</span><em> et al.</em></span><h3 class="title">Applied logistic regression</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Technometrics</h3></div><div class="series">(2013)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>J.O. </span>Ogutu</span><em> et al.</em></span><h3 class="title">Genomic selection using regularized linear regression models: ridge regression, lasso, elastic net and their extensions</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">BMC Proc. BioMed Cent.</h3></div><div class="series">(2012)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>J.M. </span>Keller</span><em> et al.</em></span><h3 class="title">A fuzzy K-nearest neighbor algorithm</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">IEEE Trans. Syst. Man Cybern.</h3></div><div class="series">(1985)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>W. </span>Zuo</span><em> et al.</em></span><h3 class="title">On kernel difference-weighted k-nearest neighbor classification</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Pattern Anal. Appl.</h3></div><div class="series">(2008)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>A. </span>Smola</span><em> et al.</em></span><h3 class="title">Support vector regression machines</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Adv. Neural Inf. Process. Syst.</h3></div><div class="series">(1997)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>L. </span>Yang</span><em> et al.</em></span><h3 class="title">Image-based visibility estimation algorithm for intelligent transportation systems</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">IEEE Access</h3></div><div class="series">(2018)</div></span></li><li class="bib-reference u-margin-s-bottom"><span class="u-font-sans"><span class="author u-font-sans"><span>J. </span>Zhang</span><em> et al.</em></span><h3 class="title">Modified logistic regression: an approximation to SVM and its applications in large-scale text categorization</h3><span class="host u-clr-grey6 u-font-sans"><div class="series"><h3 class="title">Proceedings Twent. Int. Conf. Mach. Learn.</h3></div><div class="series">(2003)</div></span></li><li class="bib-reference u-margin-s-bottom"><span>O.S. Soliman, A.S. Mahmoud, A classification system for remote sensing satellite images using support vector machine...</span></li></div><button class="button-alternative button-alternative-secondary text-m u-font-sans u-margin-l-bottom button-alternative-icon-left" type="button" id="show-more-refs-btn"><span class="button-alternative-icon"><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down u-fill-grey8"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></span><span class="button-alternative-text">View more references</span></button></div></div><div id="preview-section-cited-by"><section aria-label="Cited by" class="ListArticles preview"><div class="PageDivider"></div><header id="citing-articles-header"><h2 class="u-h4 u-margin-l-ver u-font-serif">Cited by (1304)</h2></header><div aria-describedby="citing-articles-header"><div class="citing-articles u-margin-l-bottom"><ul><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-0-title"><a class="anchor anchor-default" href="/science/article/pii/S2001037024000278"><span class="anchor-text">Automated machine learning in nanotoxicity assessment: A comparative study of predictive model performance</span></a></h3><div class="text-s">2024, Computational and Structural Biotechnology Journal</div></div><div class="buttons text-s"><button class="button-link button-link-secondary button-link-icon-right" type="button" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-0-title" aria-controls="citing-articles-article-0" aria-expanded="false"><span class="button-link-text">Show abstract</span><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif text-s" id="reference-abstract"><div class="u-margin-ver-m"><p id="sp0045">Computational modeling has earned significant interest as an alternative to animal testing of toxicity assessment. However, the process of selecting an appropriate algorithm and fine-tuning hyperparameters for the developing of optimized models takes considerable time, expertise, and an intensive search. The recent emergence of automated machine learning (autoML) approaches, available as user-friendly platforms, has proven beneficial for individuals with limited knowledge in ML-based predictive model development. These autoML platforms automate crucial steps in model development, including data preprocessing, algorithm selection, and hyperparameter tuning. In this study, we used seven previously published and publicly available datasets for oxides and metals to develop nanotoxicity prediction models. AutoML platforms, namely Vertex AI, Azure, and Dataiku, were employed and performance measures such as accuracy, F1 score, precision, and recall for these autoML-based models were then compared with those of conventional ML-based models. The results demonstrated clearly that the autoML platforms produced more reliable nanotoxicity prediction models, outperforming those built with conventional ML algorithms. While none of the three autoML platforms significantly outperformed the others, distinctions exist among them in terms of the available options for choosing technical features throughout the model development steps. This allows users to select an autoML platform that aligns with their knowledge of predictive model development and its technical features. Additionally, prediction models constructed from datasets with better data quality displayed, enhanced performance than those built from datasets with lower data quality, indicating that future studies with high-quality datasets can further improve the performance of those autoML-based prediction models.</p></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-1-title"><a class="anchor anchor-default" href="/science/article/pii/S0957417424008194"><span class="anchor-text">A finite element-based machine learning framework to predict the mechanical behavior of the pelvic floor muscles during childbirth</span></a></h3><div class="text-s">2024, Expert Systems with Applications</div></div><div class="buttons text-s"><button class="button-link button-link-secondary button-link-icon-right" type="button" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-1-title" aria-controls="citing-articles-article-1" aria-expanded="false"><span class="button-link-text">Show abstract</span><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif text-s" id="reference-abstract"><div class="u-margin-ver-m"><p id="d1e1405">The medical community has been focusing on gaining a deeper understanding of birth trauma, which affects millions of women worldwide. Maternal lesions can be challenging to diagnose and expensive to examine. To better comprehend the mechanism of injuries occurring in the pelvic floor muscles (PFM), biomechanical simulations can be a valuable tool. However, utilizing the finite element method (FEM) to conduct simulations can be a time-consuming process. To overcome this issue, the present study aims to develop a machine learning (ML) framework to predict stresses on the PFM during childbirth by training ML algorithms on FEM simulation data. To generate the dataset for the ML algorithmâ€™s training, childbirth simulations were performed using different material properties to characterize the PFM. Four ML algorithms were employed, namely Random Forest (RF), Extreme Gradient Boosting (XGBT), Support Vector Regression (SVR), and Artificial Neural Networks (ANN), considering two scenarios: (1) stress prediction for the maximum stretch level of the muscle, and (2) for multiple levels of fetal descent. Results showed that the ANN performed best in the former, with a mean absolute error (MAE) of 0.191 MPa. In the latter, XGBT provided lower errors for 20 and 35 mm of fetal descent, with MAE values of 0.002 and 0.028 MPa, respectively. Nevertheless, the ANN yielded better predictions for 50 and 65 mm, with MAE values of 0.214 and 0.187 MPa, respectively. The present work represents the first attempt to use FEM-based ML algorithms with childbirth simulations to obtain near-real-time predictions in routine clinical procedures.</p></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-2-title"><a class="anchor anchor-default" href="/science/article/pii/S0969806X24002597"><span class="anchor-text">A deep neural network for predicting soil texture using airborne radiometric data</span></a></h3><div class="text-s">2024, Radiation Physics and Chemistry</div></div><div class="buttons text-s"><button class="button-link button-link-secondary button-link-icon-right" type="button" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-2-title" aria-controls="citing-articles-article-2" aria-expanded="false"><span class="button-link-text">Show abstract</span><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif text-s" id="reference-abstract"><div class="u-margin-ver-m"><p id="abspara0010">The ternary nature of soil texture, defined by its proportions of clay, silt, and sand, makes it challenging to predict through linear regression models from other soil attributes and auxiliary variables. The most promising results in this field have been recently achieved by Machine Learning methods which are able to derive non-linear, non-site-specific models to predict soil texture. In this paper we present a method of constructing a pair of Deep Neural Network (DNN) algorithms that can predict clay and sand soil contents from Airborne Gamma Ray Spectrometry data of K and Th ground abundances.</p><p id="abspara0015">We tested the algorithm&#x27;s hyperparameters through various configurations to optimize the DNNs&#x27; performance, effectively avoiding underfitting and overfitting of the models. This led to the creation of a high-resolution 20Â mÂ Ã—Â 20Â m soil texture map from dense AGRS data, significantly refining the previous map&#x27;s granularity. The application of the obtained <span id="gs1">DNN</span> models to unseen sites can be supported by future training on additional textural classes.</p></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-3-title"><a class="anchor anchor-default" href="/science/article/pii/S1746809424003240"><span class="anchor-text">Comparison of machine learning algorithms and feature extraction techniques for the automatic detection of surface EMG activation timing</span></a></h3><div class="text-s">2024, Biomedical Signal Processing and Control</div></div><div class="buttons text-s"><button class="button-link button-link-secondary button-link-icon-right" type="button" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-3-title" aria-controls="citing-articles-article-3" aria-expanded="false"><span class="button-link-text">Show abstract</span><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif text-s" id="reference-abstract"><div class="u-margin-ver-m"><p id="sp0010">This paper presents a methodology for automatically detecting muscular activity by denoising, extracting features, and classifying surface electromyography (sEMG) signals. The proposed methodology utilizes the Discrete Wavelet Transform (DWT) and Willisonâ€™s Amplitude Algorithm (WAMP) for feature extraction. Five classification methods, including Neural Networks (NN), Classification Vector, XGBoost, Light Gradient Boosting Machine (LGBM), and ExtraTree, were evaluated using F-Measure, Precision, and Recall as performance metrics. Through k-fold cross-validation, the XGBoost algorithm, when combined with the Eigen values feature, achieved the highest training performance with an F1-Score of 98.71Â %. For the test group, the LGBM classifier using WAMP, and NN with both WAMP and Eigen values as features, demonstrated the best average performance with F1-Scores of 96.52Â Â±Â 3.45Â % and 96.52Â Â±Â 3.07Â %, respectively. These results highlight the precision and performance of the proposed approach in detecting EMG signals. Moreover, the framework has the potential to support clinicians in diagnosing neuromuscular disorders and developing humanâ€“machine interfaces.</p></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-4-title"><a class="anchor anchor-default" href="/science/article/pii/S095741742400215X"><span class="anchor-text">Early detection of fake news on virtual social networks: A time-aware approach based on crowd signals</span></a></h3><div class="text-s">2024, Expert Systems with Applications</div></div><div class="buttons text-s"><button class="button-link button-link-secondary button-link-icon-right" type="button" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-4-title" aria-controls="citing-articles-article-4" aria-expanded="false"><span class="button-link-text">Show abstract</span><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif text-s" id="reference-abstract"><div class="u-margin-ver-m"><p id="d1e12531">With virtual social networks (VSNs) ever more popular as a means of disseminating fake news, methods for automatically detecting this type of content have become increasingly important. Early fake news detection seeks to detect a fake news story before it is widely spread to enable the implementation of mitigatory actions to minimize its adverse effects on society. Studies based on early detection are promising, but use restricted-access data (e.g., personal and sensitive data) from usersâ€™ profiles, which is typically not available in VSNs. To address the problem of restricted data, albeit leaving aside early detection, some studies have explored using crowd signals. This approach combines the opinions (i.e., signals) of a group of users (i.e., the crowd) to detect fake news. Given this scenario, this paper hypothesizes that <em>using usersâ€™ opinions can enable the early detection of fake news with results comparable to those of existing state-of-the-art methods, but without relying on restricted-access data</em>. Thus, we propose a novel fake news early detection method: <em>TCS</em> (Time-aware Crowd Signals). The proposed method explores the temporal nature of news propagation to detect fake news, utilizing usersâ€™ reputations obtained from their public behavior when spreading news in the past. Experiments on four different datasets show that the proposed method performance is comparable with state-of-the-art methods. As well as confirming the hypothesis, <em>TCS</em> identified fake news stories in VSNs earlier than other methods without relying on restricted-access data from network users.</p></div></div></div></li><li class="ListArticleItem u-margin-l-bottom"><div class="sub-heading u-margin-xs-bottom"><h3 class="u-font-serif" id="citing-articles-article-5-title"><a class="anchor anchor-default" href="/science/article/pii/S2949891024002690"><span class="anchor-text">Innovative integrated workflow for data-driven production forecasting and well completion optimization: A Montney Formation case study</span></a></h3><div class="text-s">2024, Geoenergy Science and Engineering</div></div><div class="buttons text-s"><button class="button-link button-link-secondary button-link-icon-right" type="button" data-aa-button="sd:product:journal:article:location=citing-articles:type=view-details" aria-describedby="citing-articles-article-5-title" aria-controls="citing-articles-article-5" aria-expanded="false"><span class="button-link-text">Show abstract</span><svg focusable="false" viewBox="0 0 92 128" width="17.25" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div><div class="u-display-none" aria-hidden="true"><div class="abstract u-margin-xs-top u-margin-m-bottom u-font-serif text-s" id="reference-abstract"><div class="u-margin-ver-m"><p id="abspara0010">With the use of advanced data analytics and machine learning (ML) techniques, the oil and gas industry has transformed significantly in recent years. These innovations have opened new opportunities in reservoir engineering, allowing engineers to leverage data for better decision-making and well completion optimization. A key challenge in hydrocarbon exploration and production is forecasting gas production rates from unconventional sources. This is a crucial factor that affects how resources are allocated and decisions are made, requiring the application of novel techniques to enhance hydrocarbon production. Here, a novel and comprehensive automated workflow is introduced covering data collection, data preparation, feature selection, ML model development, and operational parameter optimization. The workflow uses various ML and optimization methods, including a modified Differential Evolution (MDE) algorithm, to improve gas production forecasting and optimize well completion parameters. We applied the proposed workflow to 3144 horizontal gas wells in the Montney Formation, British Columbia (BC), Canada, to assess its performance. The results showed the advantages of incorporating the initial 24 months of cumulative gas production data alongside well and completion data. Also, following the fine-tuning of hyperparameters for the ML algorithms, we identified the most effective model for forecasting cumulative gas production within the Montney Formation as a two-layer Artificial Neural Network (ANN) model. Moreover, using the MDE algorithm, the optimization results revealed the possibility of increasing gas production by more than 10% for about 47% of the wells. This research makes a significant contribution to the field of unconventional gas exploration by introducing an automated workflow that simplifies data processing, model development, and decision-making processes. It also offers valuable insights for optimizing unconventional gas production in the Montney Formation and similar reservoirs, as the energy industry moves towards more sustainable and efficient practices.</p></div></div></div></li></ul><a class="button-alternative button-alternative-secondary button-alternative-icon-left" href="http://www.scopus.com/scopus/inward/citedby.url?partnerID=10&amp;rel=3.0.0&amp;eid=2-s2.0-85089284069&amp;md5=1cc74052aff459591aa9e85672b56b58" target="_blank" id="citing-articles-view-all-btn"><span class="button-alternative-icon"><svg focusable="false" viewBox="0 0 54 128" width="32" height="32" class="icon icon-navigate-right"><path d="m1 99l38-38-38-38 7-7 45 45-45 45z"></path></svg></span><span class="button-alternative-text">View all citing articles on Scopus</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em" class="icon icon-arrow-up-right arrow-external-link"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a></div></div></section></div><div class="PageDivider"></div><div class="article-biography text-s article-biography-has-image" id="bg005"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220311693-fx1.jpg" height="155" alt /></div><div class="article-biography-text"><p id="sp010"><strong>Li Yang</strong> received the B.E. degree in computer science from Wuhan University of Science and Technology, Wuhan, China in 2016 and the MASc degree in Engineering from University of Guelph, Guelph, Canada, 2018. Since 2018 he has been working toward the Ph.D. degree in the Department of Electrical and Computer Engineering, Western University, London, Canada. His research interests include cybersecurity, machine learning, data analytics, and intelligent transportation systems.</p></div></div><div class="article-biography text-s article-biography-has-image" id="bg010"><div class="article-biography-image"><img src="https://ars.els-cdn.com/content/image/1-s2.0-S0925231220311693-fx2.jpg" height="155" alt /></div><div class="article-biography-text"><p id="sp015"><strong>Abdallah Shami</strong> is a professor with the ECE Department at Western University, Ontario, Canada. He is the Director of the Optimized Computing and Communications Laboratory at Western University (https://www.eng.uwo.ca/oc2/). He is currently an associate editor for IEEE Transactions on Mobile Computing, IEEE Network, and IEEE Communications Surveys and Tutorials. He has chaired key symposia for IEEE GLOBECOM, IEEE ICC, IEEE ICNC, and ICCIT. He was the elected Chair of the IEEE Communications Society Technical Committee on Communications Software (2016â€“2017) and the IEEE London Ontario Section Chair (2016â€“2018).</p></div></div><a class="anchor full-text-link text-s anchor-default" href="/science/article/pii/S0925231220311693" aria-disabled="true" tabindex="-1"><span class="anchor-text">View full text</span></a><div class="Copyright"><span class="copyright-line">Â© 2020 Elsevier B.V. All rights reserved.</span></div></article><div class="u-show-from-md col-lg-6 col-md-8 pad-right u-padding-s-top"><aside class="RelatedContent u-clr-grey8" aria-label="Related content"><section class="RelatedContentPanel u-margin-s-bottom"><header id="recommended-articles-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link related-content-panel-toggle is-up button-link-primary button-link-icon-right" type="button" aria-expanded="true" data-aa-button="sd:product:journal:article:location=recommended-articles:type=close"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Recommended articles</span></h2></span><svg focusable="false" viewBox="0 0 92 128" width="24" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class aria-hidden="false" aria-describedby="recommended-articles-header"><div id="recommended-articles" class="text-xs"><ul><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article0-title"><a class="anchor u-clamp-2-lines anchor-default" href="/science/article/pii/S0950705120302999" title="Systematic ensemble model selection approach for educational data mining"><span class="anchor-text"><span>Systematic ensemble model selection approach for educational data mining</span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Knowledge-Based Systems, Volume 200, 2020, Article 105992</div></div><div class="authors"><span>MohammadNoor</span> <span>Injadat</span>, â€¦, <span>Abdallah</span> <span>Shami</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article1-title"><a class="anchor u-clamp-2-lines anchor-default" href="/science/article/pii/S2210670720304960" title="A survey on hyperparameters optimization algorithms of forecasting models in smart grid"><span class="anchor-text"><span>A survey on hyperparameters optimization algorithms of forecasting models in smart grid</span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Sustainable Cities and Society, Volume 61, 2020, Article 102275</div></div><div class="authors"><span>Rabiya</span> <span>Khalid</span>, <span>Nadeem</span> <span>Javaid</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-block"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article2-title"><a class="anchor u-clamp-2-lines anchor-default" href="/science/article/pii/S0950705119301923" title="Hyperparameter optimization of deep neural network using univariate dynamic encoding algorithm for searches"><span class="anchor-text"><span>Hyperparameter optimization of deep neural network using univariate dynamic encoding algorithm for searches</span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Knowledge-Based Systems, Volume 178, 2019, pp. 74-83</div></div><div class="authors"><span>YoungJun</span> <span>Yoo</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article3-title"><a class="anchor u-clamp-2-lines anchor-default" href="/science/article/pii/S2214212621000430" title="Attack classification of an intrusion detection system using deep learning and hyperparameter optimization"><span class="anchor-text"><span>Attack classification of an intrusion detection system using deep learning and hyperparameter optimization</span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Journal of Information Security and Applications, Volume 58, 2021, Article 102804</div></div><div class="authors"><span>Yesi Novaria</span> <span>Kunang</span>, â€¦, <span>Bhakti Yudho</span> <span>Suprapto</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article4-title"><a class="anchor u-clamp-2-lines anchor-default" href="/science/article/pii/S0957417417301008" title="A boosted decision tree approach using Bayesian hyper-parameter optimization for credit scoring"><span class="anchor-text"><span>A boosted decision tree approach using Bayesian hyper-parameter optimization for credit scoring</span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Expert Systems with Applications, Volume 78, 2017, pp. 225-241</div></div><div class="authors"><span>Xia</span> <span>Yufei</span>, â€¦, <span>Liu</span> <span>Nana</span></div></div><div class="buttons"></div></li><li class="RelatedContentPanelItem u-display-none"><div class="sub-heading u-padding-xs-bottom"><h3 class="related-content-panel-list-entry-outline-padding text-s u-font-serif" id="recommended-articles-article5-title"><a class="anchor u-clamp-2-lines anchor-default" href="/science/article/pii/S0306437916305695" title="Genetic algorithms for hyperparameter optimization in predictive business process monitoring"><span class="anchor-text"><span>Genetic algorithms for hyperparameter optimization in predictive business process monitoring</span></span></a></h3><div class="article-source u-clr-grey6"><div class="source">Information Systems, Volume 74, Part 1, 2018, pp. 67-83</div></div><div class="authors"><span>Chiara</span> <span>Di Francescomarino</span>, â€¦, <span>Luca</span> <span>Simonetto</span></div></div><div class="buttons"></div></li></ul></div><button class="button-link more-recommendations-button button-link-secondary text-s u-margin-s-bottom button-link-icon-right" type="button"><span class="button-link-text">Show 3 more articles</span><svg focusable="false" viewBox="0 0 92 128" height="20" width="17.25" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></div></section><section class="RelatedContentPanel u-margin-s-bottom hidden"><header id="metrics-header" class="related-content-panel-header u-margin-s-bottom"><button class="button-link related-content-panel-toggle is-up button-link-primary button-link-icon-right" type="button" aria-expanded="true"><span class="button-link-text"><h2 class="section-title u-h4"><span class="related-content-panel-title-text">Article Metrics</span></h2></span><svg focusable="false" viewBox="0 0 92 128" width="24" height="24" class="icon icon-navigate-down"><path d="m1 51l7-7 38 38 38-38 7 7-45 45z"></path></svg></button></header><div class aria-hidden="false" aria-describedby="metrics-header"><a href="https://plu.mx/plum/a/?doi=10.1016/j.neucom.2020.07.061" class="plumx-summary plum-sciencedirect-theme" data-pass-hidden-categories="true" data-hide-usage="true" data-orientation="vertical" data-hide-print="true" data-site="plum" data-on-success="onMetricsWidgetSuccess">View article metrics</a></div></section></aside></div></div></div></div><footer role="contentinfo" class="els-footer u-bg-white text-xs u-padding-s-hor u-padding-m-hor-from-sm u-padding-l-hor-from-md u-padding-l-ver u-margin-l-top u-margin-xl-top-from-sm u-margin-l-top-from-md"><div class="els-footer-elsevier u-margin-m-bottom u-margin-0-bottom-from-md u-margin-s-right u-margin-m-right-from-md u-margin-l-right-from-lg"><a class="anchor anchor-default anchor-icon-only" href="https://www.elsevier.com/" target="_blank" aria-label="Elsevier home page (opens in a new tab)" rel="nofollow"><img class="footer-logo" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/47/images/elsevier-non-solus-new-with-wordmark.svg" alt="Elsevier logo with wordmark" height="64" width="58" loading="lazy" /></a></div><div class="els-footer-content"><div class="u-remove-if-print"><ul class="els-footer-links u-margin-xs-bottom" style="list-style:none"><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-default" href="https://www.elsevier.com/solutions/sciencedirect" target="_blank" id="els-footer-about-science-direct" rel="nofollow"><span class="anchor-text">About ScienceDirect</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em" class="icon icon-arrow-up-right arrow-external-link"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a></li><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-default" href="/user/institution/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS0925231220311693" id="els-footer-remote-access" rel="nofollow"><span class="anchor-text">Remote access</span></a></li><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-default" href="https://sd-cart.elsevier.com/?" target="_blank" id="els-footer-shopping-cart" rel="nofollow"><span class="anchor-text">Shopping cart</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em" class="icon icon-arrow-up-right arrow-external-link"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a></li><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-default" href="http://elsmediakits.com" target="_blank" id="els-footer-advertise" rel="nofollow"><span class="anchor-text">Advertise</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em" class="icon icon-arrow-up-right arrow-external-link"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a></li><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-default" href="https://service.elsevier.com/app/contact/supporthub/sciencedirect/" target="_blank" id="els-footer-contact-support" rel="nofollow"><span class="anchor-text">Contact and support</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em" class="icon icon-arrow-up-right arrow-external-link"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a></li><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-default" href="https://www.elsevier.com/legal/elsevier-website-terms-and-conditions" target="_blank" id="els-footer-terms-condition" rel="nofollow"><span class="anchor-text">Terms and conditions</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em" class="icon icon-arrow-up-right arrow-external-link"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a></li><li><a class="anchor u-display-block u-clr-grey8 u-margin-s-bottom u-margin-0-bottom-from-sm u-margin-m-right-from-sm u-margin-l-right-from-md anchor-default" href="https://www.elsevier.com/legal/privacy-policy" target="_blank" id="els-footer-privacy-policy" rel="nofollow"><span class="anchor-text">Privacy policy</span><svg focusable="false" viewBox="0 0 78 128" aria-label="Opens in new window" width="1em" height="1em" class="icon icon-arrow-up-right arrow-external-link"><path d="m4 36h57.07l-59.5 59.5 7.07 7.08 59.36-59.36v56.78h1e1v-74h-74z"></path></svg></a></li></ul></div><p id="els-footer-cookie-message" class="u-remove-if-print">Cookies are used by this site. <!-- --> <button class="button-link ot-sdk-show-settings cookie-btn button-link-primary" type="button" id="ot-sdk-btn"><span class="button-link-text"><strong>Cookie Settings</strong></span></button></p><p id="els-footer-copyright">All content on this site: Copyright Â© <!-- -->2024<!-- --> Elsevier B.V., its licensors, and contributors. All rights are reserved, including those for text and data mining, AI training, and similar technologies. For all open access content, the Creative Commons licensing terms apply.</p></div><div class="els-footer-relx u-margin-0-top u-margin-m-top-from-xs u-margin-0-top-from-md"><a class="anchor anchor-default anchor-icon-only" href="https://www.relx.com/" target="_blank" aria-label="RELX home page (opens in a new tab)" id="els-footer-relx" rel="nofollow"><img loading="lazy" src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/60/images/logo-relx-tm.svg" width="93" height="20" alt="RELX group home page" /></a></div></footer></div></div></div></div>
<script type="application/json" data-iso-key="_0">{"abstracts":{"content":[{"$$":[{"$":{"id":"st385"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"sp005"},"#name":"simple-para","$$":[{"#name":"text","$$":[{"#name":"topic-link","_":"Machine learning algorithms","$":{"href":"/topics/neuroscience/machine-learning-algorithm","term":"Machine learning algorithms"}},{"#name":"__text__","_":" have been used widely in various applications and areas. To fit a "}]},{"#name":"topic-link","_":"machine learning","$":{"href":"/topics/computer-science/machine-learning","term":"machine learning"}},{"#name":"text","$$":[{"#name":"__text__","_":" model into different problems, its hyper-parameters must be tuned. Selecting the best hyper-parameter configuration for machine learning models has a direct impact on the modelâ€™s performance. It often requires deep knowledge of machine learning algorithms and appropriate hyper-parameter optimization techniques. Although several automatic optimization techniques exist, they have different strengths and drawbacks when applied to different types of problems. In this paper, optimizing the hyper-parameters of common machine learning models is studied. We introduce several state-of-the-art optimization techniques and discuss how to apply them to machine learning algorithms. Many available libraries and frameworks developed for hyper-parameter "},{"#name":"topic-link","_":"optimization problems","$":{"href":"/topics/computer-science/optimization-problem","term":"optimization problems"}},{"#name":"__text__","_":" are provided, and some open challenges of hyper-parameter optimization research are also discussed in this paper. Moreover, experiments are conducted on benchmark datasets to compare the performance of different optimization methods and provide practical examples of hyper-parameter optimization. This survey paper will help industrial users, data analysts, and researchers to better develop machine learning models by identifying the proper hyper-parameter configurations effectively."}]}]}],"$":{"view":"all","id":"as005"},"#name":"abstract-sec"}],"$":{"view":"all","id":"ab005","lang":"en","class":"author"},"#name":"abstract"}],"floats":[],"footnotes":[],"attachments":[]},"accessbarConfig":{"fallback":false,"id":"accessbar","version":"0.0.1","analytics":{"location":"accessbar","eventName":"ctaImpression"},"ariaLabel":{"accessbar":"Download options and search","componentsList":"PDF Options"},"banner":{"id":"Banner"},"banners":[{"id":"Banner"},{"id":"BannerSsrn"}],"components":[{"analytics":[{"ids":["accessbar:clinicalkeycta:inst-known:sdcust-unknown:ent-no:ra-no:source-linkinghub:method-ip"],"eventName":"ctaClick"}],"label":"Access through&nbsp;**ClinicalKey**","id":"ClinicalKey"},{"ariaLabel":"Access through your institution","institutionLogoAltText":"Seamless access","analytics":[{"ids":["accessbar:accesscta:inst-known:sdcust-unknown:ent-unknown:ra-yes:source-sdcookie:method-shib"],"eventName":"ctaClick"}],"labelPrefix":"Access through","defaultLabelSuffix":"your institution","institutionName":"University of Nottingham Ningbo, China","href":"https://auth.elsevier.com/ShibAuth/institutionLogin?entityID=https%3A%2F%2Fidp.nottingham.edu.cn%2Fidp%2Fshibboleth&appReturnURL=https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fabs%2Fpii%2FS0925231220311693%3Ffr%3DRR-2%26ref%3Dpdf_download%26rr%3D8851c74ebed560e3","remoteAccessType":"SHIB","id":"RemoteAccess"},{"analytics":[{"ids":["accessbar:purchase-pdf"],"eventName":"ctaClick"}],"label":"Purchase PDF","href":"/getaccess/pii/S0925231220311693/purchase","rel":"noreferrer noopener","target":"_blank","id":"PurchasePDF"},{"analytics":[{"ids":["accessbar:another-institution"],"eventName":"ctaClick"}],"label":"Access through another institution","href":"/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0925231220311693","id":"RemoteAccessOther"},{"id":"LinkResolver","analytics":[{"eventName":"ctaClick","ids":["accessbar:linkresolver"]}],"rel":"noreferrer noopener","target":"_blank","href":"https://www.elsevier.com/?ctx_ver=Z39.88-2004&ctx_enc=info:ofi/enc:UTF-8&url_ver=Z39.88-2004&rfr_id=info:sid/Elsevier:SD&svc_val_fmt=info:ofi/fmt:kev:mtx:sch_svc&rft_val_fmt=info:ofi/fmt:kev:mtx:journal&rft.aulast=YANG&rft.auinit=L&rft.date=2020&rft.issn=09252312&rft.volume=415C&rft.spage=295&rft.epage=316&rft.title=Neurocomputing&rft.atitle=On%20hyperparameter%20optimization%20of%20machine%20learning%20algorithms%3A%20Theory%20and%20practice&rft_id=info:doi/10.1016/j.neucom.2020.07.061","label":"Find it here!"}],"search":{"inputPlaceHolder":"Search ScienceDirect","ariaLabel":{"input":"Search ScienceDirect","submit":"Submit search"},"formAction":"/search#submit","analytics":[{"ids":["accessbar:search"],"eventName":"searchStart"}],"id":"QuickSearch"}},"adobeTarget":{"header-sign-in":{"variation":"#2","enabled":true}},"article":{"accessOptions":{"remoteAccessOptions":{"institutionName":"University of Nottingham Ningbo, China","remoteAccessType":"SHIB","institutionUrl":"https://auth.elsevier.com/ShibAuth/institutionLogin?entityID=https%3A%2F%2Fidp.nottingham.edu.cn%2Fidp%2Fshibboleth&appReturnURL=https%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fabs%2Fpii%2FS0925231220311693%3Ffr%3DRR-2%26ref%3Dpdf_download%26rr%3D8851c74ebed560e3"},"linkType":"PURCHASE","linkUrl":"/getaccess/pii/S0925231220311693","price":{"currency":"USD","totalPrice":27.95},"purchaseNonDiscounted":{"linkUrl":"/getaccess/pii/S0925231220311693?corporate=true","price":{"currency":"USD","totalPrice":37.95}}},"analyticsMetadata":{"accountId":"228598","accountName":"ScienceDirect Guests","loginStatus":"anonymous","userId":"12975512","isLoggedIn":false},"cid":"271597","content-family":"serial","copyright-line":"Â© 2020 Elsevier B.V. All rights reserved.","cover-date-years":["2020"],"cover-date-start":"2020-11-20","cover-date-text":"20 November 2020","document-subtype":"fla","document-type":"article","eid":"1-s2.0-S0925231220311693","doi":"10.1016/j.neucom.2020.07.061","first-fp":"295","hub-eid":"1-s2.0-S0925231220X00385","issuePii":"S0925231220X00385","item-weight":"FULL-TEXT","language":"en","last-lp":"316","last-author":{"#name":"last-author","$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"$$":[{"#name":"author","$":{"biographyid":"bg010","id":"au010","author-id":"S0925231220311693-a768414c0192b66856adf769e2f486c1"},"$$":[{"#name":"given-name","_":"Abdallah"},{"#name":"surname","_":"Shami"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Resources"},"_":"Resources"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_review_%26_editing"},"_":"Writing - review & editing"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Supervision"},"_":"Supervision"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Project_administration"},"_":"Project administration"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Funding_acquisition"},"_":"Funding acquisition"},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnhtbG5zJTNBeGxpbmslMjIlM0F0cnVlJTJDJTIyaWQlMjIlM0ElMjJlbTAxMCUyMiUyQyUyMnR5cGUlMjIlM0ElMjJlbWFpbCUyMiUyQyUyMmhyZWYlMjIlM0ElMjJtYWlsdG8lM0FhYmRhbGxhaC5zaGFtaSU0MHV3by5jYSUyMiU3RCUyQyUyMl8lMjIlM0ElMjJhYmRhbGxhaC5zaGFtaSU0MHV3by5jYSUyMiU3RA=="}]}]},"normalized-first-auth-initial":"L","normalized-first-auth-surname":"YANG","open-research":{"#name":"open-research","$":{"xmlns:xocs":true},"$$":[{"#name":"or-embargo-opening-date","_":"2022-08-12T00:00:00.000Z"}]},"pages":[{"last-page":"316","first-page":"295"}],"pii":"S0925231220311693","self-archiving":{"#name":"self-archiving","$":{"xmlns:xocs":true},"$$":[{"#name":"sa-start-date","_":"2022-08-12T00:00:00.000Z"},{"#name":"sa-user-license","_":"http://creativecommons.org/licenses/by-nc-nd/4.0/"}]},"srctitle":"Neurocomputing","suppl":"C","timestamp":"2021-02-16T11:29:10.516956Z","title":{"content":[{"#name":"title","$":{"id":"tm005"},"_":"On hyperparameter optimization of machine learning algorithms: Theory and practice"}],"floats":[],"footnotes":[],"attachments":[]},"vol-first":"415","vol-iss-suppl-text":"Volume 415","userSettings":{"forceAbstract":false,"creditCardPurchaseAllowed":true,"blockFullTextForAnonymousAccess":false,"disableWholeIssueDownload":false,"preventTransactionalAccess":false,"preventDocumentDelivery":true},"contentType":"JL","crossmark":true,"document-references":132,"freeHtmlGiven":false,"userProfile":{"departmentName":"ScienceDirect Guests","accessType":"GUEST","accountId":"228598","webUserId":"12975512","accountName":"ScienceDirect Guests","departmentId":"291352","userType":"NORMAL","hasMultipleOrganizations":false},"access":{"openAccess":false,"openArchive":false},"aipType":"none","articleEntitlement":{"entitled":false,"isCasaUser":false,"usageInfo":"(12975512,U|291352,D|228598,A|3,P|2,PL)(SDFE,CON|be2461336ecb674aff3b3ef-841b28bdabd3gxrqb,SSO|ANON_GUEST,ACCESS_TYPE)"},"crawlerInformation":{"canCrawlPDFContent":false,"isCrawler":false},"dates":{"Available online":"25 July 2020","Received":"13 December 2019","Revised":["14 May 2020"],"Accepted":"16 July 2020","Publication date":"20 November 2020","Version of Record":"12 August 2020"},"downloadFullIssue":false,"entitlementReason":"unsubscribed","hasBody":true,"has-large-authors":false,"hasScholarlyAbstract":true,"headerConfig":{"contactUrl":"https://service.elsevier.com/app/contact/supporthub/sciencedirect/","userName":"","userEmail":"","orgName":"ScienceDirect Guests","webUserId":"12975512","libraryBanner":{},"shib_regUrl":"","tick_regUrl":"","recentInstitutions":[],"canActivatePersonalization":false,"hasInstitutionalAssociation":false,"hasMultiOrg":false,"userType":"GUEST","userAnonymity":"ANON_GUEST","allowCart":true,"environment":"prod","cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com"},"isCorpReq":false,"isPdfFullText":false,"issn":"09252312","issn-primary-formatted":"0925-2312","issRange":"","isThirdParty":false,"pageCount":22,"publication-content":{"noElsevierLogo":false,"imprintPublisher":{"displayName":"Elsevier","id":"47"},"isSpecialIssue":false,"isSampleIssue":false,"transactionsBlocked":false,"publicationOpenAccess":{"oaStatus":"","oaArticleCount":446,"openArchiveStatus":false,"openArchiveArticleCount":18,"openAccessStartDate":"","oaAllowsAuthorPaid":true},"issue-cover":{"attachment":[{"attachment-eid":"1-s2.0-S0925231220X00385-cov200h.gif","file-basename":"cov200h","extension":"gif","filename":"cov200h.gif","ucs-locator":["https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220X00385/cover/DOWNSAMPLED200/image/gif/ae38d88e21600c96940b7bad6b11fec4/cov200h.gif"],"attachment-type":"IMAGE-COVER-H200","filesize":"5663","pixel-height":"200","pixel-width":"149"},{"attachment-eid":"1-s2.0-S0925231220X00385-cov150h.gif","file-basename":"cov150h","extension":"gif","filename":"cov150h.gif","ucs-locator":["https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220X00385/cover/DOWNSAMPLED/image/gif/5146595cef80896b640b8c76010eaa2a/cov150h.gif"],"attachment-type":"IMAGE-COVER-H150","filesize":"4322","pixel-height":"150","pixel-width":"112"}]},"smallCoverUrl":"https://ars.els-cdn.com/content/image/S09252312.gif","title":"neurocomputing","contentTypeCode":"JL","images":{"coverImage":"https://ars.els-cdn.com/content/image/1-s2.0-S0925231220X00385-cov150h.gif","logo":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/402a3f5c247cf997723622b5a8bc17cc2004f90c/image/elsevier-non-solus.png","logoAltText":"Elsevier"},"publicationCoverImageUrl":"https://ars.els-cdn.com/content/image/1-s2.0-S0925231220X00385-cov150h.gif"},"volRange":"415","features":["aamAttachments","keywords","references","biography","preview"],"titleString":"On hyperparameter optimization of machine learning algorithms: Theory and practice","ssrn":{},"renderingMode":"Preview","isAbstract":true,"isContentVisible":false,"ajaxLinks":{"referredToBy":true,"authorMetadata":true},"pdfEmbed":false,"displayViewFullText":false},"authors":{"content":[{"#name":"author-group","$":{"id":"ag005"},"$$":[{"#name":"author","$":{"biographyid":"bg005","id":"au005","author-id":"S0925231220311693-75c35717970266854719a749e620ec93"},"$$":[{"#name":"given-name","_":"Li"},{"#name":"surname","_":"Yang"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Methodology"},"_":"Methodology"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Software"},"_":"Software"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Validation"},"_":"Validation"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Formal_analysis"},"_":"Formal analysis"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Investigation"},"_":"Investigation"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Data_curation"},"_":"Data curation"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_original_draft"},"_":"Writing - original draft"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Visualization"},"_":"Visualization"},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnhtbG5zJTNBeGxpbmslMjIlM0F0cnVlJTJDJTIyaWQlMjIlM0ElMjJlbTAwNSUyMiUyQyUyMnR5cGUlMjIlM0ElMjJlbWFpbCUyMiUyQyUyMmhyZWYlMjIlM0ElMjJtYWlsdG8lM0FseWFuZzMzOSU0MHV3by5jYSUyMiU3RCUyQyUyMl8lMjIlM0ElMjJseWFuZzMzOSU0MHV3by5jYSUyMiU3RA=="}]},{"#name":"author","$":{"biographyid":"bg010","id":"au010","author-id":"S0925231220311693-a768414c0192b66856adf769e2f486c1"},"$$":[{"#name":"given-name","_":"Abdallah"},{"#name":"surname","_":"Shami"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Resources"},"_":"Resources"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_review_%26_editing"},"_":"Writing - review & editing"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Supervision"},"_":"Supervision"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Project_administration"},"_":"Project administration"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Funding_acquisition"},"_":"Funding acquisition"},{"#name":"encoded-e-address","__encoded":"JTdCJTIyJTIzbmFtZSUyMiUzQSUyMmUtYWRkcmVzcyUyMiUyQyUyMiUyNCUyMiUzQSU3QiUyMnhtbG5zJTNBeGxpbmslMjIlM0F0cnVlJTJDJTIyaWQlMjIlM0ElMjJlbTAxMCUyMiUyQyUyMnR5cGUlMjIlM0ElMjJlbWFpbCUyMiUyQyUyMmhyZWYlMjIlM0ElMjJtYWlsdG8lM0FhYmRhbGxhaC5zaGFtaSU0MHV3by5jYSUyMiU3RCUyQyUyMl8lMjIlM0ElMjJhYmRhbGxhaC5zaGFtaSU0MHV3by5jYSUyMiU3RA=="}]},{"#name":"affiliation","$":{"id":"af005","affiliation-id":"S0925231220311693-c32016a7adaa8ba99741ce612da1de1c"},"$$":[{"#name":"textfn","_":"Department of Electrical and Computer Engineering, University of Western Ontario, 1151 Richmond St, London, ON N6A 3K7, Canada"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Electrical and Computer Engineering"},{"#name":"organization","_":"University of Western Ontario"},{"#name":"address-line","_":"1151 Richmond St"},{"#name":"city","_":"London"},{"#name":"state","_":"ON"},{"#name":"postal-code","_":"N6A 3K7"},{"#name":"country","_":"Canada"}]},{"#name":"source-text","$":{"id":"str005"},"_":"Department of Electrical and Computer Engineering, University of Western Ontario, 1151 Richmond St, London, Ontario, N6A 3K7, Canada"}]}]}],"floats":[],"footnotes":[],"affiliations":{"af005":{"#name":"affiliation","$":{"id":"af005","affiliation-id":"S0925231220311693-c32016a7adaa8ba99741ce612da1de1c"},"$$":[{"#name":"textfn","_":"Department of Electrical and Computer Engineering, University of Western Ontario, 1151 Richmond St, London, ON N6A 3K7, Canada"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Electrical and Computer Engineering"},{"#name":"organization","_":"University of Western Ontario"},{"#name":"address-line","_":"1151 Richmond St"},{"#name":"city","_":"London"},{"#name":"state","_":"ON"},{"#name":"postal-code","_":"N6A 3K7"},{"#name":"country","_":"Canada"}]},{"#name":"source-text","$":{"id":"str005"},"_":"Department of Electrical and Computer Engineering, University of Western Ontario, 1151 Richmond St, London, Ontario, N6A 3K7, Canada"}]}},"attachments":[],"correspondences":{},"scopusAuthorIds":{},"articles":{}},"authorMetadata":[],"banner":{"expanded":false},"biographies":{"content":[{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg005","view":"all"},"$$":[{"#name":"link","$":{"id":"lk005","locator":"fx1","href":"pii:S0925231220311693/fx1","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp010","view":"all"},"$$":[{"#name":"bold","_":"Li Yang"},{"#name":"__text__","_":" received the B.E. degree in computer science from Wuhan University of Science and Technology, Wuhan, China in 2016 and the MASc degree in Engineering from University of Guelph, Guelph, Canada, 2018. Since 2018 he has been working toward the Ph.D. degree in the Department of Electrical and Computer Engineering, Western University, London, Canada. His research interests include cybersecurity, machine learning, data analytics, and intelligent transportation systems."}]}]},{"#name":"biography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg010","view":"all"},"$$":[{"#name":"link","$":{"id":"lk010","locator":"fx2","href":"pii:S0925231220311693/fx2","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp015","view":"all"},"$$":[{"#name":"bold","_":"Abdallah Shami"},{"#name":"__text__","_":" is a professor with the ECE Department at Western University, Ontario, Canada. He is the Director of the Optimized Computing and Communications Laboratory at Western University (https://www.eng.uwo.ca/oc2/). He is currently an associate editor for IEEE Transactions on Mobile Computing, IEEE Network, and IEEE Communications Surveys and Tutorials. He has chaired key symposia for IEEE GLOBECOM, IEEE ICC, IEEE ICNC, and ICCIT. He was the elected Chair of the IEEE Communications Society Technical Committee on Communications Software (2016â€“2017) and the IEEE London Ontario Section Chair (2016â€“2018)."}]}]}],"floats":[],"footnotes":[],"attachments":[{"attachment-eid":"1-s2.0-S0925231220311693-fx2.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220311693/fx2/DOWNSAMPLED/image/jpeg/83b1a01f94ec40bb97316a69257f9ac6/fx2.jpg","file-basename":"fx2","filename":"fx2.jpg","extension":"jpg","filesize":"5872","pixel-height":"155","pixel-width":"111","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231220311693-fx1.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220311693/fx1/DOWNSAMPLED/image/jpeg/167d17e56c0369019b464b0580bb9eeb/fx1.jpg","file-basename":"fx1","filename":"fx1.jpg","extension":"jpg","filesize":"6982","pixel-height":"155","pixel-width":"111","attachment-type":"IMAGE-DOWNSAMPLED"},{"attachment-eid":"1-s2.0-S0925231220311693-fx2.sml","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220311693/fx2/THUMBNAIL/image/gif/f2c271f525258acd7096241cd2d8c2b9/fx2.sml","file-basename":"fx2","filename":"fx2.sml","extension":"sml","filesize":"15040","pixel-height":"164","pixel-width":"117","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231220311693-fx1.sml","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220311693/fx1/THUMBNAIL/image/gif/867801b61cfdefba113535915b6b8f9c/fx1.sml","file-basename":"fx1","filename":"fx1.sml","extension":"sml","filesize":"15824","pixel-height":"164","pixel-width":"117","attachment-type":"IMAGE-THUMBNAIL"},{"attachment-eid":"1-s2.0-S0925231220311693-fx2_lrg.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220311693/fx2/HIGHRES/image/jpeg/19e53e1b0663f497ba2adad0c66acc64/fx2_lrg.jpg","file-basename":"fx2","filename":"fx2_lrg.jpg","extension":"jpg","filesize":"20116","pixel-height":"413","pixel-width":"295","attachment-type":"IMAGE-HIGH-RES"},{"attachment-eid":"1-s2.0-S0925231220311693-fx1_lrg.jpg","ucs-locator":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0925231220311693/fx1/HIGHRES/image/jpeg/d08208dacd89a5d2283db45b939b06a7/fx1_lrg.jpg","file-basename":"fx1","filename":"fx1_lrg.jpg","extension":"jpg","filesize":"23701","pixel-height":"413","pixel-width":"295","attachment-type":"IMAGE-HIGH-RES"}]},"body":{},"browser":{"name":"Chrome","engine":"Blink"},"chapters":{"toc":[],"isLoading":false},"changeViewLinks":{"showFullTextLink":true,"showAbstractLink":false},"citingArticles":{"hitCount":1304,"viewMoreUrl":"http://www.scopus.com/scopus/inward/citedby.url?partnerID=10&rel=3.0.0&eid=2-s2.0-85089284069&md5=1cc74052aff459591aa9e85672b56b58","articles":[{"articleTitle":"Automated machine learning in nanotoxicity assessment: A comparative study of predictive model performance","authors":"Xiao X., Trinh T.X., Gerelkhuu Z., Ha E., Yoon T.H.","doi":"10.1016/j.csbj.2024.02.003","externalArticle":false,"issn":"20010370","openAccess":1,"page":"9-19","pii":"S2001037024000278","publicationDate":"2024-12-01","publicationTitle":"Computational and Structural Biotechnology Journal","publicationYear":"2024","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85185837027&md5=43576968e9c59ef7a9d2e84fdba9a1d","scopusEid":"2-s2.0-85185837027","thirdParty":false,"volume":"Volume 25","abstract":{"$$":[{"$$":[{"$$":[{"#name":"attachment-eid","_":"1-s2.0-S2001037024000278-ga1.jpg"},{"#name":"ucs-locator","_":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2001037024000278/ga1/DOWNSAMPLED/image/jpeg/e4eea5405c288f62c691d889f8c549f0/ga1.jpg"},{"#name":"file-basename","_":"ga1"},{"#name":"abstract-attachment","_":"true"},{"#name":"filename","_":"ga1.jpg"},{"#name":"extension","_":"jpg"},{"#name":"filesize","_":"21839"},{"#name":"pixel-height","_":"241"},{"#name":"pixel-width","_":"301"},{"#name":"attachment-type","_":"IMAGE-DOWNSAMPLED"}],"$":{"xmlns:xocs":true},"#name":"attachment"},{"$$":[{"#name":"attachment-eid","_":"1-s2.0-S2001037024000278-ga1.sml"},{"#name":"ucs-locator","_":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2001037024000278/ga1/THUMBNAIL/image/gif/e8dbc453fcd06fba6976fde081347d61/ga1.sml"},{"#name":"file-basename","_":"ga1"},{"#name":"abstract-attachment","_":"true"},{"#name":"filename","_":"ga1.sml"},{"#name":"extension","_":"sml"},{"#name":"filesize","_":"14317"},{"#name":"pixel-height","_":"164"},{"#name":"pixel-width","_":"204"},{"#name":"attachment-type","_":"IMAGE-THUMBNAIL"}],"$":{"xmlns:xocs":true},"#name":"attachment"},{"$$":[{"#name":"attachment-eid","_":"1-s2.0-S2001037024000278-ga1_lrg.jpg"},{"#name":"ucs-locator","_":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S2001037024000278/HIGHRES/image/jpeg/2638cf2fdf1b39ade0324102d8963f33/ga1_lrg.jpg"},{"#name":"file-basename","_":"ga1"},{"#name":"abstract-attachment","_":"true"},{"#name":"filename","_":"ga1_lrg.jpg"},{"#name":"extension","_":"jpg"},{"#name":"filesize","_":"173600"},{"#name":"pixel-height","_":"1069"},{"#name":"pixel-width","_":"1333"},{"#name":"attachment-type","_":"IMAGE-HIGH-RES"}],"$":{"xmlns:xocs":true},"#name":"attachment"}],"#name":"attachments"},{"$$":[{"$":{"id":"sect0005"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"sp0045"},"#name":"simple-para","_":"Computational modeling has earned significant interest as an alternative to animal testing of toxicity assessment. However, the process of selecting an appropriate algorithm and fine-tuning hyperparameters for the developing of optimized models takes considerable time, expertise, and an intensive search. The recent emergence of automated machine learning (autoML) approaches, available as user-friendly platforms, has proven beneficial for individuals with limited knowledge in ML-based predictive model development. These autoML platforms automate crucial steps in model development, including data preprocessing, algorithm selection, and hyperparameter tuning. In this study, we used seven previously published and publicly available datasets for oxides and metals to develop nanotoxicity prediction models. AutoML platforms, namely Vertex AI, Azure, and Dataiku, were employed and performance measures such as accuracy, F1 score, precision, and recall for these autoML-based models were then compared with those of conventional ML-based models. The results demonstrated clearly that the autoML platforms produced more reliable nanotoxicity prediction models, outperforming those built with conventional ML algorithms. While none of the three autoML platforms significantly outperformed the others, distinctions exist among them in terms of the available options for choosing technical features throughout the model development steps. This allows users to select an autoML platform that aligns with their knowledge of predictive model development and its technical features. Additionally, prediction models constructed from datasets with better data quality displayed, enhanced performance than those built from datasets with lower data quality, indicating that future studies with high-quality datasets can further improve the performance of those autoML-based prediction models."}],"$":{"view":"all","id":"abs0010"},"#name":"abstract-sec"}],"$":{"view":"all","id":"ab0010","class":"author"},"#name":"abstract"},{"$$":[{"$":{"id":"sect0010"},"#name":"section-title","_":"Graphical Abstract"},{"$$":[{"$$":[{"$$":[{"$$":[{"$":{"role":"short","id":"at0045"},"#name":"alt-text","_":"ga1"},{"$":{"role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","xmlns:xlink":true,"id":"lk0035","href":"pii:S2001037024000278/ga1","type":"simple","locator":"ga1"},"#name":"link"}],"$":{"id":"fig0035"},"#name":"figure"}],"#name":"display"}],"$":{"view":"all","id":"sp0050"},"#name":"simple-para"}],"$":{"view":"all","id":"abs0015"},"#name":"abstract-sec"}],"$":{"view":"all","id":"ab0015","class":"graphical"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"},"pdf":{"urlType":"download","url":"/science/article/pii/S2001037024000278/pdfft?md5=a55b1b2f2d833b4759fe66b5685cf5b2&pid=1-s2.0-S2001037024000278-main.pdf"}},{"articleTitle":"A finite element-based machine learning framework to predict the mechanical behavior of the pelvic floor muscles during childbirth","authors":"Moura R., Oliveira D.A., Ferreira J.P.S., Parente M.P.L., Kimmich N., Natal Jorge R.M.","doi":"10.1016/j.eswa.2024.123953","externalArticle":false,"issn":"09574174","openAccess":1,"pii":"S0957417424008194","publicationDate":"2024-09-15","publicationTitle":"Expert Systems with Applications","publicationYear":"2024","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85190112848&md5=326a261887c524ca689ec5384da42fcc","scopusEid":"2-s2.0-85190112848","thirdParty":false,"volume":"Volume 250","abstract":{"$$":[{"$$":[{"$":{"id":"d1e1402"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"d1e1405"},"#name":"simple-para","_":"The medical community has been focusing on gaining a deeper understanding of birth trauma, which affects millions of women worldwide. Maternal lesions can be challenging to diagnose and expensive to examine. To better comprehend the mechanism of injuries occurring in the pelvic floor muscles (PFM), biomechanical simulations can be a valuable tool. However, utilizing the finite element method (FEM) to conduct simulations can be a time-consuming process. To overcome this issue, the present study aims to develop a machine learning (ML) framework to predict stresses on the PFM during childbirth by training ML algorithms on FEM simulation data. To generate the dataset for the ML algorithmâ€™s training, childbirth simulations were performed using different material properties to characterize the PFM. Four ML algorithms were employed, namely Random Forest (RF), Extreme Gradient Boosting (XGBT), Support Vector Regression (SVR), and Artificial Neural Networks (ANN), considering two scenarios: (1) stress prediction for the maximum stretch level of the muscle, and (2) for multiple levels of fetal descent. Results showed that the ANN performed best in the former, with a mean absolute error (MAE) of 0.191 MPa. In the latter, XGBT provided lower errors for 20 and 35 mm of fetal descent, with MAE values of 0.002 and 0.028 MPa, respectively. Nevertheless, the ANN yielded better predictions for 50 and 65 mm, with MAE values of 0.214 and 0.187 MPa, respectively. The present work represents the first attempt to use FEM-based ML algorithms with childbirth simulations to obtain near-real-time predictions in routine clinical procedures."}],"$":{"view":"all","id":"d1e1404"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e1401","class":"author"},"#name":"abstract"},{"$$":[{"$":{"id":"d1e1408"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e1417"},"#name":"para","_":"Machine learning accelerates the results obtained from childbirth simulations."}],"$":{"id":"d1e1414"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e1422"},"#name":"para","_":"Possibility of predicting pelvic floor musclesâ€™ mechanical behavior during labor."}],"$":{"id":"d1e1419"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e1427"},"#name":"para","_":"Artificial neural networks yield lowest mean absolute error for stress prediction."}],"$":{"id":"d1e1424"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e1432"},"#name":"para","_":"Real-time biomechanical analysis achievable and suitable for clinical applications."}],"$":{"id":"d1e1429"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e1437"},"#name":"para","_":"Use of artificial intelligence tools contributes to reducing maternal morbidity."}],"$":{"id":"d1e1434"},"#name":"list-item"}],"$":{"id":"d1e1413"},"#name":"list"}],"$":{"view":"all","id":"d1e1411"},"#name":"simple-para"}],"$":{"view":"all","id":"d1e1410"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e1407","class":"author-highlights"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"},"pdf":{"urlType":"download","url":"/science/article/pii/S0957417424008194/pdfft?md5=fa9e5004beedd2a31f739a2c20d51d51&pid=1-s2.0-S0957417424008194-main.pdf"}},{"articleTitle":"A deep neural network for predicting soil texture using airborne radiometric data","authors":"Maino A., Alberi M., Barbagli A., Chiarelli E., Colonna T., Franceschi M., Gallorini F., Guastaldi E., Lopane N., Mantovani F., Petrone D., Pierini S., Raptis K.G.C., Strati V., Xhixha G.","doi":"10.1016/j.radphyschem.2024.111767","externalArticle":false,"issn":"0969806X","openAccess":1,"pii":"S0969806X24002597","publicationDate":"2024-08-01","publicationTitle":"Radiation Physics and Chemistry","publicationYear":"2024","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85190829292&md5=e67f65c1662b36531e4ecaca2874641","scopusEid":"2-s2.0-85190829292","thirdParty":false,"volume":"Volume 221","abstract":{"$$":[{"$$":[{"$":{"id":"sectitle0010"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"abspara0010"},"#name":"simple-para","_":"The ternary nature of soil texture, defined by its proportions of clay, silt, and sand, makes it challenging to predict through linear regression models from other soil attributes and auxiliary variables. The most promising results in this field have been recently achieved by Machine Learning methods which are able to derive non-linear, non-site-specific models to predict soil texture. In this paper we present a method of constructing a pair of Deep Neural Network (DNN) algorithms that can predict clay and sand soil contents from Airborne Gamma Ray Spectrometry data of K and Th ground abundances."},{"$$":[{"#name":"__text__","_":"We tested the algorithm's hyperparameters through various configurations to optimize the DNNs' performance, effectively avoiding underfitting and overfitting of the models. This led to the creation of a high-resolution 20Â mÂ Ã—Â 20Â m soil texture map from dense AGRS data, significantly refining the previous map's granularity. The application of the obtained "},{"$":{"sponsor-id":"https://doi.org/10.13039/100006187","role":"http://www.elsevier.com/xml/linking-roles/grant-sponsor","xmlns:xlink":true,"id":"gs1","type":"simple"},"#name":"grant-sponsor","_":"DNN"},{"#name":"__text__","_":" models to unseen sites can be supported by future training on additional textural classes."}],"$":{"view":"all","id":"abspara0015"},"#name":"simple-para"}],"$":{"view":"all","id":"abssec0010"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0010","lang":"en","class":"author"},"#name":"abstract"},{"$$":[{"$":{"id":"sectitle0015"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0010"},"#name":"para","_":"Airborne radiometric data abundantly feed DNNs for soil texture predictions."}],"$":{"id":"u0010"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0015"},"#name":"para","_":"DNNs allow to overcome linear constraints for relations between K and clay content."}],"$":{"id":"u0015"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0020"},"#name":"para","_":"We optimized DNN hyperparameters in terms of accuracy and computational time."}],"$":{"id":"u0020"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0025"},"#name":"para","_":"We validated the DNNs for the prediction of soil texture from radiometric data."}],"$":{"id":"u0025"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0030"},"#name":"para","_":"We obtained a 20Â mÂ Ã—Â 20Â m soil texture map of the Mezzano Lowland (Italy)."}],"$":{"id":"u0030"},"#name":"list-item"}],"$":{"id":"ulist0010"},"#name":"list"}],"$":{"view":"all","id":"abspara0020"},"#name":"simple-para"}],"$":{"view":"all","id":"abssec0015"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0015","lang":"en","class":"author-highlights"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"},"pdf":{"urlType":"download","url":"/science/article/pii/S0969806X24002597/pdfft?md5=ccb7818db66772635cd5c8a45cab215d&pid=1-s2.0-S0969806X24002597-main.pdf"}},{"articleTitle":"Comparison of machine learning algorithms and feature extraction techniques for the automatic detection of surface EMG activation timing","authors":"GallÃ³n V.M., VÃ©lez S.M., RamÃ­rez J., BolaÃ±os F.","doi":"10.1016/j.bspc.2024.106266","externalArticle":false,"issn":"17468094","openAccess":1,"pii":"S1746809424003240","publicationDate":"2024-08-01","publicationTitle":"Biomedical Signal Processing and Control","publicationYear":"2024","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85188818881&md5=88c2c9d44add34dc6a68a949429bb9","scopusEid":"2-s2.0-85188818881","thirdParty":false,"volume":"Volume 94","abstract":{"$$":[{"$$":[{"$":{"id":"st005"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0005"},"#name":"para","_":"The article proposed a novel methodology for automated surface electromyography (sEMG) signal analysis focusing on diverse machine learning models, and hyperparameter optimization achieving an F1-Score of 98.71Â % with the XGBoost algorithm."}],"$":{"id":"o0005"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0010"},"#name":"para","_":"Hyperparameter tuning was performed for each model using the scikit-learn library. The paper provides detailed information on the best hyperparameter settings for XGBoost, Extra Trees, LGBM, SVM, and Neural Networks."}],"$":{"id":"o0010"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0015"},"#name":"para","_":"The models were trained on a dataset featuring muscle contractions and extensions in distinct body regions. This diverse training set aimed to capture the complexities and variations encountered in real-world surface electromyography (sEMG) applications."}],"$":{"id":"o0015"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0020"},"#name":"para","_":"The paper employs non-parametric tests, including Friedmanâ€™s test and post-hoc tests, to assess the significance of differences among the models. Visualizations and statistical analysis provide insights into algorithm performance based on F1-Score, Precision, and Recall."}],"$":{"id":"o0020"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0025"},"#name":"para","_":"The models showcased practicality for real-world applications, supporting clinicians in diagnosing neuromuscular disorders and advancing humanâ€“machine interfaces."}],"$":{"id":"o0025"},"#name":"list-item"}],"$":{"id":"l0005"},"#name":"list"}],"$":{"view":"all","id":"sp0005"},"#name":"simple-para"}],"$":{"view":"all","id":"as005"},"#name":"abstract-sec"}],"$":{"view":"all","id":"ab005","lang":"en","class":"author-highlights"},"#name":"abstract"},{"$$":[{"$":{"id":"st010"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"sp0010"},"#name":"simple-para","_":"This paper presents a methodology for automatically detecting muscular activity by denoising, extracting features, and classifying surface electromyography (sEMG) signals. The proposed methodology utilizes the Discrete Wavelet Transform (DWT) and Willisonâ€™s Amplitude Algorithm (WAMP) for feature extraction. Five classification methods, including Neural Networks (NN), Classification Vector, XGBoost, Light Gradient Boosting Machine (LGBM), and ExtraTree, were evaluated using F-Measure, Precision, and Recall as performance metrics. Through k-fold cross-validation, the XGBoost algorithm, when combined with the Eigen values feature, achieved the highest training performance with an F1-Score of 98.71Â %. For the test group, the LGBM classifier using WAMP, and NN with both WAMP and Eigen values as features, demonstrated the best average performance with F1-Scores of 96.52Â Â±Â 3.45Â % and 96.52Â Â±Â 3.07Â %, respectively. These results highlight the precision and performance of the proposed approach in detecting EMG signals. Moreover, the framework has the potential to support clinicians in diagnosing neuromuscular disorders and developing humanâ€“machine interfaces."}],"$":{"view":"all","id":"as010"},"#name":"abstract-sec"}],"$":{"view":"all","id":"ab010","class":"author"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"},"pdf":{"urlType":"download","url":"/science/article/pii/S1746809424003240/pdfft?md5=2d0511102870720128c1569abcce583e&pid=1-s2.0-S1746809424003240-main.pdf"}},{"articleTitle":"Early detection of fake news on virtual social networks: A time-aware approach based on crowd signals","authors":"Cavalcante A.A.B., Freire P.M.S., Goldschmidt R.R., Justel C.M.","doi":"10.1016/j.eswa.2024.123350","externalArticle":false,"issn":"09574174","openAccess":0,"pii":"S095741742400215X","publicationDate":"2024-08-01","publicationTitle":"Expert Systems with Applications","publicationYear":"2024","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85183980661&md5=a4a4904d4322cad44a46119f7de567e2","scopusEid":"2-s2.0-85183980661","thirdParty":false,"volume":"Volume 247","abstract":{"$$":[{"$$":[{"$":{"id":"d1e12528"},"#name":"section-title","_":"Abstract"},{"$$":[{"$$":[{"#name":"__text__","_":"With virtual social networks (VSNs) ever more popular as a means of disseminating fake news, methods for automatically detecting this type of content have become increasingly important. Early fake news detection seeks to detect a fake news story before it is widely spread to enable the implementation of mitigatory actions to minimize its adverse effects on society. Studies based on early detection are promising, but use restricted-access data (e.g., personal and sensitive data) from usersâ€™ profiles, which is typically not available in VSNs. To address the problem of restricted data, albeit leaving aside early detection, some studies have explored using crowd signals. This approach combines the opinions (i.e., signals) of a group of users (i.e., the crowd) to detect fake news. Given this scenario, this paper hypothesizes that "},{"#name":"italic","_":"using usersâ€™ opinions can enable the early detection of fake news with results comparable to those of existing state-of-the-art methods, but without relying on restricted-access data"},{"#name":"__text__","_":". Thus, we propose a novel fake news early detection method: "},{"#name":"italic","_":"TCS"},{"#name":"__text__","_":" (Time-aware Crowd Signals). The proposed method explores the temporal nature of news propagation to detect fake news, utilizing usersâ€™ reputations obtained from their public behavior when spreading news in the past. Experiments on four different datasets show that the proposed method performance is comparable with state-of-the-art methods. As well as confirming the hypothesis, "},{"#name":"italic","_":"TCS"},{"#name":"__text__","_":" identified fake news stories in VSNs earlier than other methods without relying on restricted-access data from network users."}],"$":{"view":"all","id":"d1e12531"},"#name":"simple-para"}],"$":{"view":"all","id":"d1e12530"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e12527","class":"author"},"#name":"abstract"},{"$$":[{"$":{"id":"d1e12543"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e12552"},"#name":"para","_":"Early detection enables actions to mitigate Fake Newsâ€™ adverse effects."}],"$":{"id":"d1e12549"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e12557"},"#name":"para","_":"Early detection usually depends on users restricted data (typically unavailable)."}],"$":{"id":"d1e12554"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e12562"},"#name":"para","_":"Our method uses user implicit opinion (Crowd Signals) to early detect Fake News."}],"$":{"id":"d1e12559"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e12567"},"#name":"para","_":"Experimental evaluation demonstrated superior performance of our method."}],"$":{"id":"d1e12564"},"#name":"list-item"}],"$":{"id":"d1e12548"},"#name":"list"}],"$":{"view":"all","id":"d1e12546"},"#name":"simple-para"}],"$":{"view":"all","id":"d1e12545"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e12542","class":"author-highlights"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"},"pdf":{"urlType":"download","url":"/science/article/pii/S095741742400215X/pdfft?md5=588425b38f5ca1a7a0f177d5a05b4e32&pid=1-s2.0-S095741742400215X-main.pdf"}},{"articleTitle":"Innovative integrated workflow for data-driven production forecasting and well completion optimization: A Montney Formation case study","authors":"Rahmanifard H., Gates I.D.","doi":"10.1016/j.geoen.2024.212899","externalArticle":false,"issn":"29498910","openAccess":1,"pii":"S2949891024002690","publicationDate":"2024-07-01","publicationTitle":"Geoenergy Science and Engineering","publicationYear":"2024","scopusArticleUrl":"http://www.scopus.com/scopus/inward/record.url?partnerID=10&rel=3.0.0&view=basic&eid=2-s2.0-85192511832&md5=fa78df6c65ac174b58bb72eaff381da7","scopusEid":"2-s2.0-85192511832","thirdParty":false,"volume":"Volume 238","abstract":{"$$":[{"$$":[{"$":{"id":"sectitle0010"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"abspara0010"},"#name":"simple-para","_":"With the use of advanced data analytics and machine learning (ML) techniques, the oil and gas industry has transformed significantly in recent years. These innovations have opened new opportunities in reservoir engineering, allowing engineers to leverage data for better decision-making and well completion optimization. A key challenge in hydrocarbon exploration and production is forecasting gas production rates from unconventional sources. This is a crucial factor that affects how resources are allocated and decisions are made, requiring the application of novel techniques to enhance hydrocarbon production. Here, a novel and comprehensive automated workflow is introduced covering data collection, data preparation, feature selection, ML model development, and operational parameter optimization. The workflow uses various ML and optimization methods, including a modified Differential Evolution (MDE) algorithm, to improve gas production forecasting and optimize well completion parameters. We applied the proposed workflow to 3144 horizontal gas wells in the Montney Formation, British Columbia (BC), Canada, to assess its performance. The results showed the advantages of incorporating the initial 24 months of cumulative gas production data alongside well and completion data. Also, following the fine-tuning of hyperparameters for the ML algorithms, we identified the most effective model for forecasting cumulative gas production within the Montney Formation as a two-layer Artificial Neural Network (ANN) model. Moreover, using the MDE algorithm, the optimization results revealed the possibility of increasing gas production by more than 10% for about 47% of the wells. This research makes a significant contribution to the field of unconventional gas exploration by introducing an automated workflow that simplifies data processing, model development, and decision-making processes. It also offers valuable insights for optimizing unconventional gas production in the Montney Formation and similar reservoirs, as the energy industry moves towards more sustainable and efficient practices."}],"$":{"view":"all","id":"abssec0010"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0010","lang":"en","class":"author"},"#name":"abstract"},{"$$":[{"$":{"id":"sectitle0015"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0010"},"#name":"para","_":"New three-step method to handle missing data: blends domain expertiseÂ +Â AI/ML."}],"$":{"id":"u0010"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0015"},"#name":"para","_":"Presents ensemble model, informed by domain knowledge, for feature selection."}],"$":{"id":"u0015"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0020"},"#name":"para","_":"Method integrates historical production rates into the input data."}],"$":{"id":"u0020"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0025"},"#name":"para","_":"Systematic approach for hyperparameter tuning and model development."}],"$":{"id":"u0025"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"p0030"},"#name":"para","_":"Method suggests well performance improvement using multiple optimization algorithms."}],"$":{"id":"u0030"},"#name":"list-item"}],"$":{"id":"ulist0010"},"#name":"list"}],"$":{"view":"all","id":"abspara0015"},"#name":"simple-para"}],"$":{"view":"all","id":"abssec0015"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0015","lang":"en","class":"author-highlights"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"},"pdf":{"urlType":"download","url":"/science/article/pii/S2949891024002690/pdfft?md5=dad72ae86fd3143721c5e7a08a0146ff&pid=1-s2.0-S2949891024002690-main.pdf"}}]},"combinedContentItems":{"content":[{"#name":"keywords","$$":[{"#name":"keywords","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:xoe":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"class":"keyword","id":"kg005","view":"all"},"$$":[{"#name":"section-title","$":{"id":"st390"},"_":"Keywords"},{"#name":"keyword","$":{"id":"k0005"},"$$":[{"#name":"text","_":"Hyper-parameter optimization"}]},{"#name":"keyword","$":{"id":"k0010"},"$$":[{"#name":"text","_":"Machine learning"}]},{"#name":"keyword","$":{"id":"k0015"},"$$":[{"#name":"text","_":"Bayesian optimization"}]},{"#name":"keyword","$":{"id":"k0020"},"$$":[{"#name":"text","_":"Particle swarm optimization"}]},{"#name":"keyword","$":{"id":"k0025"},"$$":[{"#name":"text","_":"Genetic algorithm"}]},{"#name":"keyword","$":{"id":"k0030"},"$$":[{"#name":"text","_":"Grid search"}]}]}]},{"#name":"miscellaneous","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:xoe":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"ms005"},"_":"Communicated by Yuhua Cheng"}],"floats":[],"footnotes":[],"attachments":[]},"copilot":{"loading":false,"userQuestion":"","data":""},"crossMark":{"isOpen":false},"domainConfig":{"cdnAssetsHost":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com","assetRoute":"https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/402a3f5c247cf997723622b5a8bc17cc2004f90c"},"downloadIssue":{"openOnPageLoad":false,"isOpen":false,"downloadCapOpen":false,"articles":[],"selected":[]},"enrichedContent":{"tableOfContents":false,"researchData":{"hasResearchData":false,"dataProfile":{},"openData":{},"mendeleyData":{},"databaseLinking":{}},"geospatialData":{"attachments":[]},"interactiveCaseInsights":{},"virtualMicroscope":{}},"entitledRecommendations":{"openOnPageLoad":false,"isOpen":false,"articles":[],"selected":[],"currentPage":1,"totalPages":1},"exam":{},"helpText":{"keyDates":{"html":"<div class=\"text-s key-dates-help\"><h3 class=\"u-margin-s-bottom u-h4\">Publication milestones</h3><p class=\"u-margin-m-bottom\">The dates displayed for an article provide information on when various publication milestones were reached at the journal that has published the article. Where applicable, activities on preceding journals at which the article was previously under consideration are not shown (for instance submission, revisions, rejection).</p><p class=\"u-margin-xs-bottom\">The publication milestones include:</p><ul class=\"key-dates-help-list u-margin-m-bottom u-padding-s-left\"><li><span class=\"u-text-italic\">Received</span>: The date the article was originally submitted to the journal.</li><li><span class=\"u-text-italic\">Revised</span>: The date the most recent revision of the article was submitted to the journal. Dates corresponding to intermediate revisions are not shown.</li><li><span class=\"u-text-italic\">Accepted</span>: The date the article was accepted for publication in the journal.</li><li><span class=\"u-text-italic\">Available online</span>: The date a version of the article was made available online in the journal.</li><li><span class=\"u-text-italic\">Version of Record</span>: The date the finalized version of the article was made available in the journal.</li></ul><p>More information on publishing policies can be found on the <a class=\"anchor u-display-inline anchor-alternative\" href=\"https://www.elsevier.com/about/policies-and-standards/publishing-ethics\" target=\"_blank\"><span class=\"anchor-text\">Publishing Ethics Policies</span></a> page. View our <a class=\"anchor u-display-inline anchor-alternative\" href=\"https://www.elsevier.com/researcher/author/submit-your-paper\" target=\"_blank\"><span class=\"anchor-text\">Publishing with Elsevier: step-by-step</span></a> page to learn more about the publishing process. For any questions on your own submission or other questions related to publishing an article, <a class=\"anchor u-display-inline anchor-alternative\" href=\"https://service.elsevier.com/app/phone/supporthub/publishing\" target=\"_blank\"><span class=\"anchor-text\">contact our Researcher support team.</span></a></p></div>","title":"What do these dates mean?"}},"glossary":{},"issueNavigation":{"previous":{},"next":{}},"linkingHubLinks":{},"metrics":{"isOpen":true},"preview":{"content":[{"#name":"introduction","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0005","view":"all"},"$$":[{"#name":"label","_":"1"},{"#name":"section-title","$":{"id":"st005"},"_":"Introduction"},{"#name":"para","$":{"id":"p0005","view":"all"},"$$":[{"#name":"__text__","_":"Machine learning (ML) algorithms have been widely used in many applications domains, including advertising, recommendation systems, computer vision, natural language processing, and user behavior analytics [1]. This is because they are generic and demonstrate high performance in data analytics problems. Different ML algorithms are suitable for different types of problems or datasets [2]. In general, building an effective machine learning model is a complex and time-consuming process that involves determining the appropriate algorithm and obtaining an optimal model architecture by tuning its hyper-parameters (HPs) [3]. Two types of parameters exist in machine learning models: one that can be initialized and updated through the data learning process ("},{"#name":"italic","_":"e.g."},{"#name":"__text__","_":", the weights of neurons in neural networks), named model parameters; while the other, named hyper-parameters, cannot be directly estimated from data learning and must be set before training a ML model because they define the model architecture [4]. Hyper-parameters are the parameters that are used to either configure a ML model ("},{"#name":"italic","_":"e.g."},{"#name":"__text__","_":", the penalty parameter "},{"#name":"italic","_":"C"},{"#name":"__text__","_":" in a support vector machine, and the learning rate to train a neural network) or to specify the algorithm used to minimize the loss function ("},{"#name":"italic","_":"e.g."},{"#name":"__text__","_":", the activation function and optimizer types in a neural network, and the kernel type in a support vector machine) [5]."}]},{"#name":"para","$":{"id":"p0010","view":"all"},"$$":[{"#name":"__text__","_":"To build an optimal ML model, a range of possibilities must be explored. The process of designing the ideal model architecture with an optimal hyper-parameter configuration is named hyper-parameter tuning. Tuning hyper-parameters is considered a key component of building an effective ML model, especially for tree-based ML models and deep neural networks, which have many hyper-parameters [6]. Hyper-parameter tuning process is different among different ML algorithms due to their different types of hyper-parameters, including categorical, discrete, and continuous hyper-parameters [7]. Manual testing is a traditional way to tune hyper-parameters and is still prevalent in graduate student research, although it requires a deep understanding of the used ML algorithms and their hyper-parameter value settings [8]. However, manual tuning is ineffective for many problems due to certain factors, including a large number of hyper-parameters, complex models, time-consuming model evaluations, and non-linear hyper-parameter interactions. These factors have inspired increased research in techniques for automatic optimization of hyper-parameters; so-called hyper-parameter optimization (HPO) [9]. The main aim of HPO is to automate hyper-parameter tuning process and make it possible for users to apply machine learning models to practical problems effectively [3]. The optimal model architecture of a ML model is expected to be obtained after a HPO process. Some important reasons for applying HPO techniques to ML models are as follows [6]:"},{"#name":"list","$":{"id":"l0055"},"$$":[{"#name":"list-item","$":{"id":"o0005"},"$$":[{"#name":"label","_":"1."},{"#name":"para","$":{"id":"p1055","view":"all"},"_":"It reduces the human effort required, since many ML developers spend considerable time tuning the hyper-parameters, especially for large datasets or complex ML algorithms with a large number of hyper-parameters."}]},{"#name":"list-item","$":{"id":"o0010"},"$$":[{"#name":"label","_":"2."},{"#name":"para","$":{"id":"p1060","view":"all"},"_":"It improves the performance of ML models. Many ML hyper-parameters have different optimums to achieve best performance in different datasets or problems."}]},{"#name":"list-item","$":{"id":"o0015"},"$$":[{"#name":"label","_":"3."},{"#name":"para","$":{"id":"p1065","view":"all"},"_":"It makes the models and research more reproducible. Only when the same level of hyper-parameter tuning process is implemented can different ML algorithms be compared fairly; hence, using a same HPO method on different ML algorithms also helps to determine the most suitable ML model for a specific problem."}]}]}]},{"#name":"para","$":{"id":"p0015","view":"all"},"_":"It is crucial to select an appropriate optimization technique to detect optimal hyper-parameters. Traditional optimization techniques may be unsuitable for HPO problems, since many HPO problems are non-convex or non-differentiable optimization problems, and may result in a local instead of a global optimum [10]. Gradient descent-based methods are a common type of traditional optimization algorithm that can be used to tune continuous hyper-parameters by calculating their gradients [11]. For example, the learning rate in a neural network can be optimized by a gradient-based method."},{"#name":"para","$":{"id":"p0020","view":"all"},"_":"Compared with traditional optimization methods like gradient descent, many other optimization techniques are more suitable for HPO problems, including decision-theoretic approaches, Bayesian optimization models, multi-fidelity optimization techniques, and metaheuristics algorithms [7]. Apart from detecting continuous hyper-parameters, many of these algorithms also have the capacity to effectively identify discrete, categorical, and conditional hyper-parameters."},{"#name":"para","$":{"id":"p0025","view":"all"},"_":"Decision-theoretic methods are based on the concept of defining a hyper-parameter search space and then detecting the hyper-parameter combinations in the search space, ultimately selecting the best-performing hyper-parameter combination. Grid search (GS) [12] is a decision-theoretic approach that exhaustively searches the optimal configuration in a fixed domain of hyper-parameters. Random search (RS) [13] is another decision-theoretic method that randomly selects hyper-parameter combinations in the search space, given limited execution time and resources. In GS and RS, each hyper-parameter configuration is treated independently."},{"#name":"para","$":{"id":"p0030","view":"all"},"$$":[{"#name":"__text__","_":"Unlike GS and RS, Bayesian optimization (BO) [14] models determine the next hyper-parameter value based on the previous results of tested hyper-parameter values, which avoids many unnecessary evaluations; thus, BO can detect the optimal hyper-parameter combination within fewer iterations than GS and RS. To be applied to different problems, BO can model the distribution of the objective function using different models as the surrogate function, including Gaussian process (GP), random forest (RF), and tree-structured Parzen estimators (TPE) models [15]. BO-RF and BO-TPE can retain the conditionality of variables [15]. Thus, they can be used to optimize conditional hyper-parameters, like the kernel type and the penalty parameter "},{"#name":"italic","_":"C"},{"#name":"__text__","_":" in a support vector machine (SVM). However, since BO models work sequentially to balance the exploration of unexplored areas and the exploitation of currently-tested regions, it is difficult to parallelize them."}]},{"#name":"para","$":{"id":"p0035","view":"all"},"_":"Training a ML model often takes considerable time and space. Multi-fidelity optimization algorithms are developed to tackle problems with limited resources, and the most common ones being bandit-based algorithms. Hyperband [16] is a popular bandit-based optimization technique that can be considered an improved version of RS. It generates small versions of datasets and allocates a same budget to each hyper-parameter combination. In each iteration of Hyperband, poorly-performing hyper-parameter configurations are eliminated to save time and resources."},{"#name":"para","$":{"id":"p0040","view":"all"},"_":"Metaheuristic algorithms are a set of techniques used to solve complex, large search space and non-convex optimization problems to which HPO problems belong [17]. Among all metaheuristic methods, genetic algorithm (GA) [18] and particle swarm optimization (PSO) [19] are the two most prevalent metaheuristic algorithms used for HPO problems. Genetic algorithms detect well-performing hyper-parameter combinations in each generation, and pass them to the next generation until the best-performing combination is identified. In PSO algorithms, each particle communicates with other particles to detect and update the current global optimum in each iteration until the final optimum is detected. Metaheuristics can efficiently explore the search space to detect optimal or near-optimal solutions. Hence, they are particularly suitable for the HPO problems with large configuration space due to their high efficiency. For instance, they can be used in deep neural networks (DNNs) which have a large configuration space with multiple hyper-parameters, including the activation and optimizer types, the learning rate, drop-out rate, etc."},{"#name":"para","$":{"id":"p0045","view":"all"},"_":"Although using HPO algorithms to tune the hyper-parameters of ML models greatly improves the model performance, certain other aspects, like their computational complexity, still have much room for improvement. On the other hand, since different HPO models have their own advantages and suitable problems, overviewing them is necessary for proper optimization algorithm selection in terms of different types of ML models and problems."},{"#name":"para","$":{"id":"p0050","view":"all"},"$$":[{"#name":"__text__","_":"This paper makes the following contributions:"},{"#name":"list","$":{"id":"l0060"},"$$":[{"#name":"list-item","$":{"id":"o0020"},"$$":[{"#name":"label","_":"1."},{"#name":"para","$":{"id":"p1070","view":"all"},"_":"It reviews common ML algorithms and their important hyper-parameters."}]},{"#name":"list-item","$":{"id":"o0025"},"$$":[{"#name":"label","_":"2."},{"#name":"para","$":{"id":"p1075","view":"all"},"_":"It analyzes common HPO techniques, including their benefits and drawbacks, to help apply them to different ML models by appropriate algorithm selection in practical problems."}]},{"#name":"list-item","$":{"id":"o0030"},"$$":[{"#name":"label","_":"3."},{"#name":"para","$":{"id":"p1080","view":"all"},"_":"It surveys common HPO libraries and frameworks for practical use."}]},{"#name":"list-item","$":{"id":"o0035"},"$$":[{"#name":"label","_":"4."},{"#name":"para","$":{"id":"p1085","view":"all"},"_":"It discusses the open challenges and research directions of the HPO research domain."}]}]}]},{"#name":"para","$":{"id":"p0055","view":"all"},"_":"In this survey paper, we begin with a comprehensive introduction of the common optimization techniques used in ML hyper-parameter tuning problems. Section 2 introduces the main concepts of mathematical optimization and hyper-parameter optimization, as well as the general HPO process. In Section 3, we discuss the key hyper-parameters of common ML models that need to be tuned. Section 4 covers the various state-of-the-art optimization approaches that have been proposed for tackling HPO problems. In Section 5, we analyze different HPO methods and discuss how they can be applied to ML algorithms. In Section 6, we provide an introduction to various public libraries and frameworks that are developed to implement HPO. Section 7 presents and discusses the experimental results of using HPO on benchmark datasets for HPO method comparison and practical use case demonstration. In Section 8, we discuss several research directions and open challenges that should be considered to improve current HPO models or develop new HPO approaches. We conclude the paper in Section 9."}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0010","view":"all"},"$$":[{"#name":"label","_":"2"},{"#name":"section-title","$":{"id":"st010"},"_":"Mathematical optimization and hyper-parameter optimization problems"},{"#name":"para","$":{"id":"p0060","view":"all"},"_":"The key process of machine learning is to solve optimization problems. To build a ML model, its weight parameters are initialized and optimized by an optimization method until the objective function approaches a minimum value or the accuracy approaches a maximum value [20]. Similarly, hyper-parameter optimization methods aim to optimize the architecture of a ML model by detecting the optimal hyper-parameter configurations. In this section, the main concepts of mathematical optimization and"}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0025","view":"all"},"$$":[{"#name":"label","_":"3"},{"#name":"section-title","$":{"id":"st025"},"_":"Hyper-parameters in machine learning models"},{"#name":"para","$":{"id":"p0155","view":"all"},"_":"To boost ML models by HPO, firstly, we need to find out what the key hyper-parameters are that people need to tune to fit the ML models into specific problems or datasets."},{"#name":"para","$":{"id":"p0160","view":"all"},"_":"In general, ML models can be classified as supervised and unsupervised learning algorithms, based on whether they are built to model labeled or unlabeled datasets [127]. Supervised learning algorithms are a set of machine learning algorithms that map input features to a target by training on labeled data, and mainly include"}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0085","view":"all"},"$$":[{"#name":"label","_":"4"},{"#name":"section-title","$":{"id":"st085"},"_":"Hyper-parameter optimization techniques"},{"#name":"section","$":{"id":"s0090","view":"all"},"$$":[{"#name":"label","_":"4.1"},{"#name":"section-title","$":{"id":"st090"},"_":"Model-free algorithms"},{"#name":"section","$":{"id":"s0095","view":"all"},"$$":[{"#name":"label","_":"4.1.1"},{"#name":"section-title","$":{"id":"st095"},"_":"Babysitting"},{"#name":"para","$":{"id":"p0375","view":"all"},"_":"Babysitting, also called â€˜Trial and Errorâ€™ or grad student descent (GSD), is a basic hyper-parameter tuning method [8]. This method is implemented by 100% manual tuning and widely used by students and researchers. The workflow is simple: after building a ML model, a student tests many possible hyper-parameter values based on experience, guessing, or the analysis of previously-evaluated results; the process is repeated until this student runs out of time (often reaching a deadline) or is"}]}]}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0170","view":"all"},"$$":[{"#name":"label","_":"5"},{"#name":"section-title","$":{"id":"st170"},"_":"Applying optimization techniques to machine learning algorithms"},{"#name":"section","$":{"id":"s0175","view":"all"},"$$":[{"#name":"label","_":"5.1"},{"#name":"section-title","$":{"id":"st175"},"_":"Optimization techniques analysis"},{"#name":"para","$":{"id":"p0610","view":"all"},"_":"Grid search (GS) is a simple method, its major limitation being that it is time-consuming and impacted by the curse of dimensionality [79]. Thus, it is unsuitable for a large number of hyper-parameters. Moreover, GS is often not able to detect the global optimum of continuous parameters, since it requires a pre-defined, finite set of hyper-parameter values. It is also unrealistic for GS to be used to identify integer and continuous hyper-parameter optimums with limited time and resources."}]}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0210","view":"all"},"$$":[{"#name":"label","_":"6"},{"#name":"section-title","$":{"id":"st210"},"_":"Existing HPO frameworks"},{"#name":"para","$":{"id":"p0700","view":"all"},"_":"To tackle HPO problems, many open-source libraries exist to apply theory into practice and lower the threshold for ML developers. In this section, we provide a brief introduction to some popular open-source HPO libraries or frameworks mainly for Python programming. The principles behind the involved optimization algorithms are provided in Section 4."},{"#name":"section","$":{"id":"s0215","view":"all"},"$$":[{"#name":"label","_":"6.1"},{"#name":"section-title","$":{"id":"st215"},"_":"Sklearn"},{"#name":"para","$":{"id":"p0705","view":"all"},"_":"In sklearn [30], â€˜GridSearchCVâ€™ can be implemented to detect the optimal hyper-parameters using the GS algorithm. Each hyper-parameter value in the"}]}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0300","view":"all"},"$$":[{"#name":"label","_":"7"},{"#name":"section-title","$":{"id":"st300"},"_":"Experiments"},{"#name":"para","$":{"id":"p0790","view":"all"},"_":"To summarize the content of Sections 3 Hyper-parameters in machine learning models, 4 Hyper-parameter optimization techniques, 5 Applying optimization techniques to machine learning algorithms, 6 Existing HPO frameworks, a comprehensive overview of applying hyper-parameter optimization techniques to ML models is shown in Table 2. It provides a summary of common ML algorithms, their hyper-parameters, suitable optimization methods, and available Python libraries; thus, data analysts and"}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0315","view":"all"},"$$":[{"#name":"label","_":"8"},{"#name":"section-title","$":{"id":"st315"},"_":"Open issues, challenges, and future research directions"},{"#name":"para","$":{"id":"p0865","view":"all"},"_":"Although there have been many existing HPO algorithms and practical frameworks, some issues still need to be addressed, and several aspects in this domain could be improved. In this section, we discuss the open challenges, current research questions, and potential research directions in the future. They can be classified as model complexity challenges and model performance challenges, as summarized in Table 10."},{"#name":"section","$":{"id":"s0320","view":"all"},"$$":[{"#name":"label","_":"8.1"},{"#name":"section-title","$":{"id":"st320"},"_":"Model complexity"},{"#name":"section","$":{"id":"s0325","view":"all"},"$$":[{"#name":"label","_":"8.1.1"},{"#name":"section-title","$":{"id":"st325"},"_":"Costly objective function evaluations"},{"#name":"para","$":{"id":"p0870","view":"all"},"_":"To evaluate the performance of a ML model with different hyper-parameter"}]}]}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0370","view":"all"},"$$":[{"#name":"label","_":"9"},{"#name":"section-title","$":{"id":"st370"},"_":"Conclusion"},{"#name":"para","$":{"id":"p0940","view":"all"},"_":"Machine learning has become the primary strategy for tackling data-related problems and has been widely used in various applications. To apply ML models to practical problems, their hyper-parameters need to be tuned to fit specific datasets. However, since the scale of produced data is greatly increased in real-life, and manually tuning hyper-parameters is extremely computationally expensive, it has become crucial to optimize hyper-parameters by an automatic process. In this survey paper, we"}]}]},{"#name":"section","$$":[{"#name":"section","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"s0380","view":"all"},"$$":[{"#name":"section-title","$":{"id":"st380"},"_":"CRediT authorship contribution statement"},{"#name":"para","$":{"id":"p0950","view":"all"},"$$":[{"#name":"bold","_":"Li Yang:"},{"#name":"__text__","_":" Conceptualization, Methodology, Software, Validation, Formal analysis, Investigation, Data curation, Writing - original draft, Visualization. "},{"#name":"bold","_":"Abdallah Shami:"},{"#name":"__text__","_":" Conceptualization, Resources, Writing - review & editing, Supervision, Project administration, Funding acquisition."}]}]}]},{"#name":"section","$$":[{"#name":"conflict-of-interest","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"coi005","view":"all"},"$$":[{"#name":"section-title","$":{"id":"st700"},"_":"Declaration of Competing Interest"},{"#name":"para","$":{"id":"p0945","view":"all"},"_":"The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper."}]}]},{"#name":"section","$$":[{"#name":"biography","$":{"xmlns:ce":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bg005","view":"all"},"$$":[{"#name":"link","$":{"id":"lk005","locator":"fx1","href":"pii:S0925231220311693/fx1","role":"http://data.elsevier.com/vocabulary/ElsevierContentTypes/23.4","type":"simple"}},{"#name":"simple-para","$":{"id":"sp010","view":"all"},"$$":[{"#name":"bold","_":"Li Yang"},{"#name":"__text__","_":" received the B.E. degree in computer science from Wuhan University of Science and Technology, Wuhan, China in 2016 and the MASc degree in Engineering from University of Guelph, Guelph, Canada, 2018. Since 2018 he has been working toward the Ph.D. degree in the Department of Electrical and Computer Engineering, Western University, London, Canada. His research interests include cybersecurity, machine learning, data analytics, and intelligent transportation systems."}]}]}]}],"floats":[],"footnotes":[],"attachments":[]},"questionsAndAnswers":{},"rawtext":"","recommendations":{"articles":[{"pii":"S0950705120302999","doi":"10.1016/j.knosys.2020.105992","journalTitle":"Knowledge-Based Systems","publicationYear":"2020","publicationDate":"2020-07-20","volumeSupText":"Volume 200","articleNumber":"105992","pageRange":"105992","trace-token":"AAAAQGTADEJlbKEBkdkl1bedFjuAUTjMFYGYD4LPPnmWuK5opBGpCxrOR-UFJvysqoxcyT4WSeUpfThOoVbwHKgVf6KL4imGWIGfAXJWLLSeSJcx75zNXQ","authors":{"content":[{"#name":"author-group","$":{"id":"d1e1754"},"$$":[{"#name":"author","$":{"id":"au000001","author-id":"S0950705120302999-806362fe79510f90e63aaa432aeeadd9"},"$$":[{"#name":"given-name","_":"MohammadNoor"},{"#name":"surname","_":"Injadat"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Methodology"},"_":"Methodology"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Software"},"_":"Software"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Formal_analysis"},"_":"Formal analysis"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Investigation"},"_":"Investigation"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_original_draft"},"_":"Writing - original draft"},{"#name":"cross-ref","$":{"refid":"aff1","id":"d1e1772"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea1","type":"email","href":"mailto:minjadat@uwo.ca"},"_":"minjadat@uwo.ca"}]},{"#name":"author","$":{"id":"au000002","author-id":"S0950705120302999-93f4bf901febacfc923033d1330cefaa"},"$$":[{"#name":"given-name","_":"Abdallah"},{"#name":"surname","_":"Moubayed"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_original_draft"},"_":"Writing - original draft"},{"#name":"cross-ref","$":{"refid":"aff1","id":"d1e1786"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea2","type":"email","href":"mailto:amoubaye@uwo.ca"},"_":"amoubaye@uwo.ca"}]},{"#name":"author","$":{"id":"au000003","author-id":"S0950705120302999-db6f84bc22efa1bbc879be81e37357e3"},"$$":[{"#name":"given-name","_":"Ali Bou"},{"#name":"surname","_":"Nassif"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_review_%26_editing"},"_":"Writing - review & editing"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Supervision"},"_":"Supervision"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Project_administration"},"_":"Project administration"},{"#name":"cross-ref","$":{"refid":"aff2","id":"d1e1804"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"cross-ref","$":{"refid":"aff1","id":"d1e1807"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"refid":"cor1","id":"d1e1810"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"âŽ"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea3","type":"email","href":"mailto:anassif@sharjah.ac.ae"},"_":"anassif@sharjah.ac.ae"}]},{"#name":"author","$":{"id":"au000004","author-id":"S0950705120302999-a768414c0192b66856adf769e2f486c1"},"$$":[{"#name":"given-name","_":"Abdallah"},{"#name":"surname","_":"Shami"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_review_%26_editing"},"_":"Writing - review & editing"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Supervision"},"_":"Supervision"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Project_administration"},"_":"Project administration"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Funding_acquisition"},"_":"Funding acquisition"},{"#name":"cross-ref","$":{"refid":"aff1","id":"d1e1830"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea4","type":"email","href":"mailto:abdallah.shami@uwo.ca"},"_":"abdallah.shami@uwo.ca"}]},{"#name":"affiliation","$":{"affiliation-id":"S0950705120302999-f03631989f35e154d37d9525ef8e4f95","id":"aff1"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","_":"Electrical & Computer Engineering Dept., University of Western Ontario, London, ON, Canada"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Electrical & Computer Engineering Dept., University of Western Ontario"},{"#name":"city","_":"London"},{"#name":"state","_":"ON"},{"#name":"country","_":"Canada"}]},{"#name":"source-text","$":{"id":"afs54"},"_":"Electrical & Computer Engineering Dept., University of Western Ontario, London, ON, Canada"}]},{"#name":"affiliation","$":{"affiliation-id":"S0950705120302999-3fe8c7a0aba0eed79ee914a1c357f241","id":"aff2"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","_":"Computer Engineering Dept., University of Sharjah, Sharjah, United Arab Emirates"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Computer Engineering Dept., University of Sharjah"},{"#name":"city","_":"Sharjah"},{"#name":"country","_":"United Arab Emirates"}]},{"#name":"source-text","$":{"id":"afs55"},"_":"Computer Engineering Dept., University of Sharjah, Sharjah, UAE"}]},{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"âŽ"},{"#name":"text","_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au000004","author-id":"S0950705120302999-a768414c0192b66856adf769e2f486c1"},"$$":[{"#name":"given-name","_":"Abdallah"},{"#name":"surname","_":"Shami"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_review_%26_editing"},"_":"Writing - review & editing"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Supervision"},"_":"Supervision"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Project_administration"},"_":"Project administration"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Funding_acquisition"},"_":"Funding acquisition"},{"#name":"cross-ref","$":{"refid":"aff1","id":"d1e1830"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea4","type":"email","href":"mailto:abdallah.shami@uwo.ca"},"_":"abdallah.shami@uwo.ca"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"d1e1751"},"_":"Systematic ensemble model selection approach for educational data mining"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","abstract":{"$$":[{"$$":[{"$$":[{"#name":"attachment-eid","_":"1-s2.0-S0950705120302999-si1.svg"},{"#name":"ucs-locator","_":"https://s3-eu-west-1.amazonaws.com/prod-ucs-content-store-eu-west/content/pii:S0950705120302999/STRIPIN/image/svg+xml/e4114160b8ce89ba0f1c7ec9e7e5caed/si1.svg"},{"#name":"file-basename","_":"si1"},{"#name":"abstract-attachment","_":"true"},{"#name":"filename","_":"si1.svg"},{"#name":"extension","_":"svg"},{"#name":"filesize","_":"1705"},{"#name":"attachment-type","_":"ALTIMG"}],"$":{"xmlns:xocs":true},"#name":"attachment"}],"#name":"attachments"},{"$$":[{"$":{"id":"d1e1875"},"#name":"section-title","_":"Abstract"},{"$$":[{"$$":[{"#name":"__text__","_":"A plethora of research has been done in the past focusing on predicting studentâ€™s performance in order to support their development. Many institutions are focused on improving the performance and the education quality; and this can be achieved by utilizing data mining techniques to analyze and predict studentsâ€™ performance and to determine possible factors that may affect their final marks. To address this issue, this work starts by thoroughly exploring and analyzing two different datasets at two separate stages of course delivery (20% and 50% respectively) using multiple graphical, statistical, and quantitative techniques. The feature analysis provides insights into the nature of the different features considered and helps in the choice of the machine learning algorithms and their parameters. Furthermore, this work proposes a systematic approach based on Gini index and "},{"$$":[{"#name":"mi","_":"p"}],"$":{"xmlns:mml":true,"altimg":"si1.svg","display":"inline","id":"d1e1881"},"#name":"math"},{"#name":"__text__","_":"-value to select a suitable ensemble learner from a combination of six potential machine learning algorithms. Experimental results show that the proposed ensemble models achieve high accuracy and low false positive rate at all stages for both datasets."}],"$":{"view":"all","id":"d1e1878"},"#name":"simple-para"}],"$":{"view":"all","id":"d1e1877"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e1874","class":"author"},"#name":"abstract"},{"$$":[{"$":{"id":"d1e1886"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e1895"},"#name":"para","_":"Implement EDM techniques to identify at risk students during course delivery."}],"$":{"id":"d1e1892"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e1900"},"#name":"para","_":"Analyze two educational datasets at two course delivery stages using various methods."}],"$":{"id":"d1e1897"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$$":[{"#name":"__text__","_":"Propose a systematic approach based on Gini index and "},{"$$":[{"#name":"mi","_":"p"}],"$":{"xmlns:mml":true,"altimg":"si1.svg","display":"inline","id":"d1e1908"},"#name":"math"},{"#name":"__text__","_":"-value for ensemble selection."}],"$":{"view":"all","id":"d1e1905"},"#name":"para"}],"$":{"id":"d1e1902"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e1915"},"#name":"para","_":"Results show that the ensemble models achieve high accuracy and high specificity."}],"$":{"id":"d1e1912"},"#name":"list-item"}],"$":{"id":"d1e1891"},"#name":"list"}],"$":{"view":"all","id":"d1e1889"},"#name":"simple-para"}],"$":{"view":"all","id":"d1e1888"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e1885","class":"author-highlights"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"},"pdf":{"urlType":null},"iss-first":"","vol-first":"200","isThirdParty":false,"language":"en","issn-primary-unformatted":"09507051","issn-primary-formatted":"0950-7051"},{"pii":"S2210670720304960","doi":"10.1016/j.scs.2020.102275","journalTitle":"Sustainable Cities and Society","publicationYear":"2020","publicationDate":"2020-10-01","volumeSupText":"Volume 61","articleNumber":"102275","pageRange":"102275","trace-token":"AAAAQGTADEJlbKEBkdkl1bedFjsShGekhMvlbN4Frj0pSdwJqAC7Brpu47yIwjxXGIOs6tYzWaUgN5ti9wsd0EIzIjg-3TPvFmi2mIi3oEcFaoDrTJU3Sg","authors":{"content":[{"#name":"author-group","$":{"id":"aug0005"},"$$":[{"#name":"author","$":{"id":"aut0005","biographyid":"vt0005","orcid":"0000-0001-6257-9941","author-id":"S2210670720304960-f20b7972fe4fea5d86918d2b9a356f4b"},"$$":[{"#name":"given-name","_":"Rabiya"},{"#name":"surname","_":"Khalid"}]},{"#name":"author","$":{"id":"aut0010","biographyid":"vt0010","orcid":"0000-0003-3777-8249","author-id":"S2210670720304960-889e42e1d9b1b8b841d2e78f62bfc060"},"$$":[{"#name":"given-name","_":"Nadeem"},{"#name":"surname","_":"Javaid"},{"#name":"cross-ref","$":{"id":"crf0490","refid":"fn0005"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"1"}]},{"#name":"cross-ref","$":{"id":"crf0495","refid":"cor0005"},"_":"*"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"eadd0005","type":"email","href":"mailto:nadeemjavaidqau@gmail.com"},"_":"nadeemjavaidqau@gmail.com"}]},{"#name":"affiliation","$":{"id":"aff0005","affiliation-id":"S2210670720304960-3a08d223480507c2ce72ff8da4ac836b"},"$$":[{"#name":"textfn","_":"Department of Computer Science, COMSATS University Islamabad, Islamabad 44000, Pakistan"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Computer Science, COMSATS University Islamabad"},{"#name":"city","_":"Islamabad"},{"#name":"postal-code","_":"44000"},{"#name":"country","_":"Pakistan"}]},{"#name":"source-text","$":{"id":"sot0005"},"_":"Department of Computer Science, COMSATS University Islamabad, Islamabad 44000, Pakistan"}]},{"#name":"correspondence","$":{"id":"cor0005"},"$$":[{"#name":"label","_":"âŽ"},{"#name":"text","_":"Corresponding author."}]},{"#name":"footnote","$":{"id":"fn0005"},"$$":[{"#name":"label","_":"1"},{"#name":"note-para","$":{"id":"npar0005","view":"all"},"$$":[{"#name":"inter-ref","$":{"xmlns:xlink":true,"id":"intr0005","href":"http://www.njavaid.com","type":"simple"},"_":"http://www.njavaid.com"},{"#name":"__text__","_":"."}]}]}]}],"floats":[],"footnotes":[{"#name":"footnote","$":{"id":"fn0005"},"$$":[{"#name":"label","_":"1"},{"#name":"note-para","$":{"id":"npar0005","view":"all"},"$$":[{"#name":"inter-ref","$":{"xmlns:xlink":true,"id":"intr0005","href":"http://www.njavaid.com","type":"simple"},"_":"http://www.njavaid.com"},{"#name":"__text__","_":"."}]}]}],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"aut0010","biographyid":"vt0010","orcid":"0000-0003-3777-8249","author-id":"S2210670720304960-889e42e1d9b1b8b841d2e78f62bfc060"},"$$":[{"#name":"given-name","_":"Nadeem"},{"#name":"surname","_":"Javaid"},{"#name":"cross-ref","$":{"id":"crf0490","refid":"fn0005"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"1"}]},{"#name":"cross-ref","$":{"id":"crf0495","refid":"cor0005"},"_":"*"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"eadd0005","type":"email","href":"mailto:nadeemjavaidqau@gmail.com"},"_":"nadeemjavaidqau@gmail.com"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"dochead","$":{"id":"doh0005"},"$$":[{"#name":"textfn","_":"Engineering advance"}]},{"#name":"title","$":{"id":"tit0005"},"_":"A survey on hyperparameters optimization algorithms of forecasting models in smart grid"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"rev","content-family":"serial","contentType":"JL","entitlementType":"","abstract":{"$$":[{"$$":[{"$":{"id":"sect0005"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"par0005"},"#name":"para","_":"Comparison of hyperparameters optimization, error, forecasting and preprocessing methods."}],"$":{"id":"lsti0005"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"par0010"},"#name":"para","_":"We critically analyzed data preprocessing models and highlighted important findings."}],"$":{"id":"lsti0010"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"par0015"},"#name":"para","_":"A survey of existing survey papers (ESPs) is conductedÂ·Recency score of ESPs is computed based on number of recent papers reviewed in them."}],"$":{"id":"lsti0015"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"par0020"},"#name":"para","_":"Future research directions are discussed in detail."}],"$":{"id":"lsti0020"},"#name":"list-item"}],"$":{"id":"lis0005"},"#name":"list"}],"$":{"view":"all","id":"spar0055"},"#name":"simple-para"}],"$":{"view":"all","id":"abst0005"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0005","class":"author-highlights"},"#name":"abstract"},{"$$":[{"$":{"id":"sect0010"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"spar0060"},"#name":"simple-para","_":"Forecasting in the smart grid (SG) plays a vital role in maintaining the balance between demand and supply of electricity, efficient energy management, better planning of energy generation units and renewable energy sources and their dispatching and scheduling. Existing forecasting models are being used and new models are developed for a wide range of SG applications. These algorithms have hyperparameters which need to be optimized carefully before forecasting. The optimized values of these algorithms increase the forecasting accuracy up to a significant level. In this paper, we present a brief literature review of forecasting models and the optimization methods used to tune their hyperparameters. In addition, we have also discussed the data preprocessing methods. A comparative analysis of these forecasting models, according to their hyperparameter optimization, error methods and preprocessing methods, is also presented. Besides, we have critically analyzed the existing optimization and data preprocessing models and highlighted the important findings. A survey of existing survey papers is also presented and their recency score is computed based on the number of recent papers reviewed in them. By recent, we mean that the year in which a survey paper is published and its previous three years. Finally, future research directions are discussed in detail."}],"$":{"view":"all","id":"abst0010"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0010","class":"author"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"},"pdf":{"urlType":null},"iss-first":"","vol-first":"61","isThirdParty":false,"language":"en","issn-primary-unformatted":"22106707","issn-primary-formatted":"2210-6707"},{"pii":"S0950705119301923","doi":"10.1016/j.knosys.2019.04.019","journalTitle":"Knowledge-Based Systems","publicationYear":"2019","publicationDate":"2019-08-15","volumeSupText":"Volume 178","articleNumber":"","pageRange":"74-83","trace-token":"AAAAQGTADEJlbKEBkdkl1bedFjsHpgp6qE_9-T_BJlPt7Ybwq7wz3GndelbBshLn36iUEs4SqatK-UrD2qFu4Wc0miro192pzO_e3cs9LzSTm61-Getcgw","authors":{"content":[{"#name":"author-group","$":{"id":"d1e311"},"$$":[{"#name":"author","$":{"id":"au000001","author-id":"S0950705119301923-e65bc02a66cd303bdce77e114db02ee5"},"$$":[{"#name":"given-name","_":"YoungJun"},{"#name":"surname","_":"Yoo"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea1","type":"email","href":"mailto:youdalj@postech.ac.kr"},"_":"youdalj@postech.ac.kr"}]},{"#name":"affiliation","$":{"affiliation-id":"S0950705119301923-e0484ce7accf8f4242ae4e4c2d6765ca","id":"aff1"},"$$":[{"#name":"textfn","_":"Department of Electronic Engineering, Pohang University of Science and Technology (POSTECH), San 31, Hyojadong, Namgu, Pohang, Gyungbuk, 790-784, Republic of Korea"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Department of Electronic Engineering, Pohang University of Science and Technology (POSTECH)"},{"#name":"address-line","_":"San 31, Hyojadong, Namgu, Pohang"},{"#name":"city","_":"Gyungbuk"},{"#name":"postal-code","_":"790-784"},{"#name":"country","_":"Republic of Korea"}]},{"#name":"source-text","$":{"id":"afs32"},"_":"Department of Electronic Engineering, Pohang University of Science and Technology (POSTECH), San 31, Hyojadong, Namgu, Pohang, Gyungbuk, 790-784, Republic of Korea"}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au000001","author-id":"S0950705119301923-e65bc02a66cd303bdce77e114db02ee5"},"$$":[{"#name":"given-name","_":"YoungJun"},{"#name":"surname","_":"Yoo"},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea1","type":"email","href":"mailto:youdalj@postech.ac.kr"},"_":"youdalj@postech.ac.kr"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"article-footnote","$":{"id":"aep-article-footnote-id1"},"$$":[{"#name":"label","_":"â˜†"},{"#name":"note-para","$":{"view":"all","id":"d1e303"},"$$":[{"#name":"__text__","_":"No author associated with this paper has disclosed any potential or pertinent conflicts which may be perceived to have impending conflict with this work. For full disclosure statements refer to "},{"#name":"inter-ref","$":{"xmlns:xlink":true,"id":"interref1","href":"https://doi.org/10.1016/j.knosys.2019.04.019","type":"simple"},"_":"https://doi.org/10.1016/j.knosys.2019.04.019"},{"#name":"__text__","_":".."}]}]},{"#name":"title","$":{"id":"d1e308"},"_":"Hyperparameter optimization of deep neural network using univariate dynamic encoding algorithm for searches"}],"floats":[],"footnotes":[{"#name":"article-footnote","$":{"id":"aep-article-footnote-id1"},"$$":[{"#name":"label","_":"â˜†"},{"#name":"note-para","$":{"view":"all","id":"d1e303"},"$$":[{"#name":"__text__","_":"No author associated with this paper has disclosed any potential or pertinent conflicts which may be perceived to have impending conflict with this work. For full disclosure statements refer to "},{"#name":"inter-ref","$":{"xmlns:xlink":true,"id":"interref1","href":"https://doi.org/10.1016/j.knosys.2019.04.019","type":"simple"},"_":"https://doi.org/10.1016/j.knosys.2019.04.019"},{"#name":"__text__","_":".."}]}]}],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","abstract":{"$$":[{"$$":[{"$":{"id":"d1e340"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"d1e343"},"#name":"simple-para","_":"This paper proposes a method to find the hyperparameter tuning for a deep neural network by using a univariate dynamic encoding algorithm for searches. Optimizing hyperparameters for such a neural network is difficult because the neural network that has several parameters to configure; furthermore, the training speed for such a network is slow. The proposed method was tested for two neural network models; an autoencoder and a convolution neural network with the Modified National Institute of Standards and Technology (MNIST) dataset. To optimize hyperparameters with the proposed method, the cost functions were selected as the average of the difference between the decoded value and the original image for the autoencoder, and the inverse of the evaluation accuracy for the convolution neural network. The hyperparameters were optimized using the proposed method with fast convergence speed and few computational resources, and the results were compared with those of the other considered optimization algorithms (namely, simulated annealing, genetic algorithm, and particle swarm algorithm) to show the effectiveness of the proposed methodology."}],"$":{"view":"all","id":"d1e342"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e339","class":"author"},"#name":"abstract"},{"$$":[{"$":{"id":"d1e346"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e355"},"#name":"para","_":"An optimization method for hyper-parameters for a deep neural network."}],"$":{"id":"d1e352"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e360"},"#name":"para","_":"Performing optimization of the network using a univariate dynamic encoding algorithm for searches."}],"$":{"id":"d1e357"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e365"},"#name":"para","_":"Validation of the proposed method with two neural network model with MNIST data set."}],"$":{"id":"d1e362"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"d1e370"},"#name":"para","_":"Fast convergence speed and a small computational amount to optimize hyper-parameter of the network."}],"$":{"id":"d1e367"},"#name":"list-item"}],"$":{"id":"d1e351"},"#name":"list"}],"$":{"view":"all","id":"d1e349"},"#name":"simple-para"}],"$":{"view":"all","id":"d1e348"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e345","class":"author-highlights"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"},"pdf":{"urlType":null},"iss-first":"","vol-first":"178","isThirdParty":false,"language":"en","issn-primary-unformatted":"09507051","issn-primary-formatted":"0950-7051"},{"pii":"S2214212621000430","doi":"10.1016/j.jisa.2021.102804","journalTitle":"Journal of Information Security and Applications","publicationYear":"2021","publicationDate":"2021-05-01","volumeSupText":"Volume 58","articleNumber":"102804","pageRange":"102804","trace-token":"AAAAQGTADEJlbKEBkdkl1bedFjtmkruIxWKH_RN2IXOjZd89JMikmlL04FQpOR8p2taKF7S2IpDkhjTtuhe_uAc907ByIB9Bos131-pdsGg_5H2b0lW8CA","authors":{"content":[{"#name":"author-group","$":{"id":"d1e1585"},"$$":[{"#name":"author","$":{"id":"au000001","author-id":"S2214212621000430-339389c4a0553f6bc2c01a2fb5919855"},"$$":[{"#name":"given-name","_":"Yesi Novaria"},{"#name":"surname","_":"Kunang"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Software"},"_":"Software"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Visualization"},"_":"Visualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Investigation"},"_":"Investigation"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_original_draft"},"_":"Writing - original draft"},{"#name":"cross-ref","$":{"refid":"aff1","id":"d1e1599"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"refid":"aff2","id":"d1e1602"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"cross-ref","$":{"refid":"aff5","id":"d1e1605"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"e"}]}]},{"#name":"author","$":{"id":"au000002","author-id":"S2214212621000430-43b2ca2d00b13392e44cd1e951773851"},"$$":[{"#name":"given-name","_":"Siti"},{"#name":"surname","_":"Nurmaini"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Supervision"},"_":"Supervision"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Conceptualization"},"_":"Conceptualization"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Methodology"},"_":"Methodology"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_review_%26_editing"},"_":"Writing - review & editing"},{"#name":"cross-ref","$":{"refid":"aff2","id":"d1e1621"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"cross-ref","$":{"refid":"cor1","id":"d1e1624"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"âŽ"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"id":"ea1","type":"email","href":"mailto:sitinurmaini@gmail.com"},"_":"sitinurmaini@gmail.com"}]},{"#name":"author","$":{"id":"au000003","author-id":"S2214212621000430-5e686a5bd1440864d0b2d86e57ac23b5"},"$$":[{"#name":"given-name","_":"Deris"},{"#name":"surname","_":"Stiawan"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Data_curation"},"_":"Data curation"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Validation"},"_":"Validation"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_review_%26_editing"},"_":"Writing - review & editing"},{"#name":"cross-ref","$":{"refid":"aff3","id":"d1e1640"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"c"}]}]},{"#name":"author","$":{"id":"au000004","author-id":"S2214212621000430-eaca7961ba444bf1592db4ea2d9a59c8"},"$$":[{"#name":"given-name","_":"Bhakti Yudho"},{"#name":"surname","_":"Suprapto"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Validation"},"_":"Validation"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_review_%26_editing"},"_":"Writing - review & editing"},{"#name":"cross-ref","$":{"refid":"aff4","id":"d1e1652"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"d"}]}]},{"#name":"affiliation","$":{"affiliation-id":"S2214212621000430-a3444eba2c6c6b1113d97640730e8def","id":"aff1"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","_":"Doctoral Engineering Department, Faculty of Engineering, Universitas Sriwijaya, Palembang, Indonesia"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Doctoral Engineering Department, Faculty of Engineering, Universitas Sriwijaya"},{"#name":"city","_":"Palembang"},{"#name":"country","_":"Indonesia"}]},{"#name":"source-text","$":{"id":"afs80"},"_":"Doctoral Engineering Departement, Faculty of Engineering, Universitas Sriwijaya, Palembang, Indonesia"}]},{"#name":"affiliation","$":{"affiliation-id":"S2214212621000430-dfd9a9a651e527433bd61e11c74cfe58","id":"aff2"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","_":"Intelligent System Research Group, Faculty of Computer Science, Universitas Sriwijaya, Palembang, Indonesia"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Intelligent System Research Group, Faculty of Computer Science, Universitas Sriwijaya"},{"#name":"city","_":"Palembang"},{"#name":"country","_":"Indonesia"}]},{"#name":"source-text","$":{"id":"afs81"},"_":"Intelligent System Research Group, Faculty of Computer Science Department, Universitas Sriwijaya, Palembang, Indonesia"}]},{"#name":"affiliation","$":{"affiliation-id":"S2214212621000430-30fafa22272968e38280c67801da8a30","id":"aff3"},"$$":[{"#name":"label","_":"c"},{"#name":"textfn","_":"Computer Networking & Information Systems, Faculty of Computer Science, Universitas Sriwijaya, Palembang, Indonesia"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Computer Networking & Information Systems, Faculty of Computer Science, Universitas Sriwijaya"},{"#name":"city","_":"Palembang"},{"#name":"country","_":"Indonesia"}]},{"#name":"source-text","$":{"id":"afs82"},"_":"Computer Networking & Information Systems, Faculty of Computer Science Department, Universitas Sriwijaya, Palembang, Indonesia"}]},{"#name":"affiliation","$":{"affiliation-id":"S2214212621000430-d41de7ce8b1138616c57515672ae7803","id":"aff4"},"$$":[{"#name":"label","_":"d"},{"#name":"textfn","_":"Electrical Engineering Department, Faculty of Engineering, Universitas Srwijaya, Palembang, Indonesia"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Electrical Engineering Department, Faculty of Engineering, Universitas Srwijaya"},{"#name":"city","_":"Palembang"},{"#name":"country","_":"Indonesia"}]},{"#name":"source-text","$":{"id":"afs83"},"_":"Electrical Engineering Departement, Universitas Srwijaya, Palembang, Indonesia"}]},{"#name":"affiliation","$":{"affiliation-id":"S2214212621000430-eca04d097bad12491e597528853c210b","id":"aff5"},"$$":[{"#name":"label","_":"e"},{"#name":"textfn","_":"Faculty of Computer Science, Universitas Bina Darma, Palembang, Indonesia"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"Faculty of Computer Science, Universitas Bina Darma"},{"#name":"city","_":"Palembang"},{"#name":"country","_":"Indonesia"}]},{"#name":"source-text","$":{"id":"afs84"},"_":"Computer Science Departement, Universitas Bina Darma, Palembang, Indonesia"}]},{"#name":"correspondence","$":{"id":"cor1"},"$$":[{"#name":"label","_":"âŽ"},{"#name":"text","_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au000004","author-id":"S2214212621000430-eaca7961ba444bf1592db4ea2d9a59c8"},"$$":[{"#name":"given-name","_":"Bhakti Yudho"},{"#name":"surname","_":"Suprapto"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Validation"},"_":"Validation"},{"#name":"contributor-role","$":{"role":"http://dictionary.casrai.org/Contributor_Roles/Writing_%E2%80%93_review_%26_editing"},"_":"Writing - review & editing"},{"#name":"cross-ref","$":{"refid":"aff4","id":"d1e1652"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"d"}]}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"d1e1582"},"_":"Attack classification of an intrusion detection system using deep learning and hyperparameter optimization"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","abstract":{"$$":[{"$$":[{"$":{"id":"d1e1733"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"d1e1736"},"#name":"simple-para","_":"A network intrusion detection system (NIDS) is a solution that mitigates the threat of attacks on a network. The success of a NIDS depends on the success of its algorithm and the performance of its method in recognizing attacks. We propose a deep learning intrusion detection system (IDS) using a pretraining approach with deep autoencoder (PTDAE) combined with a deep neural network (DNN). Models were developed using hyperparameter optimization procedures. This research provides an alternative solution to deep learning structure models through an automatic hyperparameter optimization process that combines grid search and random search techniques. The automated hyperparameter optimization process helps determine the value of hyperparameters and the best categorical hyperparameter configuration to improve detection performance. The proposed model was tested on the NSL-KDD, and CSE-CIC-ID2018 datasets. In the pretraining phase, we present the results of applying our technique to three feature extraction methods: deep autoencoder (DAE), autoencoder (AE), and stack autoencoder (SAE). The best results are obtained for the DAE method. These performance results also successfully outperform previous approaches in terms of performance metrics in multiclass classification."}],"$":{"view":"all","id":"d1e1735"},"#name":"abstract-sec"}],"$":{"view":"all","id":"d1e1732","class":"author"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"},"pdf":{"urlType":null},"iss-first":"","vol-first":"58","isThirdParty":false,"language":"en","issn-primary-unformatted":"22142126","issn-primary-formatted":"2214-2126"},{"pii":"S0957417417301008","doi":"10.1016/j.eswa.2017.02.017","journalTitle":"Expert Systems with Applications","publicationYear":"2017","publicationDate":"2017-07-15","volumeSupText":"Volume 78","articleNumber":"","pageRange":"225-241","trace-token":"AAAAQGTADEJlbKEBkdkl1bedFjuxO_dyGSZE26lxLfcp_FW4t6Bstvl63ytQfo4JevbqxH_0fFhHI4vESCARvtm7Frxlav6egOMJ0S3N2c4QDI5r7XU8Fw","authors":{"content":[{"#name":"author-group","$":{"id":"aut0001"},"$$":[{"#name":"author","$":{"id":"au0001","author-id":"S0957417417301008-faa690180ab9f1936cc1dada4557f9c8"},"$$":[{"#name":"surname","_":"Xia"},{"#name":"given-name","_":"Yufei"},{"#name":"cross-ref","$":{"id":"crf0001","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"id":"ead0001","type":"email"},"_":"xiareyoung@cumt.edu.cn"}]},{"#name":"author","$":{"id":"au0002","author-id":"S0957417417301008-2c7b106d4f5e603f1051a4d3e8ca779e"},"$$":[{"#name":"surname","_":"Liu"},{"#name":"given-name","_":"Chuanzhe"},{"#name":"cross-ref","$":{"id":"crf0002","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0003","refid":"cor0001"},"_":"*"},{"#name":"e-address","$":{"id":"ead0002","type":"email"},"_":"rdean@cumt.edu.cn"}]},{"#name":"author","$":{"id":"au0003","author-id":"S0957417417301008-ef9ef7f74b39c0e8241956d88c158093"},"$$":[{"#name":"surname","_":"Li"},{"#name":"given-name","_":"YuYing"},{"#name":"cross-ref","$":{"id":"crf0004","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"e-address","$":{"id":"ead0003","type":"email"},"_":"cumtlyy@163.com"}]},{"#name":"author","$":{"id":"au0004","author-id":"S0957417417301008-ca98b43027b9e7f05d51c4df5e7d2a65"},"$$":[{"#name":"surname","_":"Liu"},{"#name":"given-name","_":"Nana"},{"#name":"cross-ref","$":{"id":"crf0005","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"id":"ead0004","type":"email"},"_":"liunana1004@163.com"}]},{"#name":"affiliation","$":{"id":"aff0001"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","$":{"id":"cetextfn0001"},"_":"School of Management, China University of Mining and Technology, Xuzhou, Jiangsu 221116, PR China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Management"},{"#name":"organization","_":"China University of Mining and Technology"},{"#name":"city","_":"Xuzhou"},{"#name":"state","_":"Jiangsu"},{"#name":"postal-code","_":"221116"},{"#name":"country","_":"PR China"}]}]},{"#name":"affiliation","$":{"id":"aff0002"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","$":{"id":"cetextfn0002"},"_":"School of Foreign Studies, China University of Mining and Technology, Xuzhou, Jiangsu 221116, PR China"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"School of Foreign Studies"},{"#name":"organization","_":"China University of Mining and Technology"},{"#name":"city","_":"Xuzhou"},{"#name":"state","_":"Jiangsu"},{"#name":"postal-code","_":"221116"},{"#name":"country","_":"PR China"}]}]},{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"*"},{"#name":"text","$":{"id":"cetext0001"},"_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au0004","author-id":"S0957417417301008-ca98b43027b9e7f05d51c4df5e7d2a65"},"$$":[{"#name":"surname","_":"Liu"},{"#name":"given-name","_":"Nana"},{"#name":"cross-ref","$":{"id":"crf0005","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"id":"ead0004","type":"email"},"_":"liunana1004@163.com"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"tte0001"},"_":"A boosted decision tree approach using Bayesian hyper-parameter optimization for credit scoring"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","abstract":{"$$":[{"$$":[{"$":{"id":"cesectitle0001"},"#name":"section-title","_":"Highlights"},{"$$":[{"$$":[{"$$":[{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"para0001"},"#name":"para","_":"A novel boosted tree model for credit scoring is proposed."}],"$":{"id":"celistitem0001"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"para0002"},"#name":"para","_":"A hyper-parameter optimization technique is developed based on TPE algorithm."}],"$":{"id":"celistitem0002"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"para0003"},"#name":"para","_":"The model is proved to outperform several baseline techniques."}],"$":{"id":"celistitem0003"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"para0004"},"#name":"para","_":"The model is validated on five datasets over five performance metrics."}],"$":{"id":"celistitem0004"},"#name":"list-item"},{"$$":[{"#name":"label","_":"â€¢"},{"$":{"view":"all","id":"para0005"},"#name":"para","_":"The feature importance scores and decision chart enhance model interpretation."}],"$":{"id":"celistitem0005"},"#name":"list-item"}],"$":{"id":"celist0001"},"#name":"list"}],"$":{"view":"all","id":"spara0001"},"#name":"simple-para"}],"$":{"view":"all","id":"abss0001"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0001","class":"author-highlights"},"#name":"abstract"},{"$$":[{"$":{"id":"cesectitle0002"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"spara0007"},"#name":"simple-para","_":"Credit scoring is an effective tool for banks to properly guide decision profitably on granting loans. Ensemble methods, which according to their structures can be divided into parallel and sequential ensembles, have been recently developed in the credit scoring domain. These methods have proven their superiority in discriminating borrowers accurately. However, among the ensemble models, little consideration has been provided to the following: (1) highlighting the hyper-parameter tuning of base learner despite being critical to well-performed ensemble models; (2) building sequential models (i.e., boosting, as most have focused on developing the same or different algorithms in parallel); and (3) focusing on the comprehensibility of models. This paper aims to propose a sequential ensemble credit scoring model based on a variant of gradient boosting machine (i.e., extreme gradient boosting (XGBoost)). The model mainly comprises three steps. First, data pre-processing is employed to scale the data and handle missing values. Second, a model-based feature selection system based on the relative feature importance scores is utilized to remove redundant variables. Third, the hyper-parameters of XGBoost are adaptively tuned with Bayesian hyper-parameter optimization and used to train the model with selected feature subset. Several hyper-parameter optimization methods and baseline classifiers are considered as reference points in the experiment. Results demonstrate that Bayesian hyper-parameter optimization performs better than random search, grid search, and manual search. Moreover, the proposed model outperforms baseline models on average over four evaluation measures: accuracy, error rate, the area under the curve (AUC) H measure (AUC-H measure), and Brier score. The proposed model also provides feature importance scores and decision chart, which enhance the interpretability of credit scoring model."}],"$":{"view":"all","id":"abss0002"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0002","class":"author"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"},"pdf":{"urlType":null},"iss-first":"","vol-first":"78","isThirdParty":false,"language":"en","issn-primary-unformatted":"09574174","issn-primary-formatted":"0957-4174"},{"pii":"S0306437916305695","doi":"10.1016/j.is.2018.01.003","journalTitle":"Information Systems","publicationYear":"2018","publicationDate":"2018-05-01","volumeSupText":"Volume 74, Part 1","articleNumber":"","pageRange":"67-83","trace-token":"AAAAQGTADEJlbKEBkdkl1bedFjtMiHOKakTKCym6l07nqcJzlowqIPNg9bei8y6c4mwc34VMe6Eo7nqZDVzFGzbZDoKj6jAOD1gAXZmp43yojCaCt5pLTQ","authors":{"content":[{"#name":"author-group","$":{"id":"aut0001"},"$$":[{"#name":"author","$":{"id":"au0001","author-id":"S0306437916305695-d09d23730787fc087d1dca9ea06bde32"},"$$":[{"#name":"given-name","_":"Chiara"},{"#name":"surname","_":"Di Francescomarino"},{"#name":"cross-ref","$":{"id":"crf0003","refid":"cor0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"âŽ"}]},{"#name":"cross-ref","$":{"id":"crf0004","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:dfmchiara@fbk.eu","id":"ead0001"},"_":"dfmchiara@fbk.eu"}]},{"#name":"author","$":{"id":"au0002","author-id":"S0306437916305695-37bd2003d402810c5a468a1db842481f","orcid":"0000-0002-9247-7476"},"$$":[{"#name":"given-name","_":"Marlon"},{"#name":"surname","_":"Dumas"},{"#name":"cross-ref","$":{"id":"crf0005","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:marlon.dumas@ut.ee","id":"ead0002"},"_":"marlon.dumas@ut.ee"}]},{"#name":"author","$":{"id":"au0003","author-id":"S0306437916305695-e72fca4938728a6ffaeb002d568cf8a8"},"$$":[{"#name":"given-name","_":"Marco"},{"#name":"surname","_":"Federici"},{"#name":"cross-ref","$":{"id":"crf0006","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0007","refid":"aff0003"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"c"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:federici.marco.94@gmail.com","id":"ead0003"},"_":"marco.federici@student.uva.nl"}]},{"#name":"author","$":{"id":"au0004","author-id":"S0306437916305695-30b369b6f021114fc7ae13953c286465"},"$$":[{"#name":"given-name","_":"Chiara"},{"#name":"surname","_":"Ghidini"},{"#name":"cross-ref","$":{"id":"crf0008","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:ghidini@fbk.eu","id":"ead0004"},"_":"ghidini@fbk.eu"}]},{"#name":"author","$":{"id":"au0005","author-id":"S0306437916305695-679204bd9bf2e7797a062bbe88eb5c9f"},"$$":[{"#name":"given-name","_":"Fabrizio Maria"},{"#name":"surname","_":"Maggi"},{"#name":"cross-ref","$":{"id":"crf0009","refid":"aff0002"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"b"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:f.m.maggi@ut.ee","id":"ead0005"},"_":"f.m.maggi@ut.ee"}]},{"#name":"author","$":{"id":"au0006","author-id":"S0306437916305695-0b1ee229db469d7eaeee8ca18f77b539","orcid":"0000-0002-7318-6833"},"$$":[{"#name":"given-name","_":"Williams"},{"#name":"surname","_":"Rizzi"},{"#name":"cross-ref","$":{"id":"crf0010","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0011","refid":"aff0004"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"d"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:williams.rizzi@studenti.unitn.it","id":"ead0006"},"_":"williams.rizzi@studenti.unitn.it"}]},{"#name":"author","$":{"id":"au0007","author-id":"S0306437916305695-d0ad83b53c24cc5f01e085ae5c003e79","orcid":"0000-0001-5611-2747"},"$$":[{"#name":"given-name","_":"Luca"},{"#name":"surname","_":"Simonetto"},{"#name":"cross-ref","$":{"id":"crf0012","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0013","refid":"aff0003"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"c"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:luca.simonetto.94@gmail.com","id":"ead0007"},"_":"luca.simonetto@student.uva.nl"}]},{"#name":"affiliation","$":{"id":"aff0001","affiliation-id":"S0306437916305695-5e3bb858075a9abd96676d6b1918561f"},"$$":[{"#name":"label","_":"a"},{"#name":"textfn","$":{"id":"cetextfn0001"},"_":"FBK-IRST, Via Sommarive 18, Trento 38123, Italy"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"FBK-IRST"},{"#name":"address-line","_":"Via Sommarive 18"},{"#name":"city","_":"Trento"},{"#name":"postal-code","_":"38123"},{"#name":"country","_":"Italy"}]}]},{"#name":"affiliation","$":{"id":"aff0002","affiliation-id":"S0306437916305695-59e16e047f727c3a522d107c27eb6f87"},"$$":[{"#name":"label","_":"b"},{"#name":"textfn","$":{"id":"cetextfn0002"},"_":"University of Tartu, Ãœlikooli 18, Tartu 50090, Estonia"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"University of Tartu"},{"#name":"address-line","_":"Ãœlikooli 18"},{"#name":"city","_":"Tartu"},{"#name":"postal-code","_":"50090"},{"#name":"country","_":"Estonia"}]}]},{"#name":"affiliation","$":{"id":"aff0003","affiliation-id":"S0306437916305695-da7665d5c588b22cb946b4353b5d9dcd"},"$$":[{"#name":"label","_":"c"},{"#name":"textfn","$":{"id":"cetextfn0003"},"_":"University of Amsterdam, Spui 21, 1012 WX Amsterdam, The Netherlands"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"University of Amsterdam"},{"#name":"address-line","_":"Spui 21, 1012 WX Amsterdam"},{"#name":"country","_":"The Netherlands"}]}]},{"#name":"affiliation","$":{"id":"aff0004","affiliation-id":"S0306437916305695-8ddb0c1cbab6fc89cd9ee843035e6a76"},"$$":[{"#name":"label","_":"d"},{"#name":"textfn","$":{"id":"cetextfn0004"},"_":"University of Trento, Via Sommarive 9, Trento 38123, Italy"},{"#name":"affiliation","$":{"xmlns:sa":true},"$$":[{"#name":"organization","_":"University of Trento"},{"#name":"address-line","_":"Via Sommarive 9"},{"#name":"city","_":"Trento"},{"#name":"postal-code","_":"38123"},{"#name":"country","_":"Italy"}]}]},{"#name":"correspondence","$":{"id":"cor0001"},"$$":[{"#name":"label","_":"âŽ"},{"#name":"text","$":{"id":"cor1"},"_":"Corresponding author."}]}]}],"floats":[],"footnotes":[],"attachments":[]},"lastAuthor":{"content":[{"#name":"author","$":{"id":"au0007","author-id":"S0306437916305695-d0ad83b53c24cc5f01e085ae5c003e79","orcid":"0000-0001-5611-2747"},"$$":[{"#name":"given-name","_":"Luca"},{"#name":"surname","_":"Simonetto"},{"#name":"cross-ref","$":{"id":"crf0012","refid":"aff0001"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"a"}]},{"#name":"cross-ref","$":{"id":"crf0013","refid":"aff0003"},"$$":[{"#name":"sup","$":{"loc":"post"},"_":"c"}]},{"#name":"e-address","$":{"xmlns:xlink":true,"type":"email","href":"mailto:luca.simonetto.94@gmail.com","id":"ead0007"},"_":"luca.simonetto@student.uva.nl"}]}],"floats":[],"footnotes":[],"attachments":[]},"title":{"content":[{"#name":"title","$":{"id":"ct0001"},"_":"Genetic algorithms for hyperparameter optimization in predictive business process monitoring"}],"floats":[],"footnotes":[],"attachments":[]},"openArchive":false,"openAccess":false,"document-subtype":"fla","content-family":"serial","contentType":"JL","entitlementType":"","abstract":{"$$":[{"$$":[{"$":{"id":"sectt0001"},"#name":"section-title","_":"Abstract"},{"$$":[{"$":{"view":"all","id":"spara0001"},"#name":"simple-para","_":"Predictive business process monitoring aims at predicting the outcome of ongoing cases of a business process based on past execution traces. A wide range of techniques for this predictive task have been proposed in the literature. It turns out that no single technique, under a default configuration, consistently achieves the best predictive accuracy across all datasets. Thus, the selection and configuration of a technique needs to be done for each dataset. This paper presents a framework for predictive process monitoring that brings together a range of techniques, each with an associated set of hyperparameters. The framework incorporates two automatic hyperparameter optimization algorithms, which, given a dataset, select suitable techniques for each step in the framework and configure these techniques with minimal user input. The proposed framework and hyperparameter optimization algorithms have been evaluated on two real-life datasets and compared with state-of-the-art approaches for predictive business process monitoring. The results demonstrate the scalability of the approach and its ability to identify accurate and reliable framework configurations."}],"$":{"view":"all","id":"abssec0001"},"#name":"abstract-sec"}],"$":{"view":"all","id":"abs0001","class":"author"},"#name":"abstract"}],"$":{"xmlns:ce":true,"xmlns:dm":true,"xmlns:sb":true},"#name":"abstracts"},"pdf":{"urlType":null},"iss-first":"","vol-first":"74","isThirdParty":false,"language":"en","issn-primary-unformatted":"03064379","issn-primary-formatted":"0306-4379"}]},"references":{"content":[{"#name":"bibliography","$":{"xmlns:ce":true,"xmlns:aep":true,"xmlns:mml":true,"xmlns:xs":true,"xmlns:xlink":true,"xmlns:xocs":true,"xmlns:tb":true,"xmlns:xsi":true,"xmlns:cals":true,"xmlns:sb":true,"xmlns:sa":true,"xmlns:ja":true,"xmlns":true,"id":"bi005","view":"all"},"$$":[{"#name":"section-title","$":{"id":"st10000"},"_":"References"},{"#name":"bibliography-sec","$":{"id":"bs005","view":"all"},"$$":[{"#name":"bib-reference","$":{"id":"b0005"},"$$":[{"#name":"label","_":"[1]"},{"#name":"reference","$":{"id":"h0005","refId":"1"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"M.I."},{"#name":"surname","_":"Jordan"}]},{"#name":"author","$$":[{"#name":"given-name","_":"T.M."},{"#name":"surname","_":"Mitchell"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Machine learning: trends, perspectives, and prospects"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Science"}]},{"#name":"volume-nr","_":"349"}]},{"#name":"date","_":"2015"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"255"},{"#name":"last-page","_":"260"}]},{"#name":"doi","_":"10.1126/science.aaa8415"}]}]},{"#name":"source-text","$":{"id":"str010"},"_":"M.I. Jordan, T.M. Mitchell, Machine learning: Trends, perspectives, and prospects, Science 349 (2015) 255-260. https://doi.org/10.1126/science.aaa8415."}]},{"#name":"bib-reference","$":{"id":"b0010"},"$$":[{"#name":"label","_":"[2]"},{"#name":"other-ref","$":{"id":"h0010","refId":"2"},"$$":[{"#name":"textref","_":"M.-A. ZÃ¶ller, M.F. Huber, Benchmark and Survey of Automated Machine Learning Frameworks, arXiv preprint arXiv:1904.12054, (2019). https://arxiv.org/abs/1904.12054"}]},{"#name":"source-text","$":{"id":"str015"},"_":"M.-A. ZÃ¶ller and M. F. Huber, Benchmark and Survey of Automated Machine Learning Frameworks, arXiv preprint arXiv:1904.12054, (2019). https://arxiv.org/abs/1904.12054."}]},{"#name":"bib-reference","$":{"id":"b0015"},"$$":[{"#name":"label","_":"[3]"},{"#name":"other-ref","$":{"id":"h0015","refId":"3"},"$$":[{"#name":"textref","_":"R.E. Shawi, M. Maher, S. Sakr, Automated machine learning: State-of-the-art and open challenges, arXiv preprint arXiv:1906.02287, (2019). http://arxiv.org/abs/1906.02287"}]},{"#name":"source-text","$":{"id":"str020"},"_":"R. E. Shawi, M. Maher, S. Sakr, Automated machine learning: State-of-the-art and open challenges, arXiv preprint arXiv:1906.02287, (2019). http://arxiv.org/abs/1906.02287."}]},{"#name":"bib-reference","$":{"id":"b0020"},"$$":[{"#name":"label","_":"[4]"},{"#name":"reference","$":{"id":"h0020","refId":"4"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Kuhn"}]},{"#name":"author","$$":[{"#name":"given-name","_":"K."},{"#name":"surname","_":"Johnson"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Applied Predictive Modeling"}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"date","_":"2013"},{"#name":"publisher","$$":[{"#name":"name","_":"Springer"}]}]}]},{"#name":"comment","_":"ISBN: 9781461468493."}]},{"#name":"source-text","$":{"id":"str025"},"_":"M. Kuhn and K. Johnson, Applied Predictive Modeling., Springer (2013) ISBN: 9781461468493."}]},{"#name":"bib-reference","$":{"id":"b0025"},"$$":[{"#name":"label","_":"[5]"},{"#name":"reference","$":{"id":"h0025","refId":"5"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"G.I."},{"#name":"surname","_":"Diaz"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Fokoue-Nkoutche"}]},{"#name":"author","$$":[{"#name":"given-name","_":"G."},{"#name":"surname","_":"Nannicini"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Samulowitz"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"An effective algorithm for hyperparameter optimization of neural networks"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IBM J. Res. Dev."}]},{"#name":"volume-nr","_":"61"}]},{"#name":"date","_":"2017"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"20"}]},{"#name":"doi","_":"10.1147/JRD.2017.2709578"}]}]},{"#name":"source-text","$":{"id":"str030"},"_":"G.I. Diaz, A. Fokoue-Nkoutche, G. Nannicini, H. Samulowitz, An effective algorithm for hyperparameter optimization of neural networks, IBM J. Res. Dev. 61 (2017) 1-20. https://doi.org/10.1147/JRD.2017.2709578."}]},{"#name":"bib-reference","$":{"id":"b0030"},"$$":[{"#name":"label","_":"[6]"},{"#name":"reference","$":{"id":"h0030","refId":"6"},"$$":[{"#name":"host","$$":[{"#name":"edited-book","$$":[{"#name":"editors","$$":[{"#name":"editor","$$":[{"#name":"given-name","_":"F."},{"#name":"surname","_":"Hutter"}]},{"#name":"editor","$$":[{"#name":"given-name","_":"L."},{"#name":"surname","_":"Kotthoff"}]},{"#name":"editor","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Vanschoren"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Automatic Machine Learning: Methods, Systems, Challenges"}]},{"#name":"date","_":"2019"},{"#name":"publisher","$$":[{"#name":"name","_":"Springer"}]},{"#name":"isbn","_":"9783030053185"}]}]}]},{"#name":"source-text","$":{"id":"str035"},"_":"F. Hutter, L. Kotthoff, and J. Vanschoren, Eds., Automatic Machine Learning: Methods, Systems, Challenges, Springer (2019) ISBN: 9783030053185."}]},{"#name":"bib-reference","$":{"id":"b0035"},"$$":[{"#name":"label","_":"[7]"},{"#name":"reference","$":{"id":"h0035","refId":"7"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"N."},{"#name":"surname","_":"Decastro-GarcÃ­a"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Ã.L."},{"#name":"surname","_":"MuÃ±oz CastaÃ±eda"}]},{"#name":"author","$$":[{"#name":"given-name","_":"D."},{"#name":"surname","_":"Escudero GarcÃ­a"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M.V."},{"#name":"surname","_":"Carriegos"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Effect of the sampling of a dataset in the hyperparameter optimization phase over the efficiency of a machine learning algorithm"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Complexity"}]}]},{"#name":"date","_":"2019 (2019)."}]},{"#name":"doi","_":"10.1155/2019/6278908"}]}]},{"#name":"source-text","$":{"id":"str040"},"_":"N. Decastro-GarcÃ­a, Ã. L. MuÃ±oz CastaÃ±eda, D. Escudero GarcÃ­a, and M. V. Carriegos, Effect of the Sampling of a Dataset in the Hyperparameter Optimization Phase over the Efficiency of a Machine Learning Algorithm, Complexity 2019 (2019). https://doi.org/10.1155/2019/6278908."}]},{"#name":"bib-reference","$":{"id":"b0040"},"$$":[{"#name":"label","_":"[8]"},{"#name":"other-ref","$":{"id":"h0040","refId":"8"},"$$":[{"#name":"textref","_":"S. Abreu, Automated Architecture Design for Deep Neural Networks, arXiv preprint arXiv:1908.10714, (2019). http://arxiv.org/abs/1908.10714"}]},{"#name":"source-text","$":{"id":"str045"},"_":"S. Abreu, Automated Architecture Design for Deep Neural Networks, arXiv preprint arXiv:1908.10714, (2019). http://arxiv.org/abs/1908.10714."}]},{"#name":"bib-reference","$":{"id":"b0045"},"$$":[{"#name":"label","_":"[9]"},{"#name":"other-ref","$":{"id":"h0045","refId":"9"},"$$":[{"#name":"textref","_":"O.S. Steinholtz, A Comparative Study of Black-box Optimization Algorithms for Tuning of Hyper-parameters in Deep Neural Networks, M.S. thesis, Dept. Elect. Eng., LuleÃ¥ Univ. Technol., 2018"}]},{"#name":"source-text","$":{"id":"str050"},"_":"O. S. Steinholtz, A Comparative Study of Black-box Optimization Algorithms for Tuning of Hyper-parameters in Deep Neural Networks, M.S. thesis, Dept. Elect. Eng., LuleÃ¥ Univ. Technol., (2018)."}]},{"#name":"bib-reference","$":{"id":"b0050"},"$$":[{"#name":"label","_":"[10]"},{"#name":"reference","$":{"id":"h0050","refId":"10"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"G."},{"#name":"surname","_":"Luo"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A review of automatic selection methods for machine learning algorithms and hyper-parameter values"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Netw. Model. Anal. Heal. Inf. Bioinf."}]},{"#name":"volume-nr","_":"5"}]},{"#name":"date","_":"2016"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"16"}]},{"#name":"doi","_":"10.1007/s13721-016-0125-6"}]}]},{"#name":"source-text","$":{"id":"str055"},"_":"G. Luo, A review of automatic selection methods for machine learning algorithms and hyper-parameter values, Netw. Model. Anal. Heal. Informatics Bioinforma. 5 (2016) 1-16. https://doi.org/10.1007/s13721-016-0125-6."}]},{"#name":"bib-reference","$":{"id":"b0055"},"$$":[{"#name":"label","_":"[11]"},{"#name":"other-ref","$":{"id":"h0055","refId":"11"},"$$":[{"#name":"textref","_":"D. Maclaurin, D. Duvenaud, R.P. Adams, Gradient-based Hyperparameter Optimization through Reversible Learning, arXiv preprint arXiv:1502.03492, (2015). http://arxiv.org/abs/1502.03492"}]},{"#name":"source-text","$":{"id":"str060"},"_":"D. Maclaurin, D. Duvenaud, R.P. Adams, Gradient-based Hyperparameter Optimization through Reversible Learning, arXiv preprint arXiv:1502.03492, (2015). http://arxiv.org/abs/1502.03492."}]},{"#name":"bib-reference","$":{"id":"b0060"},"$$":[{"#name":"label","_":"[12]"},{"#name":"reference","$":{"id":"h0060","refId":"12"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Bergstra"}]},{"#name":"author","$$":[{"#name":"given-name","_":"R."},{"#name":"surname","_":"Bardenet"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Bengio"}]},{"#name":"author","$$":[{"#name":"given-name","_":"B."},{"#name":"surname","_":"KÃ©gl"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Algorithms for hyper-parameter optimization"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proc. Adv. Neural Inf. Process. Syst."}]}]},{"#name":"date","_":"2011"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"2546"},{"#name":"last-page","_":"2554"}]}]}]},{"#name":"source-text","$":{"id":"str065"},"_":"J. Bergstra, R. Bardenet, Y. Bengio, and B. KÃ©gl, Algorithms for hyper-parameter optimization, Proc. Adv. Neural Inf. Process. Syst., (2011) 2546-2554."}]},{"#name":"bib-reference","$":{"id":"b0065"},"$$":[{"#name":"label","_":"[13]"},{"#name":"reference","$":{"id":"h0065","refId":"13"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"B."},{"#name":"surname","_":"James"}]},{"#name":"author","$$":[{"#name":"given-name","_":"B."},{"#name":"surname","_":"Yoshua"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Random search for hyper-parameter optimization"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Mach. Learn. Res."}]},{"#name":"volume-nr","_":"13"}]},{"#name":"issue-nr","_":"1"},{"#name":"date","_":"2012"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"281"},{"#name":"last-page","_":"305"}]}]}]},{"#name":"source-text","$":{"id":"str070"},"_":"B. James and B. Yoshua, Random Search for Hyper-Parameter Optimization, J. Mach. Learn. Res. 13 (1) (2012) 281-305."}]},{"#name":"bib-reference","$":{"id":"b0070"},"$$":[{"#name":"label","_":"[14]"},{"#name":"reference","$":{"id":"h0070","refId":"14"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"K."},{"#name":"surname","_":"Eggensperger"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Feurer"}]},{"#name":"author","$$":[{"#name":"given-name","_":"F."},{"#name":"surname","_":"Hutter"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Bergstra"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Snoek"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Hoos"}]},{"#name":"author","$$":[{"#name":"given-name","_":"K."},{"#name":"surname","_":"Leyton-Brown"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Towards an empirical foundation for assessing Bayesian optimization of hyperparameters"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"BayesOpt Work"}]}]},{"#name":"date","_":"2013"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"5"}]}]}]},{"#name":"source-text","$":{"id":"str075"},"_":"K. Eggensperger, M. Feurer, F. Hutter, J. Bergstra, J. Snoek, H. Hoos, K. Leyton-Brown, Towards an Empirical Foundation for Assessing Bayesian Optimization of Hyperparameters, BayesOpt Work. (2013) 1-5."}]},{"#name":"bib-reference","$":{"id":"b0075"},"$$":[{"#name":"label","_":"[15]"},{"#name":"reference","$":{"id":"h0075","refId":"15"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"K."},{"#name":"surname","_":"Eggensperger"}]},{"#name":"author","$$":[{"#name":"given-name","_":"F."},{"#name":"surname","_":"Hutter"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H.H."},{"#name":"surname","_":"Hoos"}]},{"#name":"author","$$":[{"#name":"given-name","_":"K."},{"#name":"surname","_":"Leyton-Brown"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Efficient benchmarking of hyperparameter optimizers via surrogates"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proc. Natl. Conf. Artif. Intell."}]},{"#name":"volume-nr","_":"2"}]},{"#name":"date","_":"2015"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1114"},{"#name":"last-page","_":"1120"}]}]}]},{"#name":"source-text","$":{"id":"str080"},"_":"K. Eggensperger, F. Hutter, H.H. Hoos, K. Leyton-Brown, Efficient benchmarking of hyperparameter optimizers via surrogates, Proc. Natl. Conf. Artif. Intell. 2 (2015) 1114-1120."}]},{"#name":"bib-reference","$":{"id":"b0080"},"$$":[{"#name":"label","_":"[16]"},{"#name":"reference","$":{"id":"h0080","refId":"16"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"L."},{"#name":"surname","_":"Li"}]},{"#name":"author","$$":[{"#name":"given-name","_":"K."},{"#name":"surname","_":"Jamieson"}]},{"#name":"author","$$":[{"#name":"given-name","_":"G."},{"#name":"surname","_":"DeSalvo"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Rostamizadeh"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Talwalkar"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Hyperband: a novel bandit-based approach to hyperparameter optimization"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Mach. Learn. Res."}]},{"#name":"volume-nr","_":"18"}]},{"#name":"date","_":"2012"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"52"}]}]}]},{"#name":"source-text","$":{"id":"str085"},"_":"L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar, Hyperband: A novel bandit-based approach to hyperparameter optimization, J. Mach. Learn. Res. 18 (2012) 1-52."}]},{"#name":"bib-reference","$":{"id":"b0085"},"$$":[{"#name":"label","_":"[17]"},{"#name":"other-ref","$":{"id":"h0085","refId":"17"},"$$":[{"#name":"textref","_":"Q. Yao, et al., Taking Human out of Learning Applications: A Survey on Automated Machine Learning, arXiv preprint arXiv:1810.13306, (2018). http://arxiv.org/abs/1810.13306."}]},{"#name":"source-text","$":{"id":"str090"},"_":"Q. Yao et al., Taking Human out of Learning Applications: A Survey on Automated Machine Learning, arXiv preprint arXiv:1810.13306, (2018). http://arxiv.org/abs/1810.13306."}]},{"#name":"bib-reference","$":{"id":"b0090"},"$$":[{"#name":"label","_":"[18]"},{"#name":"other-ref","$":{"id":"h0090","refId":"18"},"$$":[{"#name":"textref","_":"S. Lessmann, R. Stahlbock, S.F. Crone, Optimizing hyperparameters of support vector machines by genetic algorithms, Proc. 2005 Int. Conf. Artif. Intell. ICAIâ€™05. 1 (2005) 74â€“80."}]},{"#name":"source-text","$":{"id":"str095"},"_":"S. Lessmann, R. Stahlbock, S.F. Crone, Optimizing hyperparameters of support vector machines by genetic algorithms, Proc. 2005 Int. Conf. Artif. Intell. ICAIâ€™05. 1 (2005) 74-80."}]},{"#name":"bib-reference","$":{"id":"b0095"},"$$":[{"#name":"label","_":"[19]"},{"#name":"reference","$":{"id":"h0095","refId":"19"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"P.R."},{"#name":"surname","_":"Lorenzo"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Nalepa"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Kawulok"}]},{"#name":"author","$$":[{"#name":"given-name","_":"L.S."},{"#name":"surname","_":"Ramos"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J.R."},{"#name":"surname","_":"Paster"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Particle swarm optimization for hyper-parameter selection in deep neural networks"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proc. ACM Int. Conf. Genet. Evol. Comput."}]}]},{"#name":"date","_":"2017"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"481"},{"#name":"last-page","_":"488"}]}]}]},{"#name":"source-text","$":{"id":"str100"},"_":"P. R. Lorenzo, J. Nalepa, M. Kawulok, L. S. Ramos, and J. R. Paster, Particle swarm optimization for hyper-parameter selection in deep neural networks, Proc. ACM Int. Conf. Genet. Evol. Comput., (2017) 481-488."}]},{"#name":"bib-reference","$":{"id":"b0100"},"$$":[{"#name":"label","_":"[20]"},{"#name":"other-ref","$":{"id":"h0100","refId":"20"},"$$":[{"#name":"textref","_":"S. Sun, Z. Cao, H. Zhu, J. Zhao, A Survey of Optimization Methods from a Machine Learning Perspective, arXiv preprint arXiv:1906.06821, (2019). https://arxiv.org/abs/1906.06821."}]},{"#name":"source-text","$":{"id":"str105"},"_":"S. Sun, Z. Cao, H. Zhu, J. Zhao, A Survey of Optimization Methods from a Machine Learning Perspective, arXiv preprint arXiv:1906.06821, (2019). https://arxiv.org/abs/1906.06821."}]},{"#name":"bib-reference","$":{"id":"b0105"},"$$":[{"#name":"label","_":"[21]"},{"#name":"reference","$":{"id":"h0105","refId":"21"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"T.M.S."},{"#name":"surname","_":"Bradley"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Hax"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Applied Mathematical Programming"}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"date","_":"1977"},{"#name":"publisher","$$":[{"#name":"name","_":"Addison-Wesley"},{"#name":"location","_":"Reading, Massachusetts"}]}]}]}]},{"#name":"source-text","$":{"id":"str110"},"_":"T.M. S. Bradley, A. Hax, Applied Mathematical Programming, Addison-Wesley, Reading, Massachusetts. (1977)."}]},{"#name":"bib-reference","$":{"id":"b0110"},"$$":[{"#name":"label","_":"[22]"},{"#name":"reference","$":{"id":"h0110","refId":"22"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Bubeck"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Convex optimization: algorithms and complexity"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Found. Trends Mach. Learn."}]},{"#name":"volume-nr","_":"8"}]},{"#name":"date","_":"2015"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"231"},{"#name":"last-page","_":"357"}]},{"#name":"doi","_":"10.1561/2200000050"}]}]},{"#name":"source-text","$":{"id":"str115"},"_":"S. Bubeck, Convex optimization: Algorithms and complexity, Found. Trends Mach. Learn. 8 (2015) 231-357. https://doi.org/10.1561/2200000050."}]},{"#name":"bib-reference","$":{"id":"b0115"},"$$":[{"#name":"label","_":"[23]"},{"#name":"other-ref","$":{"id":"h0115","refId":"23"},"$$":[{"#name":"textref","_":"B. Shahriari, A. Bouchard-CÃ´tÃ©, N. de Freitas, Unbounded Bayesian optimization via regularization, Proc. Artif. Intell. Statist., (2016) 1168â€“1176."}]},{"#name":"source-text","$":{"id":"str120"},"_":"B. Shahriari, A. Bouchard-CÃ´tÃ©, and N. de Freitas, â€œUnbounded Bayesian optimization via regularization,â€ Proc. Artif. Intell. Statist., (2016) 1168-1176."}]},{"#name":"bib-reference","$":{"id":"b0120"},"$$":[{"#name":"label","_":"[24]"},{"#name":"reference","$":{"id":"h0120","refId":"24"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"G.I."},{"#name":"surname","_":"Diaz"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Fokoue-Nkoutche"}]},{"#name":"author","$$":[{"#name":"given-name","_":"G."},{"#name":"surname","_":"Nannicini"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Samulowitz"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"An effective algorithm for hyperparameter optimization of neural networks"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IBM J. Res. Dev."}]},{"#name":"volume-nr","_":"61"}]},{"#name":"date","_":"2017"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"20"}]},{"#name":"doi","_":"10.1147/JRD.2017.2709578"}]}]},{"#name":"source-text","$":{"id":"str125"},"_":"G.I. Diaz, A. Fokoue-Nkoutche, G. Nannicini, H. Samulowitz, An effective algorithm for hyperparameter optimization of neural networks, IBM J. Res. Dev. 61 (2017) 1-20. https://doi.org/10.1147/JRD.2017.2709578."}]},{"#name":"bib-reference","$":{"id":"b0125"},"$$":[{"#name":"label","_":"[25]"},{"#name":"reference","$":{"id":"h0125","refId":"25"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Gambella"}]},{"#name":"author","$$":[{"#name":"given-name","_":"B."},{"#name":"surname","_":"Ghaddar"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Naoum-Sawaya"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Optimization Models for Machine Learning: A Survey, arXiv preprint arXiv:1901.05331"}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"date","_":"2019"}]}]}]},{"#name":"source-text","$":{"id":"str130"},"_":"C. Gambella, B. Ghaddar, and J. Naoum-Sawaya, Optimization Models for Machine Learning: A Survey, arXiv preprint arXiv:1901.05331, (2019). http://arxiv.org/abs/1901.05331."}]},{"#name":"bib-reference","$":{"id":"b0130"},"$$":[{"#name":"label","_":"[26]"},{"#name":"reference","$":{"id":"h0130","refId":"26"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"E.R."},{"#name":"surname","_":"Sparks"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Talwalkar"}]},{"#name":"author","$$":[{"#name":"given-name","_":"D."},{"#name":"surname","_":"Haas"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M.J."},{"#name":"surname","_":"Franklin"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M.I."},{"#name":"surname","_":"Jordan"}]},{"#name":"author","$$":[{"#name":"given-name","_":"T."},{"#name":"surname","_":"Kraska"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Automating model search for large scale machine learning"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proc. 6th ACM Symp. Cloud Comput."}]}]},{"#name":"date","_":"2015"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"368"},{"#name":"last-page","_":"380"}]}]}]},{"#name":"source-text","$":{"id":"str135"},"_":"E. R. Sparks, A. Talwalkar, D. Haas, M. J. Franklin, M. I. Jordan, and T. Kraska, Automating model search for large scale machine learning, Proc. 6th ACM Symp. Cloud Comput., (2015) 368-380."}]},{"#name":"bib-reference","$":{"id":"b0135"},"$$":[{"#name":"label","_":"[27]"},{"#name":"other-ref","$":{"id":"h0135","refId":"27"},"$$":[{"#name":"textref","_":"J. Nocedal, S. Wright, Numerical Optimization, 2006, Springer-Verlag, ISBN: 978-0-387-40065-5."}]},{"#name":"source-text","$":{"id":"str140"},"_":"J. Nocedal and S. Wright, Numerical Optimization, (2006) Springer-Verlag, ISBN: 978-0-387-40065-5."}]},{"#name":"bib-reference","$":{"id":"b0140"},"$$":[{"#name":"label","_":"[28]"},{"#name":"reference","$":{"id":"h0140","refId":"28"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"R."},{"#name":"surname","_":"Caruana"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Niculescu-Mizil"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"An empirical comparison of supervised learning algorithms"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"ACM Int. Conf. Proc. Ser."}]},{"#name":"volume-nr","_":"148"}]},{"#name":"date","_":"2006"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"161"},{"#name":"last-page","_":"168"}]},{"#name":"doi","_":"10.1145/1143844.1143865"}]}]},{"#name":"source-text","$":{"id":"str145"},"_":"R. Caruana, A. Niculescu-Mizil, An empirical comparison of supervised learning algorithms, ACM Int. Conf. Proceeding Ser. 148 (2006) 161-168. https://doi.org/10.1145/1143844.1143865."}]},{"#name":"bib-reference","$":{"id":"b0145"},"$$":[{"#name":"label","_":"[29]"},{"#name":"reference","$":{"id":"h0145","refId":"29"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"O."},{"#name":"surname","_":"Kramer"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Scikit-Learn, in Machine Learning for Evolution Strategies"}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"date","_":"2016"},{"#name":"publisher","$$":[{"#name":"name","_":"Springer International Publishing"},{"#name":"location","_":"Cham, Switzerland"}]}]},{"#name":"pages","$$":[{"#name":"first-page","_":"45"},{"#name":"last-page","_":"53"}]}]}]},{"#name":"source-text","$":{"id":"str150"},"_":"O. Kramer, Scikit-Learn, in Machine Learning for Evolution Strategies. Cham, Switzerland: Springer International Publishing, (2016) 45-53."}]},{"#name":"bib-reference","$":{"id":"b0150"},"$$":[{"#name":"label","_":"[30]"},{"#name":"reference","$":{"id":"h0150","refId":"30"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"F."},{"#name":"surname","_":"Pedregosa"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Scikit-learn: machine learning in Python"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Mach. Learn. Res."}]},{"#name":"volume-nr","_":"12"}]},{"#name":"date","_":"2011"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"2825"},{"#name":"last-page","_":"2830"}]}]}]},{"#name":"source-text","$":{"id":"str155"},"_":"F. Pedregosa et al., Scikit-learn: Machine learning in Python, J. Mach. Learn. Res., 12 (2011) 2825-2830."}]},{"#name":"bib-reference","$":{"id":"b0155"},"$$":[{"#name":"label","_":"[31]"},{"#name":"other-ref","$":{"id":"h0155","refId":"31"},"$$":[{"#name":"textref","_":"T. Chen, C.Guestrin, XGBoost: a scalable tree boosting system, arXiv preprint arXiv:1603.02754, (2016). http://arxiv.org/abs/1603.02754."}]},{"#name":"source-text","$":{"id":"str160"},"_":"T.Chen, C.Guestrin, XGBoost: a scalable tree boosting system, arXiv preprint arXiv:1603.02754, (2016). http://arxiv.org/abs/1603.02754."}]},{"#name":"bib-reference","$":{"id":"b0160"},"$$":[{"#name":"label","_":"[32]"},{"#name":"other-ref","$":{"id":"h0160","refId":"32"},"$$":[{"#name":"textref","_":"F. Chollet, Keras, 2015. https://github.com/fchollet/keras."}]},{"#name":"source-text","$":{"id":"str165"},"_":"F. Chollet, Keras, 2015. https://github.com/fchollet/keras."}]},{"#name":"bib-reference","$":{"id":"b0165"},"$$":[{"#name":"label","_":"[33]"},{"#name":"reference","$":{"id":"h0165","refId":"33"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Gambella"}]},{"#name":"author","$$":[{"#name":"given-name","_":"B."},{"#name":"surname","_":"Ghaddar"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Naoum-Sawaya"}]}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Optimization Models for Machine Learning: A Survey"}]}]},{"#name":"date","_":"2019"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"40"}]}]},{"#name":"comment","_":"http://arxiv.org/abs/1901.05331"}]},{"#name":"source-text","$":{"id":"str170"},"_":"C. Gambella, B. Ghaddar, J. Naoum-Sawaya, Optimization Models for Machine Learning: A Survey, (2019) 1-40. http://arxiv.org/abs/1901.05331"}]},{"#name":"bib-reference","$":{"id":"b0170"},"$$":[{"#name":"label","_":"[34]"},{"#name":"other-ref","$":{"id":"h0170","refId":"34"},"$$":[{"#name":"textref","_":"C.M. Bishop, Pattern Recognition and Machine Learning, 2006, Springer, ISBN: 978-0-387-31073-2."}]},{"#name":"source-text","$":{"id":"str175"},"_":"C.M. Bishop, Pattern Recognition and Machine Learning. (2006) Springer, ISBN: 978-0-387-31073-2."}]},{"#name":"bib-reference","$":{"id":"b0175"},"$$":[{"#name":"label","_":"[35]"},{"#name":"reference","$":{"id":"h0175","refId":"35"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"A.E."},{"#name":"surname","_":"Hoerl"}]},{"#name":"author","$$":[{"#name":"given-name","_":"R.W."},{"#name":"surname","_":"Kennard"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Ridge regression: applications to nonorthogonal problems"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Technometrics"}]},{"#name":"volume-nr","_":"12"}]},{"#name":"date","_":"1970"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"69"},{"#name":"last-page","_":"82"}]},{"#name":"doi","_":"10.1080/00401706.1970.10488635"}]}]},{"#name":"source-text","$":{"id":"str180"},"_":"A.E. Hoerl, R.W. Kennard, Ridge Regression: Applications to Nonorthogonal Problems, Technometrics. 12 (1970) 69-82. https://doi.org/10.1080/00401706.1970.10488635."}]},{"#name":"bib-reference","$":{"id":"b0180"},"$$":[{"#name":"label","_":"[36]"},{"#name":"reference","$":{"id":"h0180","refId":"36"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"L.E."},{"#name":"surname","_":"Melkumova"}]},{"#name":"author","$$":[{"#name":"given-name","_":"S.Y."},{"#name":"surname","_":"Shatskikh"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Comparing ridge and LASSO estimators for data analysis"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Procedia Eng."}]},{"#name":"volume-nr","_":"201"}]},{"#name":"date","_":"2017"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"746"},{"#name":"last-page","_":"755"}]},{"#name":"doi","_":"10.1016/j.proeng.2017.09.615"}]}]},{"#name":"source-text","$":{"id":"str185"},"_":"L.E. Melkumova, S.Y. Shatskikh, Comparing Ridge and LASSO estimators for data analysis, Procedia Eng. 201 (2017) 746-755. https://doi.org/10.1016/j.proeng.2017.09.615."}]},{"#name":"bib-reference","$":{"id":"b0185"},"$$":[{"#name":"label","_":"[37]"},{"#name":"reference","$":{"id":"h0185","refId":"37"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"R."},{"#name":"surname","_":"Tibshirani"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Regression shrinkage and selection via the Lasso"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. R. Stat. Soc. Ser. B"}]},{"#name":"volume-nr","_":"58"}]},{"#name":"date","_":"1996"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"267"},{"#name":"last-page","_":"288"}]},{"#name":"doi","_":"10.1111/j.2517-6161.1996.tb02080.x"}]}]},{"#name":"source-text","$":{"id":"str190"},"_":"R. Tibshirani, Regression Shrinkage and Selection Via the Lasso, J. R. Stat. Soc. Ser. B. 58 (1996) 267-288. https://doi.org/10.1111/j.2517-6161.1996.tb02080.x."}]},{"#name":"bib-reference","$":{"id":"b0190"},"$$":[{"#name":"label","_":"[38]"},{"#name":"reference","$":{"id":"h0190","refId":"38"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"D.W."},{"#name":"surname","_":"Hosmer"},{"#name":"suffix","_":"Jr"}]},{"#name":"author","$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Lemeshow"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Applied logistic regression"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Technometrics"}]},{"#name":"volume-nr","_":"34"}]},{"#name":"issue-nr","_":"1"},{"#name":"date","_":"2013"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"358"},{"#name":"last-page","_":"359"}]}]}]},{"#name":"source-text","$":{"id":"str195"},"_":"D.W. Hosmer Jr, S. Lemeshow, Applied logistic regression, Technometrics, 34 (1) (2013), 358-359."}]},{"#name":"bib-reference","$":{"id":"b0195"},"$$":[{"#name":"label","_":"[39]"},{"#name":"reference","$":{"id":"h0195","refId":"39"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"J.O."},{"#name":"surname","_":"Ogutu"}]},{"#name":"author","$$":[{"#name":"given-name","_":"T."},{"#name":"surname","_":"Schulz-Streeck"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H.P."},{"#name":"surname","_":"Piepho"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Genomic selection using regularized linear regression models: ridge regression, lasso, elastic net and their extensions"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"BMC Proc. BioMed Cent."}]},{"#name":"volume-nr","_":"6"}]},{"#name":"date","_":"2012"}]}]}]},{"#name":"source-text","$":{"id":"str200"},"_":"J.O. Ogutu, T. Schulz-Streeck, H.P. Piepho, Genomic selection using regularized linear regression models: ridge regression, lasso, elastic net and their extensions, BMC Proceedings. BioMed Cent. 6 (2012)."}]},{"#name":"bib-reference","$":{"id":"b0200"},"$$":[{"#name":"label","_":"[40]"},{"#name":"reference","$":{"id":"h0200","refId":"40"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"J.M."},{"#name":"surname","_":"Keller"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M.R."},{"#name":"surname","_":"Gray"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A fuzzy K-nearest neighbor algorithm"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IEEE Trans. Syst. Man Cybern."}]},{"#name":"volume-nr","_":"SMC-15"}]},{"#name":"date","_":"1985"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"580"},{"#name":"last-page","_":"585"}]},{"#name":"doi","_":"10.1109/TSMC.1985.6313426"}]}]},{"#name":"source-text","$":{"id":"str205"},"_":"J.M. Keller, M.R. Gray, A Fuzzy K-Nearest Neighbor Algorithm, IEEE Trans. Syst. Man Cybern. SMC-15 (1985) 580-585. https://doi.org/10.1109/TSMC.1985.6313426."}]},{"#name":"bib-reference","$":{"id":"b0205"},"$$":[{"#name":"label","_":"[41]"},{"#name":"reference","$":{"id":"h0205","refId":"41"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"W."},{"#name":"surname","_":"Zuo"}]},{"#name":"author","$$":[{"#name":"given-name","_":"D."},{"#name":"surname","_":"Zhang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"K."},{"#name":"surname","_":"Wang"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"On kernel difference-weighted k-nearest neighbor classification"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Pattern Anal. Appl."}]},{"#name":"volume-nr","_":"11"}]},{"#name":"date","_":"2008"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"247"},{"#name":"last-page","_":"257"}]},{"#name":"doi","_":"10.1007/s10044-007-0100-z"}]}]},{"#name":"source-text","$":{"id":"str210"},"_":"W. Zuo, D. Zhang, K. Wang, On kernel difference-weighted k-nearest neighbor classification, Pattern Anal. Appl. 11 (2008) 247-257. https://doi.org/10.1007/s10044-007-0100-z."}]},{"#name":"bib-reference","$":{"id":"b0210"},"$$":[{"#name":"label","_":"[42]"},{"#name":"reference","$":{"id":"h0210","refId":"42"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Smola"}]},{"#name":"author","$$":[{"#name":"given-name","_":"V."},{"#name":"surname","_":"Vapnik"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Support vector regression machines"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Adv. Neural Inf. Process. Syst."}]},{"#name":"volume-nr","_":"9"}]},{"#name":"date","_":"1997"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"155"},{"#name":"last-page","_":"161"}]}]}]},{"#name":"source-text","$":{"id":"str215"},"_":"A. Smola, V. Vapnik, Support vector regression machines, Adv. Neural Inf. Process. Syst. 9 (1997) 155-161."}]},{"#name":"bib-reference","$":{"id":"b0215"},"$$":[{"#name":"label","_":"[43]"},{"#name":"reference","$":{"id":"h0215","refId":"43"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"L."},{"#name":"surname","_":"Yang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"R."},{"#name":"surname","_":"Muresan"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Al-Dweik"}]},{"#name":"author","$$":[{"#name":"given-name","_":"L.J."},{"#name":"surname","_":"Hadjileontiadis"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Image-based visibility estimation algorithm for intelligent transportation systems"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IEEE Access"}]},{"#name":"volume-nr","_":"6"}]},{"#name":"date","_":"2018"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"76728"},{"#name":"last-page","_":"76740"}]},{"#name":"doi","_":"10.1109/ACCESS.2018.2884225"}]}]},{"#name":"source-text","$":{"id":"str220"},"_":"L. Yang, R. Muresan, A. Al-Dweik, L.J. Hadjileontiadis, Image-Based Visibility Estimation Algorithm for Intelligent Transportation Systems, IEEE Access. 6 (2018) 76728-76740. https://doi.org/10.1109/ACCESS.2018.2884225."}]},{"#name":"bib-reference","$":{"id":"b0220"},"$$":[{"#name":"label","_":"[44]"},{"#name":"reference","$":{"id":"h0220","refId":"44"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Zhang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"R."},{"#name":"surname","_":"Jin"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Yang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A.G."},{"#name":"surname","_":"Hauptmann"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Modified logistic regression: an approximation to SVM and its applications in large-scale text categorization"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proceedings Twent. Int. Conf. Mach. Learn."}]},{"#name":"volume-nr","_":"2"}]},{"#name":"date","_":"2003"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"888"},{"#name":"last-page","_":"895"}]}]}]},{"#name":"source-text","$":{"id":"str225"},"_":"J. Zhang, R. Jin, Y. Yang, A.G. Hauptmann, Modified Logistic Regression: An Approximation to SVM and Its Applications in Large-Scale Text Categorization, Proceedings, Twent. Int. Conf. Mach. Learn. 2 (2003) 888-895."}]},{"#name":"bib-reference","$":{"id":"b0225"},"$$":[{"#name":"label","_":"[45]"},{"#name":"other-ref","$":{"id":"h0225","refId":"45"},"$$":[{"#name":"textref","_":"O.S. Soliman, A.S. Mahmoud, A classification system for remote sensing satellite images using support vector machine with non-linear kernel functions, 2012 8th Int. Conf. Informatics Syst. INFOS 2012. (2012) BIO-181-BIO-187."}]},{"#name":"source-text","$":{"id":"str230"},"_":"O.S. Soliman, A.S. Mahmoud, A classification system for remote sensing satellite images using support vector machine with non-linear kernel functions, 2012 8th Int. Conf. Informatics Syst. INFOS 2012. (2012) BIO-181-BIO-187."}]},{"#name":"bib-reference","$":{"id":"b0230"},"$$":[{"#name":"label","_":"[46]"},{"#name":"reference","$":{"id":"h0230","refId":"46"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"I."},{"#name":"surname","_":"Rish"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"An empirical study of the naive Bayes classifier"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IJCAI 2001 Work Empir. Methods Artif. Intell."}]}]},{"#name":"date","_":"2001"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"41"},{"#name":"last-page","_":"46"}]}]}]},{"#name":"source-text","$":{"id":"str235"},"_":"I. Rish, An empirical study of the naive Bayes classifier, IJCAI 2001 Work. Empir. methods Artif. Intell., (2001), 41-46."}]},{"#name":"bib-reference","$":{"id":"b0235"},"$$":[{"#name":"label","_":"[47]"},{"#name":"other-ref","$":{"id":"h0235","refId":"47"},"$$":[{"#name":"textref","_":"J.N. Sulzmann, J. FÃ¼rnkranz, E. HÃ¼llermeier, On pairwise naive bayes classifiers, Lect. Notes Comput. Sci. (Including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics). 4701 LNAI (2007) 371-381. https://doi.org/10.1007/978-3-540-74958-5_35"}]},{"#name":"source-text","$":{"id":"str240"},"_":"J.N. Sulzmann, J. FÃ¼rnkranz, E. HÃ¼llermeier, On pairwise naive bayes classifiers, Lect. Notes Comput. Sci. (Including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics). 4701 LNAI (2007) 371-381. https://doi.org/10.1007/978-3-540-74958-5_35."}]},{"#name":"bib-reference","$":{"id":"b0240"},"$$":[{"#name":"label","_":"[48]"},{"#name":"reference","$":{"id":"h0240","refId":"48"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Bustamante"}]},{"#name":"author","$$":[{"#name":"given-name","_":"L."},{"#name":"surname","_":"Garrido"}]},{"#name":"author","$$":[{"#name":"given-name","_":"R."},{"#name":"surname","_":"Soto"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Comparing fuzzy Naive Bayes and Gaussian Naive Bayes for decision making in RoboCup 3D"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Lect. Notes Comput. Sci. (Including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics)"}]}]},{"#name":"date","_":"2006"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"237"},{"#name":"last-page","_":"247"}]},{"#name":"doi","_":"10.1007/11925231_23"}]},{"#name":"comment","_":"4293 LNA I"}]},{"#name":"source-text","$":{"id":"str245"},"_":"C. Bustamante, L. Garrido, R. Soto, Comparing fuzzy Naive Bayes and Gaussian Naive Bayes for decision making in RoboCup 3D, Lect. Notes Comput. Sci. (Including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics). 4293 LNAI (2006) 237-247. https://doi.org/10.1007/11925231_23."}]},{"#name":"bib-reference","$":{"id":"b0245"},"$$":[{"#name":"label","_":"[49]"},{"#name":"reference","$":{"id":"h0245","refId":"49"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"A.M."},{"#name":"surname","_":"Kibriya"}]},{"#name":"author","$$":[{"#name":"given-name","_":"E."},{"#name":"surname","_":"Frank"}]},{"#name":"author","$$":[{"#name":"given-name","_":"B."},{"#name":"surname","_":"Pfahringer"}]},{"#name":"author","$$":[{"#name":"given-name","_":"G."},{"#name":"surname","_":"Holmes"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Multinomial naive bayes for text categorization revisited"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Lect. Notes Artif. Intell. (Subseries Lect. Notes Comput. Sci.)"}]},{"#name":"volume-nr","_":"3339"}]},{"#name":"date","_":"2004"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"488"},{"#name":"last-page","_":"499"}]}]}]},{"#name":"source-text","$":{"id":"str250"},"_":"A.M. Kibriya, E. Frank, B. Pfahringer, G. Holmes, Multinomial naive bayes for text categorization revisited, Lect. Notes Artif. Intell. (Subseries Lect. Notes Comput. Sci. 3339 (2004) 488-499."}]},{"#name":"bib-reference","$":{"id":"b0250"},"$$":[{"#name":"label","_":"[50]"},{"#name":"other-ref","$":{"id":"h0250","refId":"50"},"$$":[{"#name":"textref","_":"J.D.M. Rennie, L. Shih, J. Teevan, D.R. Karger Tackling the poor assumptions of Naive Bayes text classifiers, Proc. Twent. Int. Conf. Mach. Learn. ICML (2003), 616â€“623."}]},{"#name":"source-text","$":{"id":"str255"},"_":"J.D.M. Rennie, L. Shih, J. Teevan, D.R. Karger Tackling the poor assumptions of Naive Bayes text classifiers, Proc. Twent. Int. Conf. Mach. Learn. ICML (2003), 616-623."}]},{"#name":"bib-reference","$":{"id":"b0255"},"$$":[{"#name":"label","_":"[51]"},{"#name":"other-ref","$":{"id":"h0255","refId":"51"},"$$":[{"#name":"textref","_":"V. Narayanan, I. Arora, A. Bhatia, Fast and accurate sentiment classification using an enhanced naÃ­ve Bayes model, arXiv preprint arXiv:1305.6143, (2013). https://arxiv.org/abs/1305.6143."}]},{"#name":"source-text","$":{"id":"str260"},"_":"V. Narayanan, I. Arora, and A. Bhatia, Fast and accurate sentiment classification using an enhanced naÃ­ve Bayes model, arXiv preprint arXiv:1305.6143, (2013). https://arxiv.org/abs/1305.6143."}]},{"#name":"bib-reference","$":{"id":"b0260"},"$$":[{"#name":"label","_":"[52]"},{"#name":"reference","$":{"id":"h0260","refId":"52"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Rasoul"}]},{"#name":"author","$$":[{"#name":"given-name","_":"L."},{"#name":"surname","_":"David"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A survey of decision tree classifier methodology"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IEEE Trans. Syst. Man. Cybern."}]},{"#name":"volume-nr","_":"21"}]},{"#name":"date","_":"1991"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"660"},{"#name":"last-page","_":"674"}]}]}]},{"#name":"source-text","$":{"id":"str265"},"_":"S. Rasoul, L. David, A Survey of Decision Tree Classifier Methodology, IEEE Trans. Syst. Man. Cybern. 21 (1991) 660-674."}]},{"#name":"bib-reference","$":{"id":"b0265"},"$$":[{"#name":"label","_":"[53]"},{"#name":"reference","$":{"id":"h0265","refId":"53"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"D.M."},{"#name":"surname","_":"Manias"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Jammal"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Hawilo"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Shami"}]},{"#name":"author","$$":[{"#name":"given-name","_":"P."},{"#name":"surname","_":"Heidari"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Larabi"}]},{"#name":"author","$$":[{"#name":"given-name","_":"R."},{"#name":"surname","_":"Brunner"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Machine learning for performance-aware virtual network function placement"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"2019 IEEE Glob. Commun. Conf. GLOBECOM 2019 â€“ Proc."}]}]},{"#name":"date","_":"2019"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"12"},{"#name":"last-page","_":"17"}]},{"#name":"doi","_":"10.1109/GLOBECOM38437.2019.9013246"}]}]},{"#name":"source-text","$":{"id":"str270"},"_":"D.M. Manias, M. Jammal, H. Hawilo, A. Shami, P. Heidari, A. Larabi, R. Brunner, Machine learning for performance-aware virtual network function placement, 2019 IEEE Glob. Commun. Conf. GLOBECOM 2019 - Proc. (2019) 12-17. https://doi.org/10.1109/GLOBECOM38437.2019.9013246."}]},{"#name":"bib-reference","$":{"id":"b0270"},"$$":[{"#name":"label","_":"[54]"},{"#name":"reference","$":{"id":"h0270","refId":"54"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"L."},{"#name":"surname","_":"Yang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Moubayed"}]},{"#name":"author","$$":[{"#name":"given-name","_":"I."},{"#name":"surname","_":"Hamieh"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Shami"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Tree-based intelligent intrusion detection system in internet of vehicles"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"2019 IEEE Glob. Commun. Conf. GLOBECOM 2019 â€“ Proc."}]}]},{"#name":"date","_":"2019"}]},{"#name":"doi","_":"10.1109/GLOBECOM38437.2019.9013892"}]}]},{"#name":"source-text","$":{"id":"str275"},"_":"L. Yang, A. Moubayed, I. Hamieh, A. Shami, Tree-based intelligent intrusion detection system in internet of vehicles, 2019 IEEE Glob. Commun. Conf. GLOBECOM 2019 - Proc. (2019). https://doi.org/10.1109/GLOBECOM38437.2019.9013892."}]},{"#name":"bib-reference","$":{"id":"b0275"},"$$":[{"#name":"label","_":"[55]"},{"#name":"other-ref","$":{"id":"h0275","refId":"55"},"$$":[{"#name":"textref","_":"S. Sanders, C. Giraud-Carrier, Informing the use of hyperparameter optimization through metalearning, Proc. â€“ IEEE Int. Conf. Data Mining, ICDM. 2017-Novem (2017) 1051â€“1056. https://doi.org/10.1109/ICDM.2017.137"}]},{"#name":"source-text","$":{"id":"str280"},"_":"S. Sanders, C. Giraud-Carrier, Informing the use of hyperparameter optimization through metalearning, Proc. - IEEE Int. Conf. Data Mining, ICDM. 2017-Novem (2017) 1051-1056. https://doi.org/10.1109/ICDM.2017.137."}]},{"#name":"bib-reference","$":{"id":"b0280"},"$$":[{"#name":"label","_":"[56]"},{"#name":"other-ref","$":{"id":"h0280","refId":"56"},"$$":[{"#name":"textref","_":"M. Injadat, F. Salo, A.B. Nassif, A. Essex, A. Shami, Bayesian optimization with machine learning algorithms towards anomaly detection, 2018 IEEE Glob. Commun. Conf. (2018) 1â€“6. https://doi.org/10.1109/glocom.2018.8647714."}]},{"#name":"source-text","$":{"id":"str285"},"_":"M. Injadat, F. Salo, A.B. Nassif, A. Essex, A. Shami, Bayesian Optimization with Machine Learning Algorithms Towards Anomaly Detection, 2018 IEEE Glob. Commun. Conf. (2018) 1-6. https://doi.org/10.1109/glocom.2018.8647714."}]},{"#name":"bib-reference","$":{"id":"b0285"},"$$":[{"#name":"label","_":"[57]"},{"#name":"other-ref","$":{"id":"h0285","refId":"57"},"$$":[{"#name":"textref","_":"K. Arjunan, C.N. Modi, An enhanced intrusion detection framework for securing network layer of cloud computing, ISEA Asia Secur. Priv. Conf. 2017, ISEASP 2017. (2017) 1â€“10. doi: 10.1109/ISEASP.2017.7976988."}]},{"#name":"source-text","$":{"id":"str290"},"_":"K. Arjunan, C.N. Modi, An enhanced intrusion detection framework for securing network layer of cloud computing, ISEA Asia Secur. Priv. Conf. 2017, ISEASP 2017. (2017) 1-10. https://doi.org/10.1109/ISEASP.2017.7976988."}]},{"#name":"bib-reference","$":{"id":"b0290"},"$$":[{"#name":"label","_":"[58]"},{"#name":"reference","$":{"id":"h0290","refId":"58"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Xia"}]},{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Liu"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y.Y."},{"#name":"surname","_":"Li"}]},{"#name":"author","$$":[{"#name":"given-name","_":"N."},{"#name":"surname","_":"Liu"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A boosted decision tree approach using Bayesian hyper-parameter optimization for credit scoring"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Expert Syst. Appl."}]},{"#name":"volume-nr","_":"78"}]},{"#name":"date","_":"2017"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"225"},{"#name":"last-page","_":"241"}]},{"#name":"doi","_":"10.1016/j.eswa.2017.02.017"}]}]},{"#name":"source-text","$":{"id":"str295"},"_":"Y. Xia, C. Liu, Y.Y. Li, N. Liu, A boosted decision tree approach using Bayesian hyper-parameter optimization for credit scoring, Expert Syst. Appl. 78 (2017) 225-241. https://doi.org/10.1016/j.eswa.2017.02.017."}]},{"#name":"bib-reference","$":{"id":"b0295"},"$$":[{"#name":"label","_":"[59]"},{"#name":"reference","$":{"id":"h0295","refId":"59"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"T.G."},{"#name":"surname","_":"Dietterich"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Ensemble methods in machine learning"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Mult. Classif. Syst."}]},{"#name":"volume-nr","_":"2000"}]},{"#name":"date","_":"1857"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"15"}]}]}]},{"#name":"source-text","$":{"id":"str300"},"_":"T. G. Dietterich, Ensemble methods in machine learning, Mult. Classif. Syst., 1857 (2000), 1-15."}]},{"#name":"bib-reference","$":{"id":"b0300"},"$$":[{"#name":"label","_":"[60]"},{"#name":"other-ref","$":{"id":"h0300","refId":"60"},"$$":[{"#name":"textref","_":"W. Yin, K. Kann, M. Yu, H. SchÃ¼tze, Comparative Study of CNN and RNN for Natural Language Processing, arXiv preprint arXiv:1702.01923, (2017). https://arxiv.org/abs1702.01923."}]},{"#name":"source-text","$":{"id":"str305"},"_":"W. Yin, K. Kann, M. Yu, and H. SchÃ¼tze, Comparative Study of CNN and RNN for Natural Language Processing, arXiv preprint arXiv:1702.01923, (2017). https://arxiv.org/abs1702.01923"}]},{"#name":"bib-reference","$":{"id":"b0305"},"$$":[{"#name":"label","_":"[61]"},{"#name":"reference","$":{"id":"h0305","refId":"61"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Koutsoukas"}]},{"#name":"author","$$":[{"#name":"given-name","_":"K.J."},{"#name":"surname","_":"Monaghan"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Li"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Huan"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Deep-learning: Investigating deep neural networks hyper-parameters and comparison of performance to shallow methods for modeling bioactivity data"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Cheminf."}]},{"#name":"volume-nr","_":"9"}]},{"#name":"date","_":"2017"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"13"}]},{"#name":"doi","_":"10.1186/s13321-017-0226-y"}]}]},{"#name":"source-text","$":{"id":"str310"},"_":"A. Koutsoukas, K.J. Monaghan, X. Li, J. Huan, Deep-learning: Investigating deep neural networks hyper-parameters and comparison of performance to shallow methods for modeling bioactivity data, J. Cheminform. 9 (2017) 1-13. https://doi.org/10.1186/s13321-017-0226-y."}]},{"#name":"bib-reference","$":{"id":"b0310"},"$$":[{"#name":"label","_":"[62]"},{"#name":"reference","$":{"id":"h0310","refId":"62"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"T."},{"#name":"surname","_":"Domhan"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J.T."},{"#name":"surname","_":"Springenberg"}]},{"#name":"author","$$":[{"#name":"given-name","_":"F."},{"#name":"surname","_":"Hutter"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IJCAI Int. Jt. Conf. Artif. Intell."}]}]},{"#name":"date","_":"2015- (2015)"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"3460"},{"#name":"last-page","_":"3468"}]}]}]},{"#name":"source-text","$":{"id":"str315"},"_":"T. Domhan, J.T. Springenberg, F. Hutter, Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves, IJCAI Int. Jt. Conf. Artif. Intell. 2015-January (2015) 3460-3468."}]},{"#name":"bib-reference","$":{"id":"b0315"},"$$":[{"#name":"label","_":"[63]"},{"#name":"reference","$":{"id":"h0315","refId":"63"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Ozaki"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Yano"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Onishi"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Effective hyperparameter optimization using Nelder-Mead method in deep learning"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IPSJ Trans. Comput. Vis. Appl."}]},{"#name":"volume-nr","_":"9"}]},{"#name":"date","_":"2017"}]},{"#name":"doi","_":"10.1186/s41074-017-0030-7"}]}]},{"#name":"source-text","$":{"id":"str320"},"_":"Y. Ozaki, M. Yano, M. Onishi, Effective hyperparameter optimization using Nelder-Mead method in deep learning, IPSJ Trans. Comput. Vis. Appl. 9 (2017). https://doi.org/10.1186/s41074-017-0030-7."}]},{"#name":"bib-reference","$":{"id":"b0320"},"$$":[{"#name":"label","_":"[64]"},{"#name":"reference","$":{"id":"h0320","refId":"64"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"F.C."},{"#name":"surname","_":"Soon"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H.Y."},{"#name":"surname","_":"Khaw"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J.H."},{"#name":"surname","_":"Chuah"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Kanesan"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Hyper-parameters optimisation of deep CNN architecture for vehicle logo recognition"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IET Intell. Transp. Syst."}]},{"#name":"volume-nr","_":"12"}]},{"#name":"date","_":"2018"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"939"},{"#name":"last-page","_":"946"}]},{"#name":"doi","_":"10.1049/iet-its.2018.5127"}]}]},{"#name":"source-text","$":{"id":"str325"},"_":"F.C. Soon, H.Y. Khaw, J.H. Chuah, J. Kanesan, Hyper-parameters optimisation of deep CNN architecture for vehicle logo recognition, IET Intell. Transp. Syst. 12 (2018) 939-946. https://doi.org/10.1049/iet-its.2018.5127."}]},{"#name":"bib-reference","$":{"id":"b0325"},"$$":[{"#name":"label","_":"[65]"},{"#name":"reference","$":{"id":"h0325","refId":"65"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"D."},{"#name":"surname","_":"Han"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Q."},{"#name":"surname","_":"Liu"}]},{"#name":"author","$$":[{"#name":"given-name","_":"W."},{"#name":"surname","_":"Fan"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A new image classification method using CNN transfer learning and web data augmentation"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Expert Syst. Appl."}]},{"#name":"volume-nr","_":"95"}]},{"#name":"date","_":"2018"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"43"},{"#name":"last-page","_":"56"}]},{"#name":"doi","_":"10.1016/j.eswa.2017.11.028"}]}]},{"#name":"source-text","$":{"id":"str330"},"_":"D. Han, Q. Liu, W. Fan, A new image classification method using CNN transfer learning and web data augmentation, Expert Syst. Appl. 95 (2018) 43-56. https://doi.org/10.1016/j.eswa.2017.11.028."}]},{"#name":"bib-reference","$":{"id":"b0330"},"$$":[{"#name":"label","_":"[66]"},{"#name":"reference","$":{"id":"h0330","refId":"66"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Di Francescomarino"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Dumas"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Federici"}]},{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Ghidini"}]},{"#name":"author","$$":[{"#name":"given-name","_":"F.M."},{"#name":"surname","_":"Maggi"}]},{"#name":"author","$$":[{"#name":"given-name","_":"W."},{"#name":"surname","_":"Rizzi"}]},{"#name":"author","$$":[{"#name":"given-name","_":"L."},{"#name":"surname","_":"Simonetto"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Genetic algorithms for hyperparameter optimization in predictive business process monitoring"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Inf. Syst."}]},{"#name":"volume-nr","_":"74"}]},{"#name":"date","_":"2018"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"67"},{"#name":"last-page","_":"83"}]},{"#name":"doi","_":"10.1016/j.is.2018.01.003"}]}]},{"#name":"source-text","$":{"id":"str335"},"_":"C. Di Francescomarino, M. Dumas, M. Federici, C. Ghidini, F.M. Maggi, W. Rizzi, L. Simonetto, Genetic algorithms for hyperparameter optimization in predictive business process monitoring, Inf. Syst. 74 (2018) 67-83. https://doi.org/10.1016/j.is.2018.01.003."}]},{"#name":"bib-reference","$":{"id":"b0335"},"$$":[{"#name":"label","_":"[67]"},{"#name":"reference","$":{"id":"h0335","refId":"67"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Moubayed"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Injadat"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Shami"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Lutfiyya"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Student engagement level in e-learning environment: clustering using K-means"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Am. J. Distance Educ."}]},{"#name":"volume-nr","_":"34"}]},{"#name":"date","_":"2020"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"20"}]},{"#name":"doi","_":"10.1080/08923647.2020.1696140"}]}]},{"#name":"source-text","$":{"id":"str340"},"_":"A. Moubayed, M. Injadat, A. Shami, H. Lutfiyya, Student Engagement Level in e-Learning Environment: Clustering Using K-means, Am. J. Distance Educ. 34 (2020) 1-20. https://doi.org/10.1080/08923647.2020.1696140."}]},{"#name":"bib-reference","$":{"id":"b0340"},"$$":[{"#name":"label","_":"[68]"},{"#name":"reference","$":{"id":"h0340","refId":"68"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Ding"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"He"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Cluster structure of K-means clustering via principal component analysis"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Lect. Notes Comput. Sci. (Including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics)"}]},{"#name":"volume-nr","_":"3056"}]},{"#name":"date","_":"2004"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"414"},{"#name":"last-page","_":"418"}]},{"#name":"doi","_":"10.1145/1015330.1015408"}]}]},{"#name":"source-text","$":{"id":"str345"},"_":"C. Ding, X. He, Cluster structure of K-means clustering via principal component analysis, Lect. Notes Comput. Sci. (Including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics). 3056 (2004) 414-418. https://doi.org/10.1145/1015330.1015408."}]},{"#name":"bib-reference","$":{"id":"b0345"},"$$":[{"#name":"label","_":"[69]"},{"#name":"reference","$":{"id":"h0345","refId":"69"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"T.K."},{"#name":"surname","_":"Moon"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"The expectation-maximization algorithm"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IEEE Signal Process. Mag."}]},{"#name":"volume-nr","_":"13"}]},{"#name":"issue-nr","_":"6"},{"#name":"date","_":"1996"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"47"},{"#name":"last-page","_":"60"}]}]}]},{"#name":"source-text","$":{"id":"str350"},"_":"T. K. Moon, The expectation-maximization algorithm, IEEE Signal Process. Mag. 13 (6) (1996) 47-60."}]},{"#name":"bib-reference","$":{"id":"b0350"},"$$":[{"#name":"label","_":"[70]"},{"#name":"reference","$":{"id":"h0350","refId":"70"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Brahim-Belhouari"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Bermak"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Shi"}]},{"#name":"author","$$":[{"#name":"given-name","_":"P.C.H."},{"#name":"surname","_":"Chan"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Fast and Robust gas identification system using an integrated gas sensor technology and Gaussian mixture models"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IEEE Sens. J."}]},{"#name":"volume-nr","_":"5"}]},{"#name":"date","_":"2005"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1433"},{"#name":"last-page","_":"1444"}]},{"#name":"doi","_":"10.1109/JSEN.2005.858926"}]}]},{"#name":"source-text","$":{"id":"str355"},"_":"S. Brahim-Belhouari, A. Bermak, M. Shi, P.C.H. Chan, Fast and Robust gas identification system using an integrated gas sensor technology and Gaussian mixture models, IEEE Sens. J. 5 (2005) 1433-1444. https://doi.org/10.1109/JSEN.2005.858926."}]},{"#name":"bib-reference","$":{"id":"b0355"},"$$":[{"#name":"label","_":"[71]"},{"#name":"other-ref","$":{"id":"h0355","refId":"71"},"$$":[{"#name":"textref","_":"Z. Y., K. G., Hierarchical clustering algorithms for document dataset, Data Min. Knowl. Discov. 10 (2005) 141â€“168."}]},{"#name":"source-text","$":{"id":"str360"},"_":"Z. Y., K. G., Hierarchical Clustering Algorithms for Document Dataset, Data Min. Knowl. Discov. 10 (2005) 141-168."}]},{"#name":"bib-reference","$":{"id":"b0360"},"$$":[{"#name":"label","_":"[72]"},{"#name":"other-ref","$":{"id":"h0360","refId":"72"},"$$":[{"#name":"textref","_":"K. Khan, S.U. Rehman, K. Aziz, S. Fong, S. Sarasvady, A. Vishwa, DBSCAN: Past, present and future, 5th Int. Conf. Appl. Digit. Inf. Web Technol. ICADIWT 2014, 2014, pp. 232â€“238. https://doi.org/10.1109/ICADIWT.2014.6814687."}]},{"#name":"source-text","$":{"id":"str365"},"_":"K. Khan, S.U. Rehman, K. Aziz, S. Fong, S. Sarasvady, A. Vishwa, DBSCAN: Past, present and future, 5th Int. Conf. Appl. Digit. Inf. Web Technol. ICADIWT 2014. (2014) 232-238. https://doi.org/10.1109/ICADIWT.2014.6814687."}]},{"#name":"bib-reference","$":{"id":"b0365"},"$$":[{"#name":"label","_":"[73]"},{"#name":"reference","$":{"id":"h0365","refId":"73"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Zhou"}]},{"#name":"author","$$":[{"#name":"given-name","_":"P."},{"#name":"surname","_":"Wang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Li"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Research on adaptive parameters determination in DBSCAN algorithm"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Inf. Comput. Sci."}]},{"#name":"volume-nr","_":"9"}]},{"#name":"date","_":"2012"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1967"},{"#name":"last-page","_":"1973"}]}]}]},{"#name":"source-text","$":{"id":"str370"},"_":"H. Zhou, P. Wang, H. Li, Research on adaptive parameters determination in DBSCAN algorithm, J. Inf. Comput. Sci. 9 (2012) 1967-1973."}]},{"#name":"bib-reference","$":{"id":"b0370"},"$$":[{"#name":"label","_":"[74]"},{"#name":"other-ref","$":{"id":"h0370","refId":"74"},"$$":[{"#name":"textref","_":"J. Shlens, A Tutorial on Principal Component Analysis, arXiv preprint arXiv:1404.1100, (2014). https://arxiv.org/abs1404.1100"}]},{"#name":"source-text","$":{"id":"str375"},"_":"J. Shlens, A Tutorial on Principal Component Analysis, arXiv preprint arXiv:1404.1100, (2014). https://arxiv.org/abs1404.1100"}]},{"#name":"bib-reference","$":{"id":"b0375"},"$$":[{"#name":"label","_":"[75]"},{"#name":"reference","$":{"id":"h0375","refId":"75"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"N."},{"#name":"surname","_":"Halko"}]},{"#name":"author","$$":[{"#name":"given-name","_":"P."},{"#name":"surname","_":"Martinsson"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Tropp"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Finding structure with randomness: probabilistic algorithms for constructing approximate matrix decompositions"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"SIAM Rev."}]},{"#name":"volume-nr","_":"53"}]},{"#name":"issue-nr","_":"2"},{"#name":"date","_":"2011"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"217"},{"#name":"last-page","_":"288"}]}]}]},{"#name":"source-text","$":{"id":"str380"},"_":"N. Halko, P. Martinsson, J. Tropp, Finding structure with randomness: probabilistic algorithms for constructing approximate matrix decompositions, SIAM Rev. 53 (2) (2011), pp. 217-288"}]},{"#name":"bib-reference","$":{"id":"b0380"},"$$":[{"#name":"label","_":"[76]"},{"#name":"reference","$":{"id":"h0380","refId":"76"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Loog"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Conditional linear discriminant analysis"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proc. â€“ Int. Conf. Pattern Recognit."}]},{"#name":"volume-nr","_":"2"}]},{"#name":"date","_":"2006"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"387"},{"#name":"last-page","_":"390"}]},{"#name":"doi","_":"10.1109/ICPR.2006.402"}]}]},{"#name":"source-text","$":{"id":"str385"},"_":"M. Loog, Conditional linear discriminant analysis, Proc. - Int. Conf. Pattern Recognit. 2 (2006) 387-390. https://doi.org/10.1109/ICPR.2006.402."}]},{"#name":"bib-reference","$":{"id":"b0385"},"$$":[{"#name":"label","_":"[77]"},{"#name":"reference","$":{"id":"h0385","refId":"77"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"P."},{"#name":"surname","_":"Howland"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Wang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Park"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Solving the small sample size problem in face recognition using generalized discriminant analysis"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Pattern Recognit."}]},{"#name":"volume-nr","_":"39"}]},{"#name":"date","_":"2006"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"277"},{"#name":"last-page","_":"287"}]},{"#name":"doi","_":"10.1016/j.patcog.2005.06.013"}]}]},{"#name":"source-text","$":{"id":"str390"},"_":"P. Howland, J. Wang, H. Park, Solving the small sample size problem in face recognition using generalized discriminant analysis, Pattern Recognit. 39 (2006) 277-287. https://doi.org/10.1016/j.patcog.2005.06.013."}]},{"#name":"bib-reference","$":{"id":"b0390"},"$$":[{"#name":"label","_":"[78]"},{"#name":"other-ref","$":{"id":"h0390","refId":"78"},"$$":[{"#name":"textref","_":"I. Ilievski, T. Akhtar, J. Feng, C.A. Shoemaker, Efficient hyperparameter optimization of deep learning algorithms using deterministic RBF surrogates, 31st AAAI Conf. Artif. Intell. AAAI 2017, 2017, pp. 822â€“829"}]},{"#name":"source-text","$":{"id":"str395"},"_":"I. Ilievski, T. Akhtar, J. Feng, C.A. Shoemaker, Efficient hyperparameter optimization of deep learning algorithms using deterministic RBF surrogates, 31st AAAI Conf. Artif. Intell. AAAI 2017. (2017) 822-829."}]},{"#name":"bib-reference","$":{"id":"b0395"},"$$":[{"#name":"label","_":"[79]"},{"#name":"reference","$":{"id":"h0395","refId":"79"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Claesen"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Simm"}]},{"#name":"author","$$":[{"#name":"given-name","_":"D."},{"#name":"surname","_":"Popovic"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Moreau"}]},{"#name":"author","$$":[{"#name":"given-name","_":"B."},{"#name":"surname","_":"De Moor"}]}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Easy Hyperparameter Search Using Optunity, arXiv preprint arXiv:1412.1114"}]}]},{"#name":"date","_":"2014"}]}]}]},{"#name":"source-text","$":{"id":"str400"},"_":"M. Claesen, J. Simm, D. Popovic, Y. Moreau, and B. De Moor, Easy Hyperparameter Search Using Optunity, arXiv preprint arXiv:1412.1114, (2014). https://arxiv.org/abs1412.1114."}]},{"#name":"bib-reference","$":{"id":"b0400"},"$$":[{"#name":"label","_":"[80]"},{"#name":"other-ref","$":{"id":"h0400","refId":"80"},"$$":[{"#name":"textref","_":"C. Witt, Worst-case and average-case approximations by simple randomized search heuristics, in: Proceedings of the 22nd Annual Symposium on Theoretical Aspects of Computer Science, STACSâ€™05, Stuttgart, Germany, 2005, pp. 44-56."}]},{"#name":"source-text","$":{"id":"str405"},"_":"C. Witt, Worst-case and average-case approximations by simple randomized search heuristics, in: Proceedings of the 22nd Annual Symposium on Theoretical Aspects of Computer Science, STACSâ€™05, Stuttgart, Germany, 2005, pp. 44-56."}]},{"#name":"bib-reference","$":{"id":"b0405"},"$$":[{"#name":"label","_":"[81]"},{"#name":"reference","$":{"id":"h0405","refId":"81"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Bengio"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Gradient-based optimization of hyperparameters"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Neural Comput."}]},{"#name":"volume-nr","_":"12"}]},{"#name":"issue-nr","_":"8"},{"#name":"date","_":"2000"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1889"},{"#name":"last-page","_":"1900"}]}]}]},{"#name":"source-text","$":{"id":"str410"},"_":"Y. Bengio, Gradient-based optimization of hyperparameters, Neural Comput. 12 (8) (2000) 1889-1900."}]},{"#name":"bib-reference","$":{"id":"b0410"},"$$":[{"#name":"label","_":"[82]"},{"#name":"reference","$":{"id":"h0410","refId":"82"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"H.H."},{"#name":"surname","_":"Yang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"S.I."},{"#name":"surname","_":"Amari"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Complexity issues in natural gradient descent method for training multilayer perceptrons"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Neural Comput."}]},{"#name":"volume-nr","_":"10"}]},{"#name":"issue-nr","_":"8"},{"#name":"date","_":"1998"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"2137"},{"#name":"last-page","_":"2157"}]}]}]},{"#name":"source-text","$":{"id":"str415"},"_":"H. H. Yang and S. I. Amari, Complexity Issues in Natural Gradient Descent Method for Training Multilayer Perceptrons, Neural Comput. 10 (8) (1998) 2137-2157."}]},{"#name":"bib-reference","$":{"id":"b0415"},"$$":[{"#name":"label","_":"[83]"},{"#name":"other-ref","$":{"id":"h0415","refId":"83"},"$$":[{"#name":"textref","_":"J. Snoek, H. Larochelle, R. Adams, Practical Bayesian optimization of machine learning algorithms, Adv. Neural Inf. Process. Syst. 4 (2012) 2951â€“2959."}]},{"#name":"source-text","$":{"id":"str420"},"_":"J. Snoek, H. Larochelle, R. Adams Practical Bayesian optimization of machine learning algorithms Adv. Neural Inf. Process. Syst. 4 (2012), 2951-2959."}]},{"#name":"bib-reference","$":{"id":"b0420"},"$$":[{"#name":"label","_":"[84]"},{"#name":"reference","$":{"id":"h0420","refId":"84"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"E."},{"#name":"surname","_":"Hazan"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Klivans"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Yuan"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Hyperparameter optimization: a spectral approach, arXiv preprint arXiv:1706.00764"}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"date","_":"2017"}]}]}]},{"#name":"source-text","$":{"id":"str425"},"_":"E. Hazan, A. Klivans, and Y. Yuan, Hyperparameter optimization: a spectral approach, arXiv preprint arXiv:1706.00764, (2017). https://arxiv.org/abs1706.00764."}]},{"#name":"bib-reference","$":{"id":"b0425"},"$$":[{"#name":"label","_":"[85]"},{"#name":"reference","$":{"id":"h0425","refId":"85"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Seeger"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Gaussian processes for machine learning"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Int. J. Neural Syst."}]},{"#name":"volume-nr","_":"14"}]},{"#name":"date","_":"2004"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"69"},{"#name":"last-page","_":"106"}]}]}]},{"#name":"source-text","$":{"id":"str430"},"_":"M. Seeger, Gaussian processes for machine learning, Int. J. Neural Syst., 14 (2004), 69-106."}]},{"#name":"bib-reference","$":{"id":"b0430"},"$$":[{"#name":"label","_":"[86]"},{"#name":"reference","$":{"id":"h0430","refId":"86"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"F."},{"#name":"surname","_":"Hutter"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H.H."},{"#name":"surname","_":"Hoos"}]},{"#name":"author","$$":[{"#name":"given-name","_":"K."},{"#name":"surname","_":"Leyton-Brown"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Sequential model-based optimization for general algorithm configuration"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proc. LION"}]},{"#name":"volume-nr","_":"5"}]},{"#name":"date","_":"2011"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"507"},{"#name":"last-page","_":"523"}]}]}]},{"#name":"source-text","$":{"id":"str435"},"_":"F. Hutter, H. H. Hoos, and K. Leyton-Brown, Sequential model-based optimization for general algorithm configuration, Proc. LION 5, (2011) 507-523."}]},{"#name":"bib-reference","$":{"id":"b0435"},"$$":[{"#name":"label","_":"[87]"},{"#name":"other-ref","$":{"id":"h0435","refId":"87"},"$$":[{"#name":"textref","_":"I. Dewancker, M. McCourt, S. Clark, Bayesian Optimization Primer, (2015). URL: https://sigopt.com/static/pdf/SigOpt Bayesian Optimization Primer.pdf."}]},{"#name":"source-text","$":{"id":"str440"},"_":"I. Dewancker, M. McCourt, S. Clark, Bayesian Optimization Primer, (2015) URL: https://sigopt.com/static/pdf/SigOpt Bayesian Optimization Primer.pdf"}]},{"#name":"bib-reference","$":{"id":"b0440"},"$$":[{"#name":"label","_":"[88]"},{"#name":"reference","$":{"id":"h0440","refId":"88"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Hensman"}]},{"#name":"author","$$":[{"#name":"given-name","_":"N."},{"#name":"surname","_":"Fusi"}]},{"#name":"author","$$":[{"#name":"given-name","_":"N.D."},{"#name":"surname","_":"Lawrence"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Gaussian processes for big data, arXiv preprint arXiv:1309.6835"}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"date","_":"2013"}]}]}]},{"#name":"source-text","$":{"id":"str445"},"_":"J. Hensman, N. Fusi, and N. D. Lawrence, Gaussian processes for big data, arXiv preprint arXiv:1309.6835, (2013). https://arxiv.org/abs/1309.6835."}]},{"#name":"bib-reference","$":{"id":"b0445"},"$$":[{"#name":"label","_":"[89]"},{"#name":"reference","$":{"id":"h0445","refId":"89"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Claesen"}]},{"#name":"author","$$":[{"#name":"given-name","_":"B."},{"#name":"surname","_":"De Moor"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Hyperparameter Search in Machine Learning, arXiv preprint arXiv:1502.02127"}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"date","_":"2015"}]}]}]},{"#name":"source-text","$":{"id":"str450"},"_":"M. Claesen and B. De Moor, Hyperparameter Search in Machine Learning, arXiv preprint arXiv:1502.02127, (2015). https://arxiv.org/abs1502.02127."}]},{"#name":"bib-reference","$":{"id":"b0450"},"$$":[{"#name":"label","_":"[90]"},{"#name":"other-ref","$":{"id":"h0450","refId":"90"},"$$":[{"#name":"textref","_":"L. Bottou, Large-scale machine learning with stochastic gradient descent, in: Proceedings of the COMPSTAT, Springer, 2010, pp. 177â€“186."}]},{"#name":"source-text","$":{"id":"str455"},"_":"L. Bottou, Large-scale machine learning with stochastic gradient descent, Proceedings of the COMPSTAT, Springer (2010) 177-186."}]},{"#name":"bib-reference","$":{"id":"b0455"},"$$":[{"#name":"label","_":"[91]"},{"#name":"reference","$":{"id":"h0455","refId":"91"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Zhang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Xu"}]},{"#name":"author","$$":[{"#name":"given-name","_":"E."},{"#name":"surname","_":"Huang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"C.H."},{"#name":"surname","_":"Chen"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A new optimal sampling rule for multi-fidelity optimization via ordinal transformation"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"IEEE Int. Conf. Autom. Sci. Eng."}]}]},{"#name":"date","_":"2016- (2016)"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"670"},{"#name":"last-page","_":"674"}]},{"#name":"doi","_":"10.1109/COASE.2016.7743467"}]}]},{"#name":"source-text","$":{"id":"str460"},"_":"S. Zhang, J. Xu, E. Huang, C.H. Chen, A new optimal sampling rule for multi-fidelity optimization via ordinal transformation, IEEE Int. Conf. Autom. Sci. Eng. 2016-Novem (2016) 670-674. https://doi.org/10.1109/COASE.2016.7743467."}]},{"#name":"bib-reference","$":{"id":"b0460"},"$$":[{"#name":"label","_":"[92]"},{"#name":"reference","$":{"id":"h0460","refId":"92"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Z."},{"#name":"surname","_":"Karnin"}]},{"#name":"author","$$":[{"#name":"given-name","_":"T."},{"#name":"surname","_":"Koren"}]},{"#name":"author","$$":[{"#name":"given-name","_":"O."},{"#name":"surname","_":"Somekh"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Almost optimal exploration in multi-armed bandits"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"30th Int. Conf. Mach. Learn. ICML 2013"}]}]},{"#name":"issue-nr","_":"28"},{"#name":"date","_":"2013"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"2275"},{"#name":"last-page","_":"2283"}]}]}]},{"#name":"source-text","$":{"id":"str465"},"_":"Z. Karnin, T. Koren, O. Somekh, Almost optimal exploration in multi-armed bandits, 30th Int. Conf. Mach. Learn. ICML 2013. 28 (2013) 2275-2283."}]},{"#name":"bib-reference","$":{"id":"b0465"},"$$":[{"#name":"label","_":"[93]"},{"#name":"reference","$":{"id":"h0465","refId":"93"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Falkner"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Klein"}]},{"#name":"author","$$":[{"#name":"given-name","_":"F."},{"#name":"surname","_":"Hutter"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"BOHB: robust and efficient hyperparameter optimization at scale"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"35th Int. Conf. Mach. Learn. ICML 2018"}]}]},{"#name":"issue-nr","_":"4"},{"#name":"date","_":"2018"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"2323"},{"#name":"last-page","_":"2341"}]}]}]},{"#name":"source-text","$":{"id":"str470"},"_":"S. Falkner, A. Klein, F. Hutter, BOHB: Robust and Efficient Hyperparameter Optimization at Scale, 35th Int. Conf. Mach. Learn. ICML 2018. 4 (2018) 2323-2341."}]},{"#name":"bib-reference","$":{"id":"b0470"},"$$":[{"#name":"label","_":"[94]"},{"#name":"reference","$":{"id":"h0470","refId":"94"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Gogna"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Tayal"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Metaheuristics: review and application"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Exp. Theor. Artif. Intell."}]},{"#name":"volume-nr","_":"25"}]},{"#name":"date","_":"2013"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"503"},{"#name":"last-page","_":"526"}]},{"#name":"doi","_":"10.1080/0952813X.2013.782347"}]}]},{"#name":"source-text","$":{"id":"str475"},"_":"A. Gogna, A. Tayal, Metaheuristics: Review and application, J. Exp. Theor. Artif. Intell. 25 (2013) 503-526. https://doi.org/10.1080/0952813X.2013.782347."}]},{"#name":"bib-reference","$":{"id":"b0475"},"$$":[{"#name":"label","_":"[95]"},{"#name":"reference","$":{"id":"h0475","refId":"95"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"F."},{"#name":"surname","_":"Itano"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M.A."},{"#name":"surname","_":"De Abreu De"}]},{"#name":"author","$$":[{"#name":"given-name","_":"E. Del-Moral-Hernandez"},{"#name":"surname","_":"Sousa"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Extending MLP ANN hyper-parameters Optimization by using Genetic Algorithm"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proc. Int. Jt. Conf. Neural Networks"}]}]},{"#name":"date","_":"2018"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"8"}]},{"#name":"doi","_":"10.1109/IJCNN.2018.8489520"}]}]},{"#name":"source-text","$":{"id":"str480"},"_":"F. Itano, M.A. De Abreu De Sousa, E. Del-Moral-Hernandez, Extending MLP ANN hyper-parameters Optimization by using Genetic Algorithm, Proc. Int. Jt. Conf. Neural Networks. 2018-July (2018) 1-8. https://doi.org/10.1109/IJCNN.2018.8489520."}]},{"#name":"bib-reference","$":{"id":"b0480"},"$$":[{"#name":"label","_":"[96]"},{"#name":"other-ref","$":{"id":"h0480","refId":"96"},"$$":[{"#name":"textref","_":"B. Kazimipour, X. Li, A.K. Qin, A Review of Population Initialization Techniques for Evolutionary Algorithms, 2014 IEEE Congr. Evol. Comput. (2014) 2585â€“2592. https://doi.org/10.1109/CEC.2014.6900618."}]},{"#name":"source-text","$":{"id":"str485"},"_":"B. Kazimipour, X. Li, A.K. Qin, A Review of Population Initialization Techniques for Evolutionary Algorithms, 2014 IEEE Congr. Evol. Comput. (2014) 2585-2592. https://doi.org/10.1109/CEC.2014.6900618."}]},{"#name":"bib-reference","$":{"id":"b0485"},"$$":[{"#name":"label","_":"[97]"},{"#name":"reference","$":{"id":"h0485","refId":"97"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Rahnamayan"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H.R."},{"#name":"surname","_":"Tizhoosh"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M.M.A."},{"#name":"surname","_":"Salama"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A novel population initialization method for accelerating evolutionary algorithms"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Comput. Math. Appl."}]},{"#name":"volume-nr","_":"53"}]},{"#name":"date","_":"2007"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1605"},{"#name":"last-page","_":"1614"}]},{"#name":"doi","_":"10.1016/j.camwa.2006.07.013"}]}]},{"#name":"source-text","$":{"id":"str490"},"_":"S. Rahnamayan, H.R. Tizhoosh, M.M.A. Salama, A novel population initialization method for accelerating evolutionary algorithms, Comput. Math. with Appl. 53 (2007) 1605-1614. https://doi.org/10.1016/j.camwa.2006.07.013."}]},{"#name":"bib-reference","$":{"id":"b0490"},"$$":[{"#name":"label","_":"[98]"},{"#name":"reference","$":{"id":"h0490","refId":"98"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"F.G."},{"#name":"surname","_":"Lobo"}]},{"#name":"author","$$":[{"#name":"given-name","_":"D.E."},{"#name":"surname","_":"Goldberg"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Pelikan"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Time complexity of genetic algorithms on exponentially scaled problems"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proc. Genet. Evol. Comput. Conf."}]}]},{"#name":"date","_":"2000"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"151"},{"#name":"last-page","_":"158"}]}]}]},{"#name":"source-text","$":{"id":"str495"},"_":"F. G. Lobo, D. E. Goldberg, and M. Pelikan, Time complexity of genetic algorithms on exponentially scaled problems, Proc. Genet. Evol. Comput. Conf., (2000) 151-158."}]},{"#name":"bib-reference","$":{"id":"b0495"},"$$":[{"#name":"label","_":"[99]"},{"#name":"other-ref","$":{"id":"h0495","refId":"99"},"$$":[{"#name":"textref","_":"Y. Shi, R.C. Eberhart, Parameter Selection in Particle Swarm Optimization, Evolutionary Programming VII, Springer, 1998, pp. 591â€“600."}]}]},{"#name":"bib-reference","$":{"id":"b0500"},"$$":[{"#name":"label","_":"[100]"},{"#name":"reference","$":{"id":"h0500","refId":"100"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Yan"}]},{"#name":"author","$$":[{"#name":"given-name","_":"F."},{"#name":"surname","_":"He"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Y."},{"#name":"surname","_":"Chen"}]}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"A Novel Hardware/ Software Partitioning Method Based on Position Disturbed Particle Swarm Optimization with Invasive Weed Optimization"}]},{"#name":"volume-nr","_":"32"}]},{"#name":"date","_":"2017"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"340"},{"#name":"last-page","_":"355"}]},{"#name":"doi","_":"10.1007/s11390-017-1714-2"}]}]},{"#name":"source-text","$":{"id":"str505"},"_":"X. Yan, F. He, Y. Chen, A Novel Hardware/ Software Partitioning Method Based on Position Disturbed Particle Swarm Optimization with Invasive Weed Optimization, 32 (2017) 340-355. https://doi.org/10.1007/s11390-017-1714-2."}]},{"#name":"bib-reference","$":{"id":"b0505"},"$$":[{"#name":"label","_":"[101]"},{"#name":"reference","$":{"id":"h0505","refId":"101"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"M.Y."},{"#name":"surname","_":"Cheng"}]},{"#name":"author","$$":[{"#name":"given-name","_":"K.Y."},{"#name":"surname","_":"Huang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Hutomo"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Multiobjective dynamic-guiding PSO for optimizing work shift schedules"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Constr. Eng. Manag."}]},{"#name":"volume-nr","_":"144"}]},{"#name":"date","_":"2018"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"7"}]},{"#name":"doi","_":"10.1061/(ASCE)CO.1943-7862.0001548"}]}]},{"#name":"source-text","$":{"id":"str510"},"_":"M.Y. Cheng, K.Y. Huang, M. Hutomo, Multiobjective Dynamic-Guiding PSO for Optimizing Work Shift Schedules, J. Constr. Eng. Manag. 144 (2018) 1-7. https://doi.org/10.1061/(ASCE)CO.1943-7862.0001548."}]},{"#name":"bib-reference","$":{"id":"b0510"},"$$":[{"#name":"label","_":"[102]"},{"#name":"reference","$":{"id":"h0510","refId":"102"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Wang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"Z."},{"#name":"surname","_":"Wu"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Wang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Dong"}]},{"#name":"author","$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Yu"}]},{"#name":"author","$$":[{"#name":"given-name","_":"G."},{"#name":"surname","_":"Chen"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"A new population initialization method based on space transformation search, 5th Int"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Conf. Nat. Comput. ICNC"}]},{"#name":"volume-nr","_":"2009"}]},{"#name":"issue-nr","_":"5"},{"#name":"date","_":"2009"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"332"},{"#name":"last-page","_":"336"}]},{"#name":"doi","_":"10.1109/ICNC.2009.371"}]}]},{"#name":"source-text","$":{"id":"str515"},"_":"H. Wang, Z. Wu, J. Wang, X. Dong, S. Yu, G. Chen, A new population initialization method based on space transformation search, 5th Int. Conf. Nat. Comput. ICNC 2009. 5 (2009) 332-336. https://doi.org/10.1109/ICNC.2009.371."}]},{"#name":"bib-reference","$":{"id":"b0515"},"$$":[{"#name":"label","_":"[103]"},{"#name":"other-ref","$":{"id":"h0515","refId":"103"},"$$":[{"#name":"textref","_":"J. Wang, J. Xu, and X. Wang, Combination of Hyperband and Bayesian Optimization for Hyperparameter Optimization in Deep Learning, arXiv preprint arXiv:1801.01596, (2018). https://arxiv.org/abs1801.01596."}]},{"#name":"source-text","$":{"id":"str520"},"_":"J. Wang, J. Xu, and X. Wang, Combination of Hyperband and Bayesian Optimization for Hyperparameter Optimization in Deep Learning, arXiv preprint arXiv:1801.01596, (2018). https://arxiv.org/abs1801.01596."}]},{"#name":"bib-reference","$":{"id":"b0520"},"$$":[{"#name":"label","_":"[104]"},{"#name":"reference","$":{"id":"h0520","refId":"104"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"P."},{"#name":"surname","_":"Cazzaniga"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M.S."},{"#name":"surname","_":"Nobile"}]},{"#name":"author","$$":[{"#name":"given-name","_":"D."},{"#name":"surname","_":"Besozzi"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"The impact of particles initialization in PSO: parameter estimation as a case in point"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"2015 IEEE Conf. Comput. Intell. Bioinforma. Comput. Biol. CIBCB 2015"}]}]},{"#name":"date","_":"2015"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1"},{"#name":"last-page","_":"8"}]},{"#name":"doi","_":"10.1109/CIBCB.2015.7300288"}]}]},{"#name":"source-text","$":{"id":"str525"},"_":"P. Cazzaniga, M.S. Nobile, D. Besozzi, The impact of particles initialization in PSO: Parameter estimation as a case in point, 2015 IEEE Conf. Comput. Intell. Bioinforma. Comput. Biol. CIBCB 2015. (2015) 1-8. https://doi.org/10.1109/CIBCB.2015.7300288."}]},{"#name":"bib-reference","$":{"id":"b0525"},"$$":[{"#name":"label","_":"[105]"},{"#name":"reference","$":{"id":"h0525","refId":"105"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"R."},{"#name":"surname","_":"Martinez-Cantin"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"BayesOpt: a Bayesian optimization library for nonlinear optimization, experimental design and bandits"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Mach. Learn. Res."}]},{"#name":"volume-nr","_":"15"}]},{"#name":"date","_":"2015"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"3735"},{"#name":"last-page","_":"3739"}]}]}]},{"#name":"source-text","$":{"id":"str530"},"_":"R. Martinez-Cantin, BayesOpt: A Bayesian optimization library for nonlinear optimization, experimental design and bandits, J. Mach. Learn. Res. 15 (2015) 3735-3739."}]},{"#name":"bib-reference","$":{"id":"b0530"},"$$":[{"#name":"label","_":"[106]"},{"#name":"reference","$":{"id":"h0530","refId":"106"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Bergstra"}]},{"#name":"author","$$":[{"#name":"given-name","_":"B."},{"#name":"surname","_":"Komer"}]},{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Eliasmith"}]},{"#name":"author","$$":[{"#name":"given-name","_":"D."},{"#name":"surname","_":"Yamins"}]},{"#name":"author","$$":[{"#name":"given-name","_":"D.D."},{"#name":"surname","_":"Cox"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Hyperopt: a Python library for model selection and hyperparameter optimization"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Comput. Sci. Discov."}]},{"#name":"volume-nr","_":"8"}]},{"#name":"date","_":"2015"}]},{"#name":"doi","_":"10.1088/1749-4699/8/1/014008"}]}]},{"#name":"source-text","$":{"id":"str535"},"_":"J. Bergstra, B. Komer, C. Eliasmith, D. Yamins, D.D. Cox, Hyperopt: A Python library for model selection and hyperparameter optimization, Comput. Sci. Discov. 8 (2015). https://doi.org/10.1088/1749-4699/8/1/014008."}]},{"#name":"bib-reference","$":{"id":"b0535"},"$$":[{"#name":"label","_":"[107]"},{"#name":"reference","$":{"id":"h0535","refId":"107"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"B."},{"#name":"surname","_":"Komer"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Bergstra"}]},{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"Eliasmith"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Hyperopt-sklearn: automatic hyperparameter configuration for scikit-learn"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proc. ICML Workshop AutoML"}]}]},{"#name":"date","_":"2014"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"34"},{"#name":"last-page","_":"40"}]}]}]},{"#name":"source-text","$":{"id":"str540"},"_":"B. Komer, J. Bergstra, and C. Eliasmith, Hyperopt-sklearn: Automatic hyperparameter configuration for scikit-learn, Proc. ICML Workshop AutoML, (2014) 34-40."}]},{"#name":"bib-reference","$":{"id":"b0540"},"$$":[{"#name":"label","_":"[108]"},{"#name":"other-ref","$":{"id":"h0540","refId":"108"},"$$":[{"#name":"textref","_":"M. Pumperla, Hyperas, 2019. http://maxpumperla.com/hyperas/."}]},{"#name":"source-text","$":{"id":"str545"},"_":"M. Pumperla, Hyperas, 2019. http://maxpumperla.com/hyperas/."}]},{"#name":"bib-reference","$":{"id":"b0545"},"$$":[{"#name":"label","_":"[109]"},{"#name":"other-ref","$":{"id":"h0545","refId":"109"},"$$":[{"#name":"textref","_":"M. Lindauer, K. Eggensperger, M. Feurer, S. Falkner, A. Biedenkapp, and F. Hutter, Smac v3: Algorithm configuration in python, 2017. https://github.com/automl/SMAC3."}]},{"#name":"source-text","$":{"id":"str550"},"_":"M. Lindauer, K. Eggensperger, M. Feurer, S. Falkner, A. Biedenkapp, and F. Hutter, Smac v3: Algorithm configuration in python, 2017. https://github.com/automl/SMAC3."}]},{"#name":"bib-reference","$":{"id":"b0550"},"$$":[{"#name":"label","_":"[110]"},{"#name":"other-ref","$":{"id":"h0550","refId":"110"},"$$":[{"#name":"textref","_":"Tim Head, MechCoder, Gilles Louppe, et al., scikitoptimize/scikit-optimize: v0.5.2, 2018. doi: 10.5281/zenodo.1207017."}]},{"#name":"source-text","$":{"id":"str555"},"_":"Tim Head, MechCoder, Gilles Louppe, et al., scikitoptimize/scikit-optimize: v0.5.2, 2018. https://doi.org/10.5281/zenodo.1207017."}]},{"#name":"bib-reference","$":{"id":"b0555"},"$$":[{"#name":"label","_":"[111]"},{"#name":"reference","$":{"id":"h0555","refId":"111"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"N."},{"#name":"surname","_":"Knudde"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"van der Herten"}]},{"#name":"author","$$":[{"#name":"given-name","_":"T."},{"#name":"surname","_":"Dhaene"}]},{"#name":"author","$$":[{"#name":"given-name","_":"I."},{"#name":"surname","_":"Couckuyt"}]}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"GPflowOpt: A Bayesian Optimization Library using TensorFlow, arXiv preprint arXiv:1711.03845"}]}]},{"#name":"date","_":"2017"}]}]}]},{"#name":"source-text","$":{"id":"str560"},"_":"N. Knudde, J. van der Herten, T. Dhaene, and I. Couckuyt, GPflowOpt: A Bayesian Optimization Library using TensorFlow, arXiv preprint arXiv:1711.03845, (2017). https://arxiv.org/abs1711.03845."}]},{"#name":"bib-reference","$":{"id":"b0560"},"$$":[{"#name":"label","_":"[112]"},{"#name":"other-ref","$":{"id":"h0560","refId":"112"},"$$":[{"#name":"textref","_":"Autonomio Talos [Computer software], 2019. http://github.com/autonomio/talos."}]},{"#name":"source-text","$":{"id":"str565"},"_":"Autonomio Talos [Computer software], 2019. http://github.com/autonomio/talos."}]},{"#name":"bib-reference","$":{"id":"b0565"},"$$":[{"#name":"label","_":"[113]"},{"#name":"other-ref","$":{"id":"h0565","refId":"113"},"$$":[{"#name":"textref","_":"L. Hertel, P. Sadowski, J. Collado, P. Baldi, Sherpa: hyperparameter optimization for machine learning models, Conf. Neural Inf. Process. Syst., 2018."}]},{"#name":"source-text","$":{"id":"str570"},"_":"L. Hertel, P. Sadowski, J. Collado, P. Baldi, Sherpa: Hyperparameter Optimization for Machine Learning Models, Conf. Neural Inf. Process. Syst. (2018)."}]},{"#name":"bib-reference","$":{"id":"b0570"},"$$":[{"#name":"label","_":"[114]"},{"#name":"other-ref","$":{"id":"h0570","refId":"114"},"$$":[{"#name":"textref","_":"M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, et al., TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems, arXiv preprint arXiv:1603.04467, (2016). https://arxiv.org/abs1603.04467."}]},{"#name":"source-text","$":{"id":"str575"},"_":"M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, et al., TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems, arXiv preprint arXiv:1603.04467, (2016). https://arxiv.org/abs1603.04467."}]},{"#name":"bib-reference","$":{"id":"b0575"},"$$":[{"#name":"label","_":"[115]"},{"#name":"other-ref","$":{"id":"h0575","refId":"115"},"$$":[{"#name":"textref","_":"J. Grandgirard, D. Poinsot, L. Krespi, J.P. NÃ©non, A.M. Cortesero, Osprey: Hyperparameter Optimization for Machine Learning, 103 (2002) 239â€“248. https://doi.org/10.21105/joss.00034."}]},{"#name":"source-text","$":{"id":"str580"},"_":"J. Grandgirard, D. Poinsot, L. Krespi, J.P. NÃ©non, A.M. Cortesero, Osprey: Hyperparameter Optimization for Machine Learning, 103 (2002) 239-248. https://doi.org/10.21105/joss.00034."}]},{"#name":"bib-reference","$":{"id":"b0580"},"$$":[{"#name":"label","_":"[116]"},{"#name":"reference","$":{"id":"h0580","refId":"116"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"L."},{"#name":"surname","_":"Franceschi"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Donini"}]},{"#name":"author","$$":[{"#name":"given-name","_":"P."},{"#name":"surname","_":"Frasconi"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Pontil"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Forward and reverse gradient-based hyperparameter optimization, 34th Int"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Conf. Mach. Learn. ICML 2017"}]}]},{"#name":"issue-nr","_":"70"},{"#name":"date","_":"2017"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1165"},{"#name":"last-page","_":"1173"}]}]}]},{"#name":"source-text","$":{"id":"str585"},"_":"L. Franceschi, M. Donini, P. Frasconi, and M. Pontil, Forward and reverse gradient-based hyperparameter optimization, 34th Int. Conf. Mach. Learn. ICML 2017, 70 (2017) 1165-1173."}]},{"#name":"bib-reference","$":{"id":"b0585"},"$$":[{"#name":"label","_":"[117]"},{"#name":"reference","$":{"id":"h0585","refId":"117"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"F.A."},{"#name":"surname","_":"Fortin"}]},{"#name":"author","$$":[{"#name":"given-name","_":"F.M."},{"#name":"surname","_":"De Rainville"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M.A."},{"#name":"surname","_":"Gardner"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Parizeau"}]},{"#name":"author","$$":[{"#name":"given-name","_":"C."},{"#name":"surname","_":"GagÅ„e"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"DEAP: evolutionary algorithms made easy"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Mach. Learn. Res."}]},{"#name":"volume-nr","_":"13"}]},{"#name":"date","_":"2012"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"2171"},{"#name":"last-page","_":"2175"}]}]}]},{"#name":"source-text","$":{"id":"str590"},"_":"F.A. Fortin, F.M. De Rainville, M.A. Gardner, M. Parizeau, C. GagÅ„e, DEAP: Evolutionary algorithms made easy, J. Mach. Learn. Res. 13 (2012) 2171-2175."}]},{"#name":"bib-reference","$":{"id":"b0590"},"$$":[{"#name":"label","_":"[118]"},{"#name":"other-ref","$":{"id":"h0590","refId":"118"},"$$":[{"#name":"textref","_":"R.S. Olson, J.H. Moore, TPOT: a tree-based pipeline optimization tool for automating machine learning, Auto Mach. Learn. (2019) 151â€“160. https://doi.org/10.1007/978-3-030-05318-5_8"}]},{"#name":"source-text","$":{"id":"str595"},"_":"R. S. Olson and J. H. Moore, TPOT: A tree-based pipeline optimization tool for automating machine learning, Auto Mach. Learn. (2019) 151-160. https://doi.org/10.1007/978-3-030-05318-5_8"}]},{"#name":"bib-reference","$":{"id":"b0595"},"$$":[{"#name":"label","_":"[119]"},{"#name":"other-ref","$":{"id":"h0595","refId":"119"},"$$":[{"#name":"textref","_":"J. Rapin, O. Teytaud, Nevergrad â€“ a gradient-free optimization platform, 2018. https://GitHub.com/FacebookResearch/Nevergrad."}]},{"#name":"source-text","$":{"id":"str600"},"_":"J. Rapin and O. Teytaud, Nevergrad - A gradient-free optimization platform, 2018. https://GitHub.com/FacebookResearch/Nevergrad."}]},{"#name":"bib-reference","$":{"id":"b0600"},"$$":[{"#name":"label","_":"[120]"},{"#name":"reference","$":{"id":"h0600","refId":"120"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Injadat"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Moubayed"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A.B."},{"#name":"surname","_":"Nassif"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Shami"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Systematic ensemble model selection approach for educational data mining"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Knowl.-Based Syst."}]},{"#name":"volume-nr","_":"200"}]},{"#name":"date","_":"2020"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"105992"}]},{"#name":"doi","_":"10.1016/j.knosys.2020.105992"}]}]},{"#name":"source-text","$":{"id":"str605"},"_":"M. Injadat, A. Moubayed, A.B. Nassif et al, Systematic ensemble model selection approach for educational data mining, Knowledge-Based Syst. (2020). https://doi.org/10.1016/j.knosys.2020.105992."}]},{"#name":"bib-reference","$":{"id":"b0605"},"$$":[{"#name":"label","_":"[121]"},{"#name":"reference","$":{"id":"h0605","refId":"121"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"C.M."},{"#name":"surname","_":"Bishop"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Neural Networks for Pattern Recognition"}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"date","_":"1995"},{"#name":"publisher","$$":[{"#name":"name","_":"Oxford University Press"}]}]}]}]},{"#name":"source-text","$":{"id":"str610"},"_":"C.M. Bishop, Neural Networks for Pattern Recognition, Oxford University Press (1995)."}]},{"#name":"bib-reference","$":{"id":"b0610"},"$$":[{"#name":"label","_":"[122]"},{"#name":"reference","$":{"id":"h0610","refId":"122"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Krizhevsky"}]},{"#name":"author","$$":[{"#name":"given-name","_":"I."},{"#name":"surname","_":"Sutskever"}]},{"#name":"author","$$":[{"#name":"given-name","_":"G.E."},{"#name":"surname","_":"Hinton"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Imagenet classification with deep convolutional neural networks"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Adv. Neural Inf. Process. Syst."}]},{"#name":"volume-nr","_":"25"}]},{"#name":"date","_":"2012"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1097"},{"#name":"last-page","_":"1105"}]}]}]},{"#name":"source-text","$":{"id":"str615"},"_":"A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks, Adv. Neural Inf. Process. Syst. 25 (2012) 1097-1105"}]},{"#name":"bib-reference","$":{"id":"b0615"},"$$":[{"#name":"label","_":"[123]"},{"#name":"other-ref","$":{"id":"h0615","refId":"123"},"$$":[{"#name":"textref","_":"N. Hansen, A. Auger, O. Mersmann, T. Tusar, D. Brockhoff, COCO: A Platform for Comparing Continuous Optimizers in a Black-Box Setting, arXiv preprint arXiv:1603.08785, (2016). https://arxiv.org/abs1603.08785."}]},{"#name":"source-text","$":{"id":"str620"},"_":"N. Hansen, A. Auger, O. Mersmann, T. Tusar, and D. Brockhoff, COCO: A Platform for Comparing Continuous Optimizers in a Black-Box Setting, arXiv preprint arXiv:1603.08785, (2016). https://arxiv.org/abs1603.08785."}]},{"#name":"bib-reference","$":{"id":"b0620"},"$$":[{"#name":"label","_":"[124]"},{"#name":"reference","$":{"id":"h0620","refId":"124"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"G.C."},{"#name":"surname","_":"Cawley"}]},{"#name":"author","$$":[{"#name":"given-name","_":"N.L.C."},{"#name":"surname","_":"Talbot"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"On over-fitting in model selection and subsequent selection bias in performance evaluation"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Mach. Learn. Res."}]},{"#name":"volume-nr","_":"11"}]},{"#name":"date","_":"2010"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"2079"},{"#name":"last-page","_":"2107"}]}]}]},{"#name":"source-text","$":{"id":"str625"},"_":"G.C. Cawley, N.L.C. Talbot, On over-fitting in model selection and subsequent selection bias in performance evaluation, J. Mach. Learn. Res. 11 (2010) 2079-2107."}]},{"#name":"bib-reference","$":{"id":"b0625"},"$$":[{"#name":"label","_":"[125]"},{"#name":"reference","$":{"id":"h0625","refId":"125"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Boehm"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Surve"}]},{"#name":"author","$$":[{"#name":"given-name","_":"S."},{"#name":"surname","_":"Tatikonda"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"SystemML: declarative machine learning on spark"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Proc. VLDB Endow."}]},{"#name":"volume-nr","_":"9"}]},{"#name":"date","_":"2016"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1425"},{"#name":"last-page","_":"1436"}]}]},{"#name":"comment","_":"https://doi.org/10.14778/3007263.3007279"}]},{"#name":"source-text","$":{"id":"str630"},"_":"M. Boehm, A. Surve, S. Tatikonda, et al., SystemML: declarative machine learning on spark, Proc. VLDB Endow. 9 (2016) 1425-1436. https://doi.org/10.14778/3007263.3007279."}]},{"#name":"bib-reference","$":{"id":"b0630"},"$$":[{"#name":"label","_":"[126]"},{"#name":"reference","$":{"id":"h0630","refId":"126"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"X."},{"#name":"surname","_":"Meng"}]},{"#name":"author","$$":[{"#name":"given-name","_":"J."},{"#name":"surname","_":"Bradley"}]},{"#name":"author","$$":[{"#name":"given-name","_":"B."},{"#name":"surname","_":"Yavuz"}]},{"#name":"et-al"}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Mllib: machine learning in apache spark"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"J. Mach. Learn. Res."}]},{"#name":"volume-nr","_":"17"}]},{"#name":"issue-nr","_":"1"},{"#name":"date","_":"2016"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"1235"},{"#name":"last-page","_":"1241"}]}]}]},{"#name":"source-text","$":{"id":"str635"},"_":"X. Meng, J. Bradley, B. Yavuz, et al., Mllib: machine learning in apache spark, J. Mach. Learn. Res. 17 (1) (2016) 1235-1241."}]},{"#name":"bib-reference","$":{"id":"bib631"},"$$":[{"#name":"label","_":"[127]"},{"#name":"reference","$":{"id":"opt8fCRtPmdMW","refId":"127"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Moubayed"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Injadat"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Shami"}]},{"#name":"author","$$":[{"#name":"given-name","_":"H."},{"#name":"surname","_":"Lutfiyya"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"DNS typo-squatting domain detection: a data analytics & machine learning based approach"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"2018 IEEE Glob. Commun. Conf. GLOBECOM."}]}]},{"#name":"date","_":"2018"}]},{"#name":"doi","_":"10.1109/GLOCOM.2018.8647679"}]}]},{"#name":"source-text","$":{"id":"srctbib631"},"_":"Moubayed A., Injadat M., Shami A., Lutfiyya H., DNS Typo-Squatting Domain Detection: A Data Analytics & Machine Learning Based Approach, 2018 IEEE Glob. Commun. Conf. GLOBECOM. (2018). https://doi.org/10.1109/GLOCOM.2018.8647679."}]},{"#name":"bib-reference","$":{"id":"bib632"},"$$":[{"#name":"label","_":"[128]"},{"#name":"reference","$":{"id":"optrFgqrzs9wq","refId":"128"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"Li"},{"#name":"surname","_":"Yang"}]}]}]},{"#name":"host","$$":[{"#name":"book","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Comprehensive visibility indicator algorithm for adaptable speed limit control in intelligent transportation systems"}]},{"#name":"date","_":"2018"},{"#name":"publisher","$$":[{"#name":"name","_":"University of Guelph"}]}]}]}]},{"#name":"source-text","$":{"id":"srctbib632"},"_":"Yang Li, Comprehensive Visibility Indicator Algorithm for Adaptable Speed Limit Control in Intelligent Transportation Systems, University of Guelph, 2018."}]},{"#name":"bib-reference","$":{"id":"bib633"},"$$":[{"#name":"label","_":"[129]"},{"#name":"reference","$":{"id":"optHL8pB78iqc","refId":"129"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"F."},{"#name":"surname","_":"Salo"}]},{"#name":"author","$$":[{"#name":"given-name","_":"M.N."},{"#name":"surname","_":"Injadat"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Moubayed"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A.B."},{"#name":"surname","_":"Nassif"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Essex"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Clustering enabled classification using ensemble feature selection for intrusion detection"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"2019 Int. Conf. Comput. Netw. Commun. ICNC"}]}]},{"#name":"date","_":"2019"}]},{"#name":"pages","$$":[{"#name":"first-page","_":"276"},{"#name":"last-page","_":"281"}]},{"#name":"doi","_":"10.1109/ICCNC.2019.8685636"}]}]},{"#name":"source-text","$":{"id":"srctbib633"},"_":"Salo F., Injadat M.N., Moubayed A., Nassif A.B., Essex A., Clustering Enabled Classification using Ensemble Feature Selection for Intrusion Detection, 2019 Int. Conf. Comput. Netw. Commun. ICNC (2019) 276â€“281. https://doi.org/10.1109/ICCNC.2019.8685636."}]},{"#name":"bib-reference","$":{"id":"bib634"},"$$":[{"#name":"label","_":"[130]"},{"#name":"reference","$":{"id":"optEXKNCNjiGy","refId":"130"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Moubayed"}]},{"#name":"author","$$":[{"#name":"given-name","_":"E."},{"#name":"surname","_":"Aqeeli"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Shami"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Ensemble-based feature selection and classification model for DNS typo-squatting detection"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"2020 IEEE Can. Conf. Electr. Comput. Eng."}]}]},{"#name":"date","_":"2020"}]}]}]},{"#name":"source-text","$":{"id":"srctbib634"},"_":"Moubayed A., Aqeeli E., Shami A., Ensemble-based Feature Selection and Classification Model for DNS Typo-squatting Detection, 2020 IEEE Can. Conf. Electr. Comput. Eng. (2020)."}]},{"#name":"bib-reference","$":{"id":"bib637"},"$$":[{"#name":"label","_":"[131]"},{"#name":"reference","$":{"id":"optOiNcxoas5h","refId":"131"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"M."},{"#name":"surname","_":"Injadat"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Moubayed"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A.B."},{"#name":"surname","_":"Nassif"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Shami"}]}]},{"#name":"title","$$":[{"#name":"maintitle","_":"Multi-split optimized bagging ensemble model selection for multi-class educational data mining"}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Springerâ€™s Appl. Intell."}]}]},{"#name":"date","_":"2020"}]}]}]},{"#name":"source-text","$":{"id":"srctbib637"},"_":"Injadat M., Moubayed A., Nassif A.B., Shami A., Multi-split Optimized Bagging Ensemble Model Selection for Multi-class Educational Data Mining, Springerâ€™s Appl. Intell. (2020)."}]},{"#name":"bib-reference","$":{"id":"bib638"},"$$":[{"#name":"label","_":"[132]"},{"#name":"reference","$":{"id":"optC0OCrOBMox","refId":"132"},"$$":[{"#name":"contribution","$":{"langtype":"en"},"$$":[{"#name":"authors","$$":[{"#name":"author","$$":[{"#name":"given-name","_":"L."},{"#name":"surname","_":"Yang"}]},{"#name":"author","$$":[{"#name":"given-name","_":"A."},{"#name":"surname","_":"Shami"}]}]}]},{"#name":"host","$$":[{"#name":"issue","$$":[{"#name":"series","$$":[{"#name":"title","$$":[{"#name":"maintitle","_":"Hyperparameter Optimization of Machine Learning Algorithms"}]}]},{"#name":"date","_":"2020"}]}]},{"#name":"host","$$":[{"#name":"e-host","$$":[{"#name":"inter-ref","$":{"href":"https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms","type":"simple","id":"ir985"},"_":"https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms"}]}]}]},{"#name":"source-text","$":{"id":"srctbib638"},"_":"Yang L., Shami A., Hyperparameter Optimization of Machine Learning Algorithms (2020). https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms."}]}]}]}],"floats":[],"footnotes":[],"attachments":[],"sourceTextMap":{"1":"M.I. Jordan, T.M. Mitchell, Machine learning: Trends, perspectives, and prospects, Science 349 (2015) 255-260. https://doi.org/10.1126/science.aaa8415.","4":"M. Kuhn and K. Johnson, Applied Predictive Modeling., Springer (2013) ISBN: 9781461468493.","5":"G.I. Diaz, A. Fokoue-Nkoutche, G. Nannicini, H. Samulowitz, An effective algorithm for hyperparameter optimization of neural networks, IBM J. Res. Dev. 61 (2017) 1-20. https://doi.org/10.1147/JRD.2017.2709578.","6":"F. Hutter, L. Kotthoff, and J. Vanschoren, Eds., Automatic Machine Learning: Methods, Systems, Challenges, Springer (2019) ISBN: 9783030053185.","7":"N. Decastro-GarcÃ­a, Ã. L. MuÃ±oz CastaÃ±eda, D. Escudero GarcÃ­a, and M. V. Carriegos, Effect of the Sampling of a Dataset in the Hyperparameter Optimization Phase over the Efficiency of a Machine Learning Algorithm, Complexity 2019 (2019). https://doi.org/10.1155/2019/6278908.","10":"G. Luo, A review of automatic selection methods for machine learning algorithms and hyper-parameter values, Netw. Model. Anal. Heal. Informatics Bioinforma. 5 (2016) 1-16. https://doi.org/10.1007/s13721-016-0125-6.","12":"J. Bergstra, R. Bardenet, Y. Bengio, and B. KÃ©gl, Algorithms for hyper-parameter optimization, Proc. Adv. Neural Inf. Process. Syst., (2011) 2546-2554.","13":"B. James and B. Yoshua, Random Search for Hyper-Parameter Optimization, J. Mach. Learn. Res. 13 (1) (2012) 281-305.","14":"K. Eggensperger, M. Feurer, F. Hutter, J. Bergstra, J. Snoek, H. Hoos, K. Leyton-Brown, Towards an Empirical Foundation for Assessing Bayesian Optimization of Hyperparameters, BayesOpt Work. (2013) 1-5.","15":"K. Eggensperger, F. Hutter, H.H. Hoos, K. Leyton-Brown, Efficient benchmarking of hyperparameter optimizers via surrogates, Proc. Natl. Conf. Artif. Intell. 2 (2015) 1114-1120.","16":"L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, and A. Talwalkar, Hyperband: A novel bandit-based approach to hyperparameter optimization, J. Mach. Learn. Res. 18 (2012) 1-52.","19":"P. R. Lorenzo, J. Nalepa, M. Kawulok, L. S. Ramos, and J. R. Paster, Particle swarm optimization for hyper-parameter selection in deep neural networks, Proc. ACM Int. Conf. Genet. Evol. Comput., (2017) 481-488.","21":"T.M. S. Bradley, A. Hax, Applied Mathematical Programming, Addison-Wesley, Reading, Massachusetts. (1977).","22":"S. Bubeck, Convex optimization: Algorithms and complexity, Found. Trends Mach. Learn. 8 (2015) 231-357. https://doi.org/10.1561/2200000050.","24":"G.I. Diaz, A. Fokoue-Nkoutche, G. Nannicini, H. Samulowitz, An effective algorithm for hyperparameter optimization of neural networks, IBM J. Res. Dev. 61 (2017) 1-20. https://doi.org/10.1147/JRD.2017.2709578.","25":"C. Gambella, B. Ghaddar, and J. Naoum-Sawaya, Optimization Models for Machine Learning: A Survey, arXiv preprint arXiv:1901.05331, (2019). http://arxiv.org/abs/1901.05331.","26":"E. R. Sparks, A. Talwalkar, D. Haas, M. J. Franklin, M. I. Jordan, and T. Kraska, Automating model search for large scale machine learning, Proc. 6th ACM Symp. Cloud Comput., (2015) 368-380.","28":"R. Caruana, A. Niculescu-Mizil, An empirical comparison of supervised learning algorithms, ACM Int. Conf. Proceeding Ser. 148 (2006) 161-168. https://doi.org/10.1145/1143844.1143865.","29":"O. Kramer, Scikit-Learn, in Machine Learning for Evolution Strategies. Cham, Switzerland: Springer International Publishing, (2016) 45-53.","30":"F. Pedregosa et al., Scikit-learn: Machine learning in Python, J. Mach. Learn. Res., 12 (2011) 2825-2830.","33":"C. Gambella, B. Ghaddar, J. Naoum-Sawaya, Optimization Models for Machine Learning: A Survey, (2019) 1-40. http://arxiv.org/abs/1901.05331","35":"A.E. Hoerl, R.W. Kennard, Ridge Regression: Applications to Nonorthogonal Problems, Technometrics. 12 (1970) 69-82. https://doi.org/10.1080/00401706.1970.10488635.","36":"L.E. Melkumova, S.Y. Shatskikh, Comparing Ridge and LASSO estimators for data analysis, Procedia Eng. 201 (2017) 746-755. https://doi.org/10.1016/j.proeng.2017.09.615.","37":"R. Tibshirani, Regression Shrinkage and Selection Via the Lasso, J. R. Stat. Soc. Ser. B. 58 (1996) 267-288. https://doi.org/10.1111/j.2517-6161.1996.tb02080.x.","38":"D.W. Hosmer Jr, S. Lemeshow, Applied logistic regression, Technometrics, 34 (1) (2013), 358-359.","39":"J.O. Ogutu, T. Schulz-Streeck, H.P. Piepho, Genomic selection using regularized linear regression models: ridge regression, lasso, elastic net and their extensions, BMC Proceedings. BioMed Cent. 6 (2012).","40":"J.M. Keller, M.R. Gray, A Fuzzy K-Nearest Neighbor Algorithm, IEEE Trans. Syst. Man Cybern. SMC-15 (1985) 580-585. https://doi.org/10.1109/TSMC.1985.6313426.","41":"W. Zuo, D. Zhang, K. Wang, On kernel difference-weighted k-nearest neighbor classification, Pattern Anal. Appl. 11 (2008) 247-257. https://doi.org/10.1007/s10044-007-0100-z.","42":"A. Smola, V. Vapnik, Support vector regression machines, Adv. Neural Inf. Process. Syst. 9 (1997) 155-161.","43":"L. Yang, R. Muresan, A. Al-Dweik, L.J. Hadjileontiadis, Image-Based Visibility Estimation Algorithm for Intelligent Transportation Systems, IEEE Access. 6 (2018) 76728-76740. https://doi.org/10.1109/ACCESS.2018.2884225.","44":"J. Zhang, R. Jin, Y. Yang, A.G. Hauptmann, Modified Logistic Regression: An Approximation to SVM and Its Applications in Large-Scale Text Categorization, Proceedings, Twent. Int. Conf. Mach. Learn. 2 (2003) 888-895.","46":"I. Rish, An empirical study of the naive Bayes classifier, IJCAI 2001 Work. Empir. methods Artif. Intell., (2001), 41-46.","48":"C. Bustamante, L. Garrido, R. Soto, Comparing fuzzy Naive Bayes and Gaussian Naive Bayes for decision making in RoboCup 3D, Lect. Notes Comput. Sci. (Including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics). 4293 LNAI (2006) 237-247. https://doi.org/10.1007/11925231_23.","49":"A.M. Kibriya, E. Frank, B. Pfahringer, G. Holmes, Multinomial naive bayes for text categorization revisited, Lect. Notes Artif. Intell. (Subseries Lect. Notes Comput. Sci. 3339 (2004) 488-499.","52":"S. Rasoul, L. David, A Survey of Decision Tree Classifier Methodology, IEEE Trans. Syst. Man. Cybern. 21 (1991) 660-674.","53":"D.M. Manias, M. Jammal, H. Hawilo, A. Shami, P. Heidari, A. Larabi, R. Brunner, Machine learning for performance-aware virtual network function placement, 2019 IEEE Glob. Commun. Conf. GLOBECOM 2019 - Proc. (2019) 12-17. https://doi.org/10.1109/GLOBECOM38437.2019.9013246.","54":"L. Yang, A. Moubayed, I. Hamieh, A. Shami, Tree-based intelligent intrusion detection system in internet of vehicles, 2019 IEEE Glob. Commun. Conf. GLOBECOM 2019 - Proc. (2019). https://doi.org/10.1109/GLOBECOM38437.2019.9013892.","58":"Y. Xia, C. Liu, Y.Y. Li, N. Liu, A boosted decision tree approach using Bayesian hyper-parameter optimization for credit scoring, Expert Syst. Appl. 78 (2017) 225-241. https://doi.org/10.1016/j.eswa.2017.02.017.","59":"T. G. Dietterich, Ensemble methods in machine learning, Mult. Classif. Syst., 1857 (2000), 1-15.","61":"A. Koutsoukas, K.J. Monaghan, X. Li, J. Huan, Deep-learning: Investigating deep neural networks hyper-parameters and comparison of performance to shallow methods for modeling bioactivity data, J. Cheminform. 9 (2017) 1-13. https://doi.org/10.1186/s13321-017-0226-y.","62":"T. Domhan, J.T. Springenberg, F. Hutter, Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves, IJCAI Int. Jt. Conf. Artif. Intell. 2015-January (2015) 3460-3468.","63":"Y. Ozaki, M. Yano, M. Onishi, Effective hyperparameter optimization using Nelder-Mead method in deep learning, IPSJ Trans. Comput. Vis. Appl. 9 (2017). https://doi.org/10.1186/s41074-017-0030-7.","64":"F.C. Soon, H.Y. Khaw, J.H. Chuah, J. Kanesan, Hyper-parameters optimisation of deep CNN architecture for vehicle logo recognition, IET Intell. Transp. Syst. 12 (2018) 939-946. https://doi.org/10.1049/iet-its.2018.5127.","65":"D. Han, Q. Liu, W. Fan, A new image classification method using CNN transfer learning and web data augmentation, Expert Syst. Appl. 95 (2018) 43-56. https://doi.org/10.1016/j.eswa.2017.11.028.","66":"C. Di Francescomarino, M. Dumas, M. Federici, C. Ghidini, F.M. Maggi, W. Rizzi, L. Simonetto, Genetic algorithms for hyperparameter optimization in predictive business process monitoring, Inf. Syst. 74 (2018) 67-83. https://doi.org/10.1016/j.is.2018.01.003.","67":"A. Moubayed, M. Injadat, A. Shami, H. Lutfiyya, Student Engagement Level in e-Learning Environment: Clustering Using K-means, Am. J. Distance Educ. 34 (2020) 1-20. https://doi.org/10.1080/08923647.2020.1696140.","68":"C. Ding, X. He, Cluster structure of K-means clustering via principal component analysis, Lect. Notes Comput. Sci. (Including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics). 3056 (2004) 414-418. https://doi.org/10.1145/1015330.1015408.","69":"T. K. Moon, The expectation-maximization algorithm, IEEE Signal Process. Mag. 13 (6) (1996) 47-60.","70":"S. Brahim-Belhouari, A. Bermak, M. Shi, P.C.H. Chan, Fast and Robust gas identification system using an integrated gas sensor technology and Gaussian mixture models, IEEE Sens. J. 5 (2005) 1433-1444. https://doi.org/10.1109/JSEN.2005.858926.","73":"H. Zhou, P. Wang, H. Li, Research on adaptive parameters determination in DBSCAN algorithm, J. Inf. Comput. Sci. 9 (2012) 1967-1973.","75":"N. Halko, P. Martinsson, J. Tropp, Finding structure with randomness: probabilistic algorithms for constructing approximate matrix decompositions, SIAM Rev. 53 (2) (2011), pp. 217-288","76":"M. Loog, Conditional linear discriminant analysis, Proc. - Int. Conf. Pattern Recognit. 2 (2006) 387-390. https://doi.org/10.1109/ICPR.2006.402.","77":"P. Howland, J. Wang, H. Park, Solving the small sample size problem in face recognition using generalized discriminant analysis, Pattern Recognit. 39 (2006) 277-287. https://doi.org/10.1016/j.patcog.2005.06.013.","79":"M. Claesen, J. Simm, D. Popovic, Y. Moreau, and B. De Moor, Easy Hyperparameter Search Using Optunity, arXiv preprint arXiv:1412.1114, (2014). https://arxiv.org/abs1412.1114.","81":"Y. Bengio, Gradient-based optimization of hyperparameters, Neural Comput. 12 (8) (2000) 1889-1900.","82":"H. H. Yang and S. I. Amari, Complexity Issues in Natural Gradient Descent Method for Training Multilayer Perceptrons, Neural Comput. 10 (8) (1998) 2137-2157.","84":"E. Hazan, A. Klivans, and Y. Yuan, Hyperparameter optimization: a spectral approach, arXiv preprint arXiv:1706.00764, (2017). https://arxiv.org/abs1706.00764.","85":"M. Seeger, Gaussian processes for machine learning, Int. J. Neural Syst., 14 (2004), 69-106.","86":"F. Hutter, H. H. Hoos, and K. Leyton-Brown, Sequential model-based optimization for general algorithm configuration, Proc. LION 5, (2011) 507-523.","88":"J. Hensman, N. Fusi, and N. D. Lawrence, Gaussian processes for big data, arXiv preprint arXiv:1309.6835, (2013). https://arxiv.org/abs/1309.6835.","89":"M. Claesen and B. De Moor, Hyperparameter Search in Machine Learning, arXiv preprint arXiv:1502.02127, (2015). https://arxiv.org/abs1502.02127.","91":"S. Zhang, J. Xu, E. Huang, C.H. Chen, A new optimal sampling rule for multi-fidelity optimization via ordinal transformation, IEEE Int. Conf. Autom. Sci. Eng. 2016-Novem (2016) 670-674. https://doi.org/10.1109/COASE.2016.7743467.","92":"Z. Karnin, T. Koren, O. Somekh, Almost optimal exploration in multi-armed bandits, 30th Int. Conf. Mach. Learn. ICML 2013. 28 (2013) 2275-2283.","93":"S. Falkner, A. Klein, F. Hutter, BOHB: Robust and Efficient Hyperparameter Optimization at Scale, 35th Int. Conf. Mach. Learn. ICML 2018. 4 (2018) 2323-2341.","94":"A. Gogna, A. Tayal, Metaheuristics: Review and application, J. Exp. Theor. Artif. Intell. 25 (2013) 503-526. https://doi.org/10.1080/0952813X.2013.782347.","95":"F. Itano, M.A. De Abreu De Sousa, E. Del-Moral-Hernandez, Extending MLP ANN hyper-parameters Optimization by using Genetic Algorithm, Proc. Int. Jt. Conf. Neural Networks. 2018-July (2018) 1-8. https://doi.org/10.1109/IJCNN.2018.8489520.","97":"S. Rahnamayan, H.R. Tizhoosh, M.M.A. Salama, A novel population initialization method for accelerating evolutionary algorithms, Comput. Math. with Appl. 53 (2007) 1605-1614. https://doi.org/10.1016/j.camwa.2006.07.013.","98":"F. G. Lobo, D. E. Goldberg, and M. Pelikan, Time complexity of genetic algorithms on exponentially scaled problems, Proc. Genet. Evol. Comput. Conf., (2000) 151-158.","100":"X. Yan, F. He, Y. Chen, A Novel Hardware/ Software Partitioning Method Based on Position Disturbed Particle Swarm Optimization with Invasive Weed Optimization, 32 (2017) 340-355. https://doi.org/10.1007/s11390-017-1714-2.","101":"M.Y. Cheng, K.Y. Huang, M. Hutomo, Multiobjective Dynamic-Guiding PSO for Optimizing Work Shift Schedules, J. Constr. Eng. Manag. 144 (2018) 1-7. https://doi.org/10.1061/(ASCE)CO.1943-7862.0001548.","102":"H. Wang, Z. Wu, J. Wang, X. Dong, S. Yu, G. Chen, A new population initialization method based on space transformation search, 5th Int. Conf. Nat. Comput. ICNC 2009. 5 (2009) 332-336. https://doi.org/10.1109/ICNC.2009.371.","104":"P. Cazzaniga, M.S. Nobile, D. Besozzi, The impact of particles initialization in PSO: Parameter estimation as a case in point, 2015 IEEE Conf. Comput. Intell. Bioinforma. Comput. Biol. CIBCB 2015. (2015) 1-8. https://doi.org/10.1109/CIBCB.2015.7300288.","105":"R. Martinez-Cantin, BayesOpt: A Bayesian optimization library for nonlinear optimization, experimental design and bandits, J. Mach. Learn. Res. 15 (2015) 3735-3739.","106":"J. Bergstra, B. Komer, C. Eliasmith, D. Yamins, D.D. Cox, Hyperopt: A Python library for model selection and hyperparameter optimization, Comput. Sci. Discov. 8 (2015). https://doi.org/10.1088/1749-4699/8/1/014008.","107":"B. Komer, J. Bergstra, and C. Eliasmith, Hyperopt-sklearn: Automatic hyperparameter configuration for scikit-learn, Proc. ICML Workshop AutoML, (2014) 34-40.","111":"N. Knudde, J. van der Herten, T. Dhaene, and I. Couckuyt, GPflowOpt: A Bayesian Optimization Library using TensorFlow, arXiv preprint arXiv:1711.03845, (2017). https://arxiv.org/abs1711.03845.","116":"L. Franceschi, M. Donini, P. Frasconi, and M. Pontil, Forward and reverse gradient-based hyperparameter optimization, 34th Int. Conf. Mach. Learn. ICML 2017, 70 (2017) 1165-1173.","117":"F.A. Fortin, F.M. De Rainville, M.A. Gardner, M. Parizeau, C. GagÅ„e, DEAP: Evolutionary algorithms made easy, J. Mach. Learn. Res. 13 (2012) 2171-2175.","120":"M. Injadat, A. Moubayed, A.B. Nassif et al, Systematic ensemble model selection approach for educational data mining, Knowledge-Based Syst. (2020). https://doi.org/10.1016/j.knosys.2020.105992.","121":"C.M. Bishop, Neural Networks for Pattern Recognition, Oxford University Press (1995).","122":"A. Krizhevsky, I. Sutskever, G.E. Hinton, Imagenet classification with deep convolutional neural networks, Adv. Neural Inf. Process. Syst. 25 (2012) 1097-1105","124":"G.C. Cawley, N.L.C. Talbot, On over-fitting in model selection and subsequent selection bias in performance evaluation, J. Mach. Learn. Res. 11 (2010) 2079-2107.","125":"M. Boehm, A. Surve, S. Tatikonda, et al., SystemML: declarative machine learning on spark, Proc. VLDB Endow. 9 (2016) 1425-1436. https://doi.org/10.14778/3007263.3007279.","126":"X. Meng, J. Bradley, B. Yavuz, et al., Mllib: machine learning in apache spark, J. Mach. Learn. Res. 17 (1) (2016) 1235-1241.","127":"Moubayed A., Injadat M., Shami A., Lutfiyya H., DNS Typo-Squatting Domain Detection: A Data Analytics & Machine Learning Based Approach, 2018 IEEE Glob. Commun. Conf. GLOBECOM. (2018). https://doi.org/10.1109/GLOCOM.2018.8647679.","128":"Yang Li, Comprehensive Visibility Indicator Algorithm for Adaptable Speed Limit Control in Intelligent Transportation Systems, University of Guelph, 2018.","129":"Salo F., Injadat M.N., Moubayed A., Nassif A.B., Essex A., Clustering Enabled Classification using Ensemble Feature Selection for Intrusion Detection, 2019 Int. Conf. Comput. Netw. Commun. ICNC (2019) 276â€“281. https://doi.org/10.1109/ICCNC.2019.8685636.","130":"Moubayed A., Aqeeli E., Shami A., Ensemble-based Feature Selection and Classification Model for DNS Typo-squatting Detection, 2020 IEEE Can. Conf. Electr. Comput. Eng. (2020).","131":"Injadat M., Moubayed A., Nassif A.B., Shami A., Multi-split Optimized Bagging Ensemble Model Selection for Multi-class Educational Data Mining, Springerâ€™s Appl. Intell. (2020).","132":"Yang L., Shami A., Hyperparameter Optimization of Machine Learning Algorithms (2020). https://github.com/LiYangHart/Hyperparameter-Optimization-of-Machine-Learning-Algorithms."}},"referenceLinks":{"external":[{"refId":1,"scopusHubEid":"2-s2.0-84937801713","crossRefDoi":"10.1126/science.aaa8415"},{"refId":5,"scopusHubEid":"2-s2.0-85121207562"},{"refId":13,"scopusHubEid":"2-s2.0-84865202835","crossRefDoi":"10.1080/00222895.2012.702141"},{"refId":14,"scopusHubEid":"2-s2.0-84919931099"},{"refId":15,"scopusHubEid":"2-s2.0-84959905463"},{"refId":16,"scopusHubEid":"2-s2.0-84862335061"},{"refId":19,"scopusHubEid":"2-s2.0-85025461807","crossRefDoi":"10.1145/3071178.3071208"},{"refId":22,"scopusHubEid":"2-s2.0-84983143287","crossRefDoi":"10.1561/2200000050"},{"refId":24,"scopusHubEid":"2-s2.0-85121207562"},{"refId":26,"scopusHubEid":"2-s2.0-84958951297","crossRefDoi":"10.1145/2806777.2806945"},{"refId":28,"crossRefDoi":"10.1145/1143844.1143865"},{"refId":29,"scopusHubEid":"2-s2.0-85132937805","crossRefDoi":"10.1007/978-3-319-33383-0_5"},{"refId":35,"scopusHubEid":"2-s2.0-84942487147"},{"refId":36,"scopusHubEid":"2-s2.0-85033495907"},{"refId":37,"crossRefDoi":"10.1111/j.2517-6161.1996.tb02080.x"},{"refId":40,"scopusHubEid":"2-s2.0-0022219988"},{"refId":41,"scopusHubEid":"2-s2.0-50549085732","crossRefDoi":"10.1007/s10044-007-0100-z"},{"refId":43,"scopusHubEid":"2-s2.0-85057808511","crossRefDoi":"10.1109/access.2018.2884225"},{"refId":44,"scopusHubEid":"2-s2.0-1942420344"},{"refId":48,"scopusHubEid":"2-s2.0-33845943515","crossRefDoi":"10.1007/11925231_23"},{"refId":49,"scopusHubEid":"2-s2.0-22944460214","crossRefDoi":"10.1007/978-3-540-30549-1_43"},{"refId":58,"scopusHubEid":"2-s2.0-85013170820"},{"refId":62,"scopusHubEid":"2-s2.0-84949921865"},{"refId":64,"scopusHubEid":"2-s2.0-85053214510","crossRefDoi":"10.1049/iet-its.2018.5127"},{"refId":65,"scopusHubEid":"2-s2.0-85034658508"},{"refId":66,"scopusHubEid":"2-s2.0-85042235310"},{"refId":68,"scopusHubEid":"2-s2.0-7444219584","crossRefDoi":"10.1007/978-3-540-24775-3_50"},{"refId":69,"scopusHubEid":"2-s2.0-0030287048"},{"refId":70,"scopusHubEid":"2-s2.0-29044450430"},{"refId":73,"scopusHubEid":"2-s2.0-84864291221"},{"refId":75,"scopusHubEid":"2-s2.0-79960425522","crossRefDoi":"10.1137/090771806"},{"refId":76,"scopusHubEid":"2-s2.0-34047218620"},{"refId":77,"scopusHubEid":"2-s2.0-27744565938"},{"refId":81,"scopusHubEid":"2-s2.0-0034241361"},{"refId":82,"scopusHubEid":"2-s2.0-0032533046"},{"refId":85,"scopusHubEid":"2-s2.0-12444291490"},{"refId":86,"scopusHubEid":"2-s2.0-84868554032","crossRefDoi":"10.1007/978-3-642-25566-3_40"},{"refId":91,"crossRefDoi":"10.1109/COASE.2016.7743467"},{"refId":92,"scopusHubEid":"2-s2.0-84897478950"},{"refId":93,"scopusHubEid":"2-s2.0-85057312636"},{"refId":94,"scopusHubEid":"2-s2.0-84887827270"},{"refId":95,"crossRefDoi":"10.1109/ijcnn.2018.8489520"},{"refId":97,"scopusHubEid":"2-s2.0-34249011503"},{"refId":98,"scopusHubEid":"2-s2.0-2542626986"},{"refId":100,"scopusHubEid":"2-s2.0-85014912165","crossRefDoi":"10.1007/s11390-017-1714-2"}],"internal":[{"refId":36,"pii":"S1877705817341474","filesize":"576KB","pdf":{"urlType":"download","url":"/science/article/pii/S1877705817341474/pdf?md5=0a32d984e37e62da052a94b9a01a8314&pid=1-s2.0-S1877705817341474-main.pdf"}},{"refId":58,"pii":"S0957417417301008","filesize":"2MB","pdf":{"urlType":"download","url":"/science/article/pii/S0957417417301008/pdfft?md5=28eba5ee51a3be0c523f276fe3b9e619&pid=1-s2.0-S0957417417301008-main.pdf"}},{"refId":65,"pii":"S0957417417307844","filesize":"3MB","pdf":{"urlType":"download","url":"/science/article/pii/S0957417417307844/pdfft?md5=685e1ee5e5483c89d113986372aec44f&pid=1-s2.0-S0957417417307844-main.pdf"}},{"refId":66,"pii":"S0306437916305695","filesize":"2MB","pdf":{"urlType":"download","url":"/science/article/pii/S0306437916305695/pdfft?md5=55402cc9b5eb95b52d622402ed7d9941&pid=1-s2.0-S0306437916305695-main.pdf"}},{"refId":77,"pii":"S0031320305002670","filesize":"453KB","pdf":{"urlType":"download","url":"/science/article/pii/S0031320305002670/pdfft?md5=8940efcd7eaedd1ab35c65834542f11b&pid=1-s2.0-S0031320305002670-main.pdf"}},{"refId":97,"pii":"S0898122107001344","filesize":"579KB","pdf":{"urlType":"download","url":"/science/article/pii/S0898122107001344/pdfft?md5=f379d3b723250e91c9604274e595e805&pid=1-s2.0-S0898122107001344-main.pdf"}}]},"refersTo":{},"referredToBy":{},"relatedContent":{"isModal":false,"isOpenSpecialIssueArticles":false,"isOpenVirtualSpecialIssueLink":false,"isOpenRecommendations":true,"isOpenSubstances":true,"citingArticles":[false,false,false,false,false,false],"recommendations":[false,false,false,false,false,false]},"seamlessAccess":{},"specialIssueArticles":{},"substances":{},"supplementaryFilesData":[],"tableOfContents":{"outlineTitle":"Outline","outline":[{"#name":"entry","$":{"id":"ab005","type":"abstract","class":"author","depth":"1"},"$$":[{"#name":"title","$":{"id":"st385"},"_":"Abstract"}]},{"#name":"entry","$":{"id":"kg005","type":"keywords","class":"keyword","depth":"1"},"$$":[{"#name":"title","$":{"id":"st390"},"_":"Keywords"}]},{"#name":"entry","$":{"id":"s0005","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"1"},{"#name":"title","$":{"id":"st005"},"_":"Introduction"}]},{"#name":"entry","$":{"id":"s0010","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"2"},{"#name":"title","$":{"id":"st010"},"_":"Mathematical optimization and hyper-parameter optimization problems"},{"#name":"entry","$":{"id":"s0015","depth":"2"},"$$":[{"#name":"label","_":"2.1"},{"#name":"title","$":{"id":"st015"},"_":"Mathematical optimization"}]},{"#name":"entry","$":{"id":"s0020","depth":"2"},"$$":[{"#name":"label","_":"2.2"},{"#name":"title","$":{"id":"st020"},"_":"Hyper-parameter optimization problem statement"}]}]},{"#name":"entry","$":{"id":"s0025","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"3"},{"#name":"title","$":{"id":"st025"},"_":"Hyper-parameters in machine learning models"},{"#name":"entry","$":{"id":"s0030","depth":"2"},"$$":[{"#name":"label","_":"3.1"},{"#name":"title","$":{"id":"st030"},"_":"Supervised learning algorithms"},{"#name":"entry","$":{"id":"s0035","depth":"3"},"$$":[{"#name":"label","_":"3.1.1"},{"#name":"title","$":{"id":"st035"},"_":"Linear models"}]},{"#name":"entry","$":{"id":"s0040","depth":"3"},"$$":[{"#name":"label","_":"3.1.2"},{"#name":"title","$":{"id":"st040"},"_":"KNN"}]},{"#name":"entry","$":{"id":"s0045","depth":"3"},"$$":[{"#name":"label","_":"3.1.3"},{"#name":"title","$":{"id":"st045"},"_":"SVM"}]},{"#name":"entry","$":{"id":"s0050","depth":"3"},"$$":[{"#name":"label","_":"3.1.4"},{"#name":"title","$":{"id":"st050"},"_":"NaÃ­ve Bayes"}]},{"#name":"entry","$":{"id":"s0055","depth":"3"},"$$":[{"#name":"label","_":"3.1.5"},{"#name":"title","$":{"id":"st055"},"_":"Tree-based models"}]},{"#name":"entry","$":{"id":"s0060","depth":"3"},"$$":[{"#name":"label","_":"3.1.6"},{"#name":"title","$":{"id":"st060"},"_":"Ensemble learning algorithms"}]},{"#name":"entry","$":{"id":"s0065","depth":"3"},"$$":[{"#name":"label","_":"3.1.7"},{"#name":"title","$":{"id":"st065"},"_":"Deep learning models"}]}]},{"#name":"entry","$":{"id":"s0070","depth":"2"},"$$":[{"#name":"label","_":"3.2"},{"#name":"title","$":{"id":"st070"},"_":"Unsupervised learning algorithms"},{"#name":"entry","$":{"id":"s0075","depth":"3"},"$$":[{"#name":"label","_":"3.2.1"},{"#name":"title","$":{"id":"st075"},"_":"Clustering algorithms"}]},{"#name":"entry","$":{"id":"s0080","depth":"3"},"$$":[{"#name":"label","_":"3.2.2"},{"#name":"title","$":{"id":"st080"},"_":"Dimensionality reduction algorithms"}]}]}]},{"#name":"entry","$":{"id":"s0085","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"4"},{"#name":"title","$":{"id":"st085"},"_":"Hyper-parameter optimization techniques"},{"#name":"entry","$":{"id":"s0090","depth":"2"},"$$":[{"#name":"label","_":"4.1"},{"#name":"title","$":{"id":"st090"},"_":"Model-free algorithms"},{"#name":"entry","$":{"id":"s0095","depth":"3"},"$$":[{"#name":"label","_":"4.1.1"},{"#name":"title","$":{"id":"st095"},"_":"Babysitting"}]},{"#name":"entry","$":{"id":"s0100","depth":"3"},"$$":[{"#name":"label","_":"4.1.2"},{"#name":"title","$":{"id":"st100"},"_":"Grid search"}]},{"#name":"entry","$":{"id":"s0105","depth":"3"},"$$":[{"#name":"label","_":"4.1.3"},{"#name":"title","$":{"id":"st105"},"_":"Random search"}]}]},{"#name":"entry","$":{"id":"s0110","depth":"2"},"$$":[{"#name":"label","_":"4.2"},{"#name":"title","$":{"id":"st110"},"_":"Gradient-based optimization"}]},{"#name":"entry","$":{"id":"s0115","depth":"2"},"$$":[{"#name":"label","_":"4.3"},{"#name":"title","$":{"id":"st115"},"_":"Bayesian optimization"},{"#name":"entry","$":{"id":"s0120","depth":"3"},"$$":[{"#name":"label","_":"4.3.1"},{"#name":"title","$":{"id":"st120"},"_":"BO-GP"}]},{"#name":"entry","$":{"id":"s0125","depth":"3"},"$$":[{"#name":"label","_":"4.3.2"},{"#name":"title","$":{"id":"st125"},"_":"SMAC"}]},{"#name":"entry","$":{"id":"s0130","depth":"3"},"$$":[{"#name":"label","_":"4.3.3"},{"#name":"title","$":{"id":"st130"},"_":"BO-TPE"}]}]},{"#name":"entry","$":{"id":"s0135","depth":"2"},"$$":[{"#name":"label","_":"4.4"},{"#name":"title","$":{"id":"st135"},"_":"Multi-fidelity optimization algorithms"},{"#name":"entry","$":{"id":"s0140","depth":"3"},"$$":[{"#name":"label","_":"4.4.1"},{"#name":"title","$":{"id":"st140"},"_":"Successive halving"}]},{"#name":"entry","$":{"id":"s0145","depth":"3"},"$$":[{"#name":"label","_":"4.4.2"},{"#name":"title","$":{"id":"st145"},"_":"Hyperband"}]},{"#name":"entry","$":{"id":"s0150","depth":"3"},"$$":[{"#name":"label","_":"4.4.3"},{"#name":"title","$":{"id":"st150"},"_":"BOHB"}]}]},{"#name":"entry","$":{"id":"s0155","depth":"2"},"$$":[{"#name":"label","_":"4.5"},{"#name":"title","$":{"id":"st155"},"_":"Metaheuristic algorithms"},{"#name":"entry","$":{"id":"s0160","depth":"3"},"$$":[{"#name":"label","_":"4.5.1"},{"#name":"title","$":{"id":"st160"},"_":"Genetic algorithm"}]},{"#name":"entry","$":{"id":"s0165","depth":"3"},"$$":[{"#name":"label","_":"4.5.2"},{"#name":"title","$":{"id":"st165"},"_":"Particle swarm optimization"}]}]}]},{"#name":"entry","$":{"id":"s0170","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"5"},{"#name":"title","$":{"id":"st170"},"_":"Applying optimization techniques to machine learning algorithms"},{"#name":"entry","$":{"id":"s0175","depth":"2"},"$$":[{"#name":"label","_":"5.1"},{"#name":"title","$":{"id":"st175"},"_":"Optimization techniques analysis"}]},{"#name":"entry","$":{"id":"s0180","depth":"2"},"$$":[{"#name":"label","_":"5.2"},{"#name":"title","$":{"id":"st180"},"_":"Apply HPO algorithms to ML models"},{"#name":"entry","$":{"id":"s0185","depth":"3"},"$$":[{"#name":"label","_":"5.2.1"},{"#name":"title","$":{"id":"st185"},"_":"One discrete hyper-parameter"}]},{"#name":"entry","$":{"id":"s0190","depth":"3"},"$$":[{"#name":"label","_":"5.2.2"},{"#name":"title","$":{"id":"st190"},"_":"One continuous hyper-parameter"}]},{"#name":"entry","$":{"id":"s0195","depth":"3"},"$$":[{"#name":"label","_":"5.2.3"},{"#name":"title","$":{"id":"st195"},"_":"A few conditional hyper-parameters"}]},{"#name":"entry","$":{"id":"s0200","depth":"3"},"$$":[{"#name":"label","_":"5.2.4"},{"#name":"title","$":{"id":"st200"},"_":"A large hyper-parameter configuration space with multiple types of hyper-parameters"}]},{"#name":"entry","$":{"id":"s0205","depth":"3"},"$$":[{"#name":"label","_":"5.2.5"},{"#name":"title","$":{"id":"st205"},"_":"Categorical hyper-parameters"}]}]}]},{"#name":"entry","$":{"id":"s0210","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"6"},{"#name":"title","$":{"id":"st210"},"_":"Existing HPO frameworks"},{"#name":"entry","$":{"id":"s0215","depth":"2"},"$$":[{"#name":"label","_":"6.1"},{"#name":"title","$":{"id":"st215"},"_":"Sklearn"}]},{"#name":"entry","$":{"id":"s0220","depth":"2"},"$$":[{"#name":"label","_":"6.2"},{"#name":"title","$":{"id":"st220"},"_":"Spearmint"}]},{"#name":"entry","$":{"id":"s0225","depth":"2"},"$$":[{"#name":"label","_":"6.3"},{"#name":"title","$":{"id":"st225"},"_":"BayesOpt"}]},{"#name":"entry","$":{"id":"s0230","depth":"2"},"$$":[{"#name":"label","_":"6.4"},{"#name":"title","$":{"id":"st230"},"_":"Hyperopt"}]},{"#name":"entry","$":{"id":"s0235","depth":"2"},"$$":[{"#name":"label","_":"6.5"},{"#name":"title","$":{"id":"st235"},"_":"SMAC"}]},{"#name":"entry","$":{"id":"s0240","depth":"2"},"$$":[{"#name":"label","_":"6.6"},{"#name":"title","$":{"id":"st240"},"_":"BOHB"}]},{"#name":"entry","$":{"id":"s0245","depth":"2"},"$$":[{"#name":"label","_":"6.7"},{"#name":"title","$":{"id":"st245"},"_":"Optunity"}]},{"#name":"entry","$":{"id":"s0250","depth":"2"},"$$":[{"#name":"label","_":"6.8"},{"#name":"title","$":{"id":"st250"},"_":"Skopt"}]},{"#name":"entry","$":{"id":"s0255","depth":"2"},"$$":[{"#name":"label","_":"6.9"},{"#name":"title","$":{"id":"st255"},"_":"GpFlowOpt"}]},{"#name":"entry","$":{"id":"s0260","depth":"2"},"$$":[{"#name":"label","_":"6.10"},{"#name":"title","$":{"id":"st260"},"_":"Talos"}]},{"#name":"entry","$":{"id":"s0265","depth":"2"},"$$":[{"#name":"label","_":"6.11"},{"#name":"title","$":{"id":"st265"},"_":"Sherpa"}]},{"#name":"entry","$":{"id":"s0270","depth":"2"},"$$":[{"#name":"label","_":"6.12"},{"#name":"title","$":{"id":"st270"},"_":"Osprey"}]},{"#name":"entry","$":{"id":"s0275","depth":"2"},"$$":[{"#name":"label","_":"6.13"},{"#name":"title","$":{"id":"st275"},"_":"FAR-HO"}]},{"#name":"entry","$":{"id":"s0280","depth":"2"},"$$":[{"#name":"label","_":"6.14"},{"#name":"title","$":{"id":"st280"},"_":"Hyperband"}]},{"#name":"entry","$":{"id":"s0285","depth":"2"},"$$":[{"#name":"label","_":"6.15"},{"#name":"title","$":{"id":"st285"},"_":"DEAP"}]},{"#name":"entry","$":{"id":"s0290","depth":"2"},"$$":[{"#name":"label","_":"6.16"},{"#name":"title","$":{"id":"st290"},"_":"TPOT"}]},{"#name":"entry","$":{"id":"s0295","depth":"2"},"$$":[{"#name":"label","_":"6.17"},{"#name":"title","$":{"id":"st295"},"_":"Nevergrad"}]}]},{"#name":"entry","$":{"id":"s0300","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"7"},{"#name":"title","$":{"id":"st300"},"_":"Experiments"},{"#name":"entry","$":{"id":"s0305","depth":"2"},"$$":[{"#name":"label","_":"7.1"},{"#name":"title","$":{"id":"st305"},"_":"Experimental setup"}]},{"#name":"entry","$":{"id":"s0310","depth":"2"},"$$":[{"#name":"label","_":"7.2"},{"#name":"title","$":{"id":"st310"},"_":"Performance comparison"}]}]},{"#name":"entry","$":{"id":"s0315","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"8"},{"#name":"title","$":{"id":"st315"},"_":"Open issues, challenges, and future research directions"},{"#name":"entry","$":{"id":"s0320","depth":"2"},"$$":[{"#name":"label","_":"8.1"},{"#name":"title","$":{"id":"st320"},"_":"Model complexity"},{"#name":"entry","$":{"id":"s0325","depth":"3"},"$$":[{"#name":"label","_":"8.1.1"},{"#name":"title","$":{"id":"st325"},"_":"Costly objective function evaluations"}]},{"#name":"entry","$":{"id":"s0330","depth":"3"},"$$":[{"#name":"label","_":"8.1.2"},{"#name":"title","$":{"id":"st330"},"_":"Complex search space"}]}]},{"#name":"entry","$":{"id":"s0335","depth":"2"},"$$":[{"#name":"label","_":"8.2"},{"#name":"title","$":{"id":"st335"},"_":"Model performance"},{"#name":"entry","$":{"id":"s0340","depth":"3"},"$$":[{"#name":"label","_":"8.2.1"},{"#name":"title","$":{"id":"st340"},"_":"Strong anytime performance and final performance"}]},{"#name":"entry","$":{"id":"s0345","depth":"3"},"$$":[{"#name":"label","_":"8.2.2"},{"#name":"title","$":{"id":"st345"},"_":"Comparability of HPO methods"}]},{"#name":"entry","$":{"id":"s0350","depth":"3"},"$$":[{"#name":"label","_":"8.2.3"},{"#name":"title","$":{"id":"st350"},"_":"Over-fitting and generalization"}]},{"#name":"entry","$":{"id":"s0355","depth":"3"},"$$":[{"#name":"label","_":"8.2.4"},{"#name":"title","$":{"id":"st355"},"_":"Randomness"}]},{"#name":"entry","$":{"id":"s0360","depth":"3"},"$$":[{"#name":"label","_":"8.2.5"},{"#name":"title","$":{"id":"st360"},"_":"Scalability"}]},{"#name":"entry","$":{"id":"s0365","depth":"3"},"$$":[{"#name":"label","_":"8.2.6"},{"#name":"title","$":{"id":"st365"},"_":"Continuous updating capability"}]}]}]},{"#name":"entry","$":{"id":"s0370","type":"sections","depth":"1"},"$$":[{"#name":"label","_":"9"},{"#name":"title","$":{"id":"st370"},"_":"Conclusion"}]},{"#name":"entry","$":{"id":"s0380","type":"sections","depth":"1"},"$$":[{"#name":"title","$":{"id":"st380"},"_":"CRediT authorship contribution statement"}]},{"#name":"entry","$":{"id":"coi005","type":"conflict-of-interest","depth":"1"},"$$":[{"#name":"title","$":{"id":"st700"},"_":"Declaration of Competing Interest"}]},{"#name":"entry","$":{"id":"bi005","type":"bibliography","depth":"1"},"$$":[{"#name":"title","$":{"id":"st10000"},"_":"References"}]},{"#name":"entry","$":{"id":"bg005","type":"biography","depth":"1"},"$$":[{"#name":"title","_":"Vitae"}]}],"figures":[],"tables":[{"#name":"entry","$":{"id":"t0055","type":"sections","local-type":"table"}},{"#name":"entry","$":{"id":"t0005","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 1"},{"#name":"caption","$":{"truncated":"false"},"_":"The comparison of common HPO algorithms (n is the number of hyper-parameter values and k is the number of hyper-parameters)."}]},{"#name":"entry","$":{"id":"t0010","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 2"},{"#name":"caption","$":{"truncated":"false"},"_":"A comprehensive overview of common ML models, their hyper-parameters, suitable optimization techniques, and available Python libraries."}]},{"#name":"entry","$":{"id":"t0015","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 3"},{"#name":"caption","$":{"truncated":"false"},"_":"Configuration space for the hyper-parameters of tested ML models."}]},{"#name":"entry","$":{"id":"t0020","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 4"},{"#name":"caption","$":{"truncated":"false"},"_":"Performance evaluation of applying HPO methods to the RF classifier on the MNIST dataset."}]},{"#name":"entry","$":{"id":"t0025","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 5"},{"#name":"caption","$":{"truncated":"false"},"_":"Performance evaluation of applying HPO methods to the SVM classifier on the MNIST dataset."}]},{"#name":"entry","$":{"id":"t0030","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 6"},{"#name":"caption","$":{"truncated":"false"},"_":"Performance evaluation of applying HPO methods to the KNN classifier on the MNIST dataset."}]},{"#name":"entry","$":{"id":"t0035","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 7"},{"#name":"caption","$":{"truncated":"false"},"_":"Performance evaluation of applying HPO methods to the RF regressor on the Bostonâ€“housing dataset."}]},{"#name":"entry","$":{"id":"t0040","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 8"},{"#name":"caption","$":{"truncated":"false"},"_":"Performance evaluation of applying HPO methods to the SVM regressor on the Bostonâ€“housing dataset."}]},{"#name":"entry","$":{"id":"t0045","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 9"},{"#name":"caption","$":{"truncated":"false"},"_":"Performance evaluation of applying HPO methods to the KNN regressor on the Bostonâ€“housing dataset."}]},{"#name":"entry","$":{"id":"t0050","type":"sections","local-type":"table"},"$$":[{"#name":"label","_":"Table 10"},{"#name":"caption","$":{"truncated":"false"},"_":"The open challenges and future directions of HPO research."}]}],"extras":[],"attachments":[],"showEntitledTocLinks":false},"tail":{},"transientError":{"isOpen":false},"userAgent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36","sidePanel":{"openState":1},"viewConfig":{"articleFeature":{"rightsAndContentLink":true},"pathPrefix":""},"virtualSpecialIssue":{"showVirtualSpecialIssueLink":false},"userCookiePreferences":{"STRICTLY_NECESSARY":true,"PERFORMANCE":true,"FUNCTIONAL":true,"TARGETING":true}}</script>
<script src="https://assets.adobedtm.com/4a848ae9611a/032db4f73473/launch-a6263b31083f.min.js" type="47a3bd3f3a53d05185487be5-text/javascript" async></script>
<script type="47a3bd3f3a53d05185487be5-text/javascript">
    window.pageData = {"content":[{"contentType":"JL","format":"MIME-XHTML","id":"sd:article:pii:S0925231220311693","type":"sd:article:JL:scope-abstract","detail":"sd:article:subtype:fla","publicationType":"journal","issn":"0925-2312","volumeNumber":"415","suppl":"C","provider":"elsevier","entitlementType":"unsubscribed"}],"page":{"businessUnit":"ELS:RP:ST","language":"en","name":"product:journal:article","noTracking":"false","productAppVersion":"abstract-redirected","productName":"SD","type":"CP-CA","environment":"prod","loadTimestamp":1715929730764,"loadTime":""},"visitor":{"accessType":"ae:ANON_GUEST","accountId":"ae:228598","accountName":"ae:ScienceDirect Guests","loginStatus":"anonymous","userId":"ae:12975512","ipAddress":"79.78.170.33","appSessionId":"f3c519c8-b9ac-49b8-85ea-12d55db11507"}};
    window.pageData.page.loadTime = performance ? Math.round(performance.now()).toString() : '';

    try {
      appData.push({
      event: 'pageLoad',
      page: pageData.page,
      visitor: pageData.visitor,
      content: pageData.content
      })
    } catch(e) {
        console.warn("There was an error loading or running Adobe DTM: ", e);
    }
</script>
<script nomodule src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/73/js/core-js/3.20.2/core-js.es.minified.js" type="47a3bd3f3a53d05185487be5-text/javascript"></script>
<script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/100/js/react/16.14.0/react.production.min.js" type="47a3bd3f3a53d05185487be5-text/javascript"></script>
<script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/shared-assets/100/js/react-dom/16.14.0/react-dom.production.min.js" type="47a3bd3f3a53d05185487be5-text/javascript"></script>
<script src="https://sdfestaticassets-eu-west-1.sciencedirectassets.com/prod/402a3f5c247cf997723622b5a8bc17cc2004f90c/arp.js" async type="47a3bd3f3a53d05185487be5-text/javascript"></script>
<script type="47a3bd3f3a53d05185487be5-text/javascript">
    const pendoData = {"visitor":{"pageName":"SD:product:journal:article","pageType":"CP-CA","pageProduct":"SD","pageLanguage":"en","pageEnvironment":"prod","accessType":"ae:ANON_GUEST","countryCode":"GB"},"account":{"id":"ae:228598","name":"ae:ScienceDirect Guests"},"events":{}};;
    pendoData.events = {
      ready: function () {
        pendo.addAltText();
      },
    };
    function runPendo(data, options) {
  const {
    firstDelay,
    maxRetries,
    urlPrefix,
    urlSuffix,
    apiKey
  } = options;
  (function (apiKey) {
    (function (p, e, n, d, o) {
      var v, w, x, y, z;
      o = p[d] = p[d] || {};
      o._q = [];
      v = ['initialize', 'identify', 'updateOptions', 'pageLoad'];
      for (w = 0, x = v.length; w < x; ++w) (function (m) {
        o[m] = o[m] || function () {
          o._q[m === v[0] ? 'unshift' : 'push']([m].concat([].slice.call(arguments, 0)));
        };
      })(v[w]);
      y = e.createElement(n);
      y.async = !0;
      y.src = urlPrefix + apiKey + urlSuffix;
      z = e.getElementsByTagName(n)[0];
      z.parentNode.insertBefore(y, z);
    })(window, document, 'script', 'pendo');
    pendo.addAltText = function () {
      var target = document.querySelector('body');
      var observer = new MutationObserver(function (mutations) {
        mutations.forEach(function (mutation) {
          if (mutation?.addedNodes?.length) {
            if (mutation.addedNodes[0]?.className?.includes("_pendo-badge")) {
              const badge = mutation.addedNodes[0];
              const altText = badge?.attributes['aria-label'].value ? badge?.attributes['aria-label'].value : 'Feedback';
              const pendoBadgeImage = pendo.dom(`#${badge?.attributes?.id.value} img`);
              if (pendoBadgeImage.length) {
                pendoBadgeImage[0]?.setAttribute('alt', altText);
              }
            }
          }
        });
      });
      var config = {
        attributeFilter: ['data-layout'],
        attributes: true,
        childList: true,
        characterData: true,
        subtree: false
      };
      observer.observe(target, config);
    };
  })(apiKey);
  (function watchAndSetPendo(nextDelay, retryAttempt) {
    if (typeof pageDataTracker === 'object' && typeof pageDataTracker.getVisitorId === 'function' && pageDataTracker.getVisitorId()) {
      data.visitor.id = pageDataTracker.getVisitorId();
      console.debug(`initializing pendo`);
      pendo.initialize(data);
    } else {
      if (retryAttempt > 0) {
        return setTimeout(function () {
          watchAndSetPendo(nextDelay * 2, retryAttempt - 1);
        }, nextDelay);
      }
      pendo.initialize(data);
      console.debug(`gave up ... pendo initialized`);
    }
  })(firstDelay, maxRetries);
}
    runPendo(pendoData, {
      firstDelay: 100,
      maxRetries: 5,
      urlPrefix: 'https://cdn.pendo.io/agent/static/',
      urlSuffix: '/pendo.js',
      apiKey: 'd6c1d995-bc7e-4e53-77f1-2ea4ecbb9565',
    });
  </script>
<span id="pendo-answer-rating"></span>
<script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          displayAlign: 'left',
          "fast-preview": {
            disabled: true
          },
          CommonHTML: { linebreaks: { automatic: true } },
          PreviewHTML: { linebreaks: { automatic: true } },
          'HTML-CSS': { linebreaks: { automatic: true } },
          SVG: {
            scale: 90,
            linebreaks: { automatic: true }
          }
        });
      </script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=MML_SVG" type="47a3bd3f3a53d05185487be5-text/javascript"></script>
<script async src="https://www.googletagservices.com/tag/js/gpt.js" type="47a3bd3f3a53d05185487be5-text/javascript"></script>
<script async src="https://scholar.google.com/scholar_js/casa.js" type="47a3bd3f3a53d05185487be5-text/javascript"></script>
<script type="47a3bd3f3a53d05185487be5-module" src="https://static.mendeley.com/view-pdf-component/0.8.9/dist/view-pdf-element.js" crossorigin="anonymous" async></script>
<script data-cfasync="false">
      (function initOneTrust()  {
        const monitor = {
  init: () => {},
  loaded: () => {},
};
        function enableGroup(group) {
  document.querySelectorAll(`script[type*="ot-${group}"]`).forEach(script => {
    script.type = 'text/javascript';
    document.head.appendChild(script);
  });
}
        function runOneTrustCookies(doClear, monitor) {
  const oneTrustConsentSdkId = 'onetrust-consent-sdk';
  const emptyNodeSelectors = 'h3.ot-host-name, h4.ot-host-desc, button.ot-host-box';
  const ariaLabelledByButtonNodes = 'div.ot-accordion-layout > button';
  const ariaAttribute = 'aria-labelledby';
  function adjustOneTrustDOM() {
    const oneTrustRoot = document.getElementById('onetrust-consent-sdk');

    /* remove empty nodes */
    [...(oneTrustRoot?.querySelectorAll(emptyNodeSelectors) ?? [])].filter(e => e.textContent === '').forEach(e => e.remove());

    /* remove invalid aria-labelledby values */
    oneTrustRoot?.querySelectorAll(ariaLabelledByButtonNodes).forEach(e => {
      const presentIdValue = e.getAttribute(ariaAttribute)?.split(' ').filter(label => document.getElementById(label)).join(' ');
      if (presentIdValue) {
        e.setAttribute(ariaAttribute, presentIdValue);
      }
    });
  }
  function observeOneTrustLoaded(shouldSetOTDefaults, isConsentPresent) {
    const cb = (mutationList, observer) => {
      const oneTrustRoot = mutationList.filter(mutationRecord => mutationRecord.type === 'childList' && mutationRecord.addedNodes.length).map(mutationRecord => [...mutationRecord.addedNodes]).flat().find(e => e.id === oneTrustConsentSdkId);
      if (oneTrustRoot && typeof OneTrust !== 'undefined') {
        monitor.loaded(true);
        OneTrust.OnConsentChanged(() => {
          const perfAllowed = decodeURIComponent(document.cookie.match('(^| )OptanonConsent=([^;]+)')?.[2])?.match('groups=([0-9:0|1,?]+)&?')?.[1]?.match('2:([0|1])')[1] === '1';
          if (perfAllowed) {
            enableGroup('performance');
          }
        });
        if (!isConsentPresent && (shouldSetOTDefaults || OneTrust.GetDomainData().ConsentModel.Name === 'implied consent')) {
          OneTrust.AllowAll();
        }
        document.dispatchEvent(new CustomEvent('@sdtech/onetrust/loaded', {}));
        observer.disconnect();
        adjustOneTrustDOM();
      }
    };
    const observer = new MutationObserver(cb);
    observer.observe(document.querySelector('body'), {
      childList: true
    });
  }
  if (doClear) {
    document.cookie = 'OptanonAlertBoxClosed=; expires=Thu, 01 Jan 1970 00:00:00 UTC; samesite=lax; path=/';
  }
  const isConsentPresent = !!decodeURIComponent(document.cookie.match('(^| )OptanonConsent=([^;]+)')?.[2])?.match('groups=([0-9:0|1,?]+)&?')?.[1];
  const shouldSetOTDefaults = 'true' === 'false' && !document.cookie?.match('OptanonAlertBoxClosed=');
  if (shouldSetOTDefaults) {
    const date = new Date();
    date.setFullYear(date.getFullYear() + 1);
    document.cookie = `OptanonAlertBoxClosed=${new Date().toISOString()}; expires=${date.toUTCString()}; samesite=lax; path=/; domain=sciencedirect.com`;
  }
  observeOneTrustLoaded(shouldSetOTDefaults, isConsentPresent, monitor);
  window.addOTScript = () => {
    const otSDK = document.createElement('script');
    otSDK.setAttribute('data-cfasync', 'false');
    otSDK.setAttribute('src', 'https://cdn.cookielaw.org/scripttemplates/otSDKStub.js');
    otSDK.setAttribute('data-document-language', 'true');
    otSDK.setAttribute('data-domain-script', '865ea198-88cc-4e41-8952-1df75d554d02');
    window.addOTScript = () => {};
    document.head.appendChild(otSDK);
    monitor.init();
  };
  window.addEventListener('load', () => window.addOTScript());
}
        if (document.location.host.match(/.sciencedirect.com$/)) {
          runOneTrustCookies(true, monitor);
        }
        else {
          window.addEventListener('load', (event) => {
            enableGroup('performance');
          });
        }
      }());
    </script>
<script src="/cdn-cgi/scripts/7d0fa10a/cloudflare-static/rocket-loader.min.js" data-cf-settings="47a3bd3f3a53d05185487be5-|49" defer></script><script>(function(){if (!document.body) return;var js = "window['__CF$cv$params']={r:'8851c7509b6e3696',t:'MTcxNTkyOTczMS4xMTQwMDA='};_cpo=document.createElement('script');_cpo.nonce='',_cpo.src='/cdn-cgi/challenge-platform/scripts/jsd/main.js',document.getElementsByTagName('head')[0].appendChild(_cpo);";var _0xh = document.createElement('iframe');_0xh.height = 1;_0xh.width = 1;_0xh.style.position = 'absolute';_0xh.style.top = 0;_0xh.style.left = 0;_0xh.style.border = 'none';_0xh.style.visibility = 'hidden';document.body.appendChild(_0xh);function handler() {var _0xi = _0xh.contentDocument || _0xh.contentWindow.document;if (_0xi) {var _0xj = _0xi.createElement('script');_0xj.innerHTML = js;_0xi.getElementsByTagName('head')[0].appendChild(_0xj);}}if (document.readyState !== 'loading') {handler();} else if (window.addEventListener) {document.addEventListener('DOMContentLoaded', handler);} else {var prev = document.onreadystatechange || function () {};document.onreadystatechange = function (e) {prev(e);if (document.readyState !== 'loading') {document.onreadystatechange = prev;handler();}};}})();</script></body>
</html>