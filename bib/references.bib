@INPROCEEDINGS{7280644,
  author={Mantovani, Rafael G. and Rossi, André L. D. and Vanschoren, Joaquin and Bischl, Bernd and Carvalho, André C. P. L. F.},
  booktitle={2015 International Joint Conference on Neural Networks (IJCNN)}, 
  title={To tune or not to tune: Recommending when to adjust SVM hyper-parameters via meta-learning}, 
  year={2015},
  volume={},
  number={},
  pages={1-8},
  keywords={Niobium,Support vector machines,Training,Optimization,Computational modelling,Nickel,Radio frequency},
  doi={10.1109/IJCNN.2015.7280644},
series={2015 International Joint Conference on Neural Networks (IJCNN)}
}


@article{JMLRv2018444,
  author  = {Philipp Probst and Anne-Laure Boulesteix and Bernd Bischl},
  title   = {Tunability: Importance of Hyperparameters of Machine Learning Algorithms},
  journal = {Journal of Machine Learning Research},
  year    = {2019},
  volume  = {20},
  number  = {53},
  pages   = {1--32},
  url     = {http://jmlr.org/papers/v20/18-444.html},
  doi	  = {10.48550/arXiv.1802.09596},
series={Journal of Machine Learning Research, Vol. 20},
keywords={ machine learning, supervised learning, classification, hyperparameters, tuning, meta-learning }
}


@article{Weerts2020ImportanceOT,
  title={Importance of Tuning Hyperparameters of Machine Learning Algorithms},
  author={Hilde J. P. Weerts and Andreas Mueller and Joaquin Vanschoren},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.07588},
  url={https://api.semanticscholar.org/CorpusID:220525868},
  doi	  = {10.48550/arXiv.2007.07588},
series={arXiv preprint arXiv:2007.07588, 2020},
keywords={ machine learning, hyperparameter tuning, meta learning }
}


@article{101016jipm,
author = {Jang, Hyejin and Yoon, Byungun},
title = {TechWordNet: Development of semantic relation for technology information analysis using F-term and natural language processing},
year = {2021},
issue_date = {Nov 2021},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {58},
number = {6},
issn = {0306-4573},
url = {https://doi.org/10.1016/j.ipm.2021.102752},
doi = {10.1016/j.ipm.2021.102752},
journal = {Inf. Process. Manage.},
month = {nov},
numpages = {18},
keywords = {Technology intelligence, F-term, Patent analysis, Natural language processing, Deep learning},
series={Information Processing & Management, Vol. 58}
}


@InProceedings{1010079783,
author="Krapivin, Mikalai
and Autayeu, Aliaksandr
and Marchese, Maurizio
and Blanzieri, Enrico
and Segata, Nicola",
editor="Chowdhury, Gobinda
and Koo, Chris
and Hunter, Jane",
title="Keyphrases Extraction from Scientific Documents: Improving Machine Learning Approaches with Natural Language Processing",
booktitle="The Role of Digital Libraries in a Time of Global Change",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="102--111",
abstract="In this paper we use Natural Language Processing techniques to improve different machine learning approaches (Support Vector Machines (SVM), Local SVM, Random Forests) to the problem of automatic keyphrases extraction from scientific papers. For the evaluation we propose a large and high-quality dataset: 2000 ACM papers from the Computer Science domain. We evaluate by comparison with expert-assigned keyphrases. Evaluation shows promising results that outperform state-of-the-art Bayesian learning system KEA improving the average F-Measure from 22{\%} (KEA) to 30{\%} (Random Forest) on the same dataset without the use of controlled vocabularies. Finally, we report a detailed analysis of the effect of the individual NLP features and data set size on the overall quality of extracted keyphrases.",
isbn="978-3-642-13654-2",
url={https://link.springer.com/chapter/10.1007/978-3-642-13654-2_12},
series={ICADL 2010, Lecture Notes in Computer Science, vol. 6102},
keywords={
Natural Language Processing, Machine Learning, Keyphrase Extraction, Support Vector Machines, Random Forests }
}


@InProceedings{10100797898116,
author="Pudasaini, Shushanta
and Shakya, Subarna
and Lamichhane, Sagar
and Adhikari, Sajjan
and Tamang, Aakash
and Adhikari, Sujan",
editor="Jeena Jacob, I.
and Gonzalez-Longatt, Francisco M.
and Kolandapalayam Shanmugam, Selvanayaki
and Izonin, Ivan",
title="Application of NLP for Information Extraction from Unstructured Documents",
booktitle="Expert Clouds and Applications",
year="2022",
publisher="Springer Singapore",
address="Singapore",
pages="695--704",
abstract="Pudasaini, ShushantaShakya, SubarnaLamichhane, SagarAdhikari, SajjanTamang, AakashAdhikari, SujanThe world is intrigued by data. In fact, huge capitals are invested to devise means that implements statistics and extract analytics from these sources. However, when we examine the studies performed on applicant tracking systems that retrieve valuable information from candidates' CVs and job descriptions, they are mostly rule-based and hardly manage to employ contemporary techniques. Even though these documents vary in contents, the structure is almost identical. Accordingly, in this paper, we implement an NLP pipeline for the extraction of such structured information from a wide variety of textual documents. As a reference, textual documents which are used in applicant tracking systems like CV (Curriculum Vitae) and job vacancy information have been considered. The proposed NLP pipeline is built with several NLP techniques like document classification, document segmentation and text extraction. Initially for the classification of textual documents, support vector machines (SVM) and XGBoost algorithms have been implemented. Different segments of the identified document are categorized using NLP techniques such as chunking, regex matching and POS tagging. Relevant information from every segment is further extracted using techniques like Named Entity Recognition (NER), regex matching and pool parsing. Extraction of such structured information from textual documents can help to gain insights and use those insights in document maintenance, document scoring, matching and auto-filling forms.",
isbn="978-981-16-2126-0",
url={https://link.springer.com/chapter/10.1007/978-981-16-2126-0_54},
series={Expert Clouds and Applications, Lecture Notes in Networks and Systems, vol. 209},
keywords={ Keywords: NLP, information extraction, segmentation, Named Entity Recognition (NER), GaussianNB, SVM, spaCy }
}


@article{knisely2023research,
  title={Research proposal content extraction using natural language processing and semi-supervised clustering: a demonstration and comparative analysis},
  author={Knisely, Benjamin M and Pavliscsak, Holly H},
  journal={Scientometrics},
  volume={128},
  number={5},
  pages={3197--3224},
  year={2023},
  publisher={Springer},
  doi={10.1007/s11192-023-04689-3},
series={Scientometrics, Vol. 128},
keywords={ Text mining · Machine learning · Cluster validation · Document clustering · Research portfolio }
}


@INPROCEEDINGS{6681106,
  author={Kumar, Pawan and Ahmad, Rashid and Chaudhary, B.D. and Sinha, Mukul K.},
  booktitle={2013 13th International Conference on Computational Science and Its Applications}, 
  title={Enriched Dashboard: An Integration and Visualization Tool for Distributed NLP Systems on Heterogeneous Platforms}, 
  year={2013},
  volume={},
  number={},
  pages={105-114},
  keywords={Natural language processing,Runtime,Software,Computer languages,Visualization,Accuracy,Computer architecture,Distributed NLP Tool,Dashboard,Integration and Testing,Visualization,Validation},
  doi={10.1109/ICCSA.2013.24},
series={2013 13th International Conference on Computational Science and Its Applications (ICCSA)}}


@article{1010800887441720201774442,
author = {Michel Mitri},
title = {Story Analysis Using Natural Language Processing and Interactive Dashboards},
journal = {Journal of Computer Information Systems},
volume = {62},
number = {2},
pages = {216--226},
year = {2022},
publisher = {Taylor \& Francis},
doi = {10.1080/08874417.2020.1774442},


URL = { 
    
        https://doi.org/10.1080/08874417.2020.1774442
    
    

},
eprint = { 
    
        https://doi.org/10.1080/08874417.2020.1774442
    
    

},
series={Journal of Computer Information Systems, Vol. 62},
keywords={ Natural language processing (NLP), data visualization, story analysis, NLP accuracy issues and mitigations, story dashboard generation }
}



@article{Trivedi2017AnIT,
  title={An Interactive Tool for Natural Language Processing on Clinical Text},
  author={Gaurav Trivedi and Phuong Pham and Wendy W. Chapman and Rebecca Hwa and Janyce Wiebe and Harry Hochheiser},
  journal={ArXiv},
  year={2017},
  volume={abs/1707.01890},
  url={https://api.semanticscholar.org/CorpusID:13324724},
  doi={10.48550/arXiv.1707.01890},
series={arXiv preprint arXiv:1707.01890 (2017)},
keywords={ Clinical text analysis, electronic medical records, visualization, interactive machine learning}
}


@article{ArnoldBiedebach24,
title={The role of hyperparameters in machine learning models and how to tune them}, 
doi={10.1017/psrm.2023.61}, 
journal={Political Science Research and Methods}, 
author={Arnold, Christian and Biedebach, Luka and Küpfer, Andreas and Neunhoeffer, Marcel}, 
year={2024}, 
pages={1–8},
series={Political Science Research and Methods, 2024},
keywords={ Best Practice, Hyperparameter Optimization, Machine Learning }
} 


@article{bahmani2021tune,
  title={To tune or not to tune? An approach for recommending important hyperparameters},
  author={Bahmani, Mohamadjavad and Shawi, Radwa El and Potikyan, Nshan and Sakr, Sherif},
  journal={arXiv preprint arXiv:2108.13066},
  year={2021},
  doi={10.48550/arXiv.2108.13066},
series={arXiv preprint arXiv:2108.13066},
keywords={ Meta-learning, hyperparameter importance, hyperparameter optimization, classification }

}


@article{YANG2020295,
title = {On hyperparameter optimization of machine learning algorithms: Theory and practice},
journal = {Neurocomputing},
volume = {415},
pages = {295-316},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2020.07.061},
url = {https://www.sciencedirect.com/science/article/pii/S0925231220311693},
author = {Li Yang and Abdallah Shami},
keywords = {Hyper-parameter optimization, Machine learning, Bayesian optimization, Particle swarm optimization, Genetic algorithm, Grid search},
abstract = {Machine learning algorithms have been used widely in various applications and areas. To fit a machine learning model into different problems, its hyper-parameters must be tuned. Selecting the best hyper-parameter configuration for machine learning models has a direct impact on the model’s performance. It often requires deep knowledge of machine learning algorithms and appropriate hyper-parameter optimization techniques. Although several automatic optimization techniques exist, they have different strengths and drawbacks when applied to different types of problems. In this paper, optimizing the hyper-parameters of common machine learning models is studied. We introduce several state-of-the-art optimization techniques and discuss how to apply them to machine learning algorithms. Many available libraries and frameworks developed for hyper-parameter optimization problems are provided, and some open challenges of hyper-parameter optimization research are also discussed in this paper. Moreover, experiments are conducted on benchmark datasets to compare the performance of different optimization methods and provide practical examples of hyper-parameter optimization. This survey paper will help industrial users, data analysts, and researchers to better develop machine learning models by identifying the proper hyper-parameter configurations effectively.},
series={Neurocomputing, Volume 415}
}


@InProceedings{10100797303128032028,
author="Vallejo-Huanga, Diego
and Jaime, Janneth
and Andrade, Carlos",
editor="Sserwanga, Isaac
and Goulding, Anne
and Moulaison-Sandy, Heather
and Du, Jia Tina
and Soares, Ant{\'o}nio Lucas
and Hessami, Viviane
and Frank, Rebecca D.",
title="Similarity Visualizer Using Natural Language Processing in Academic Documents of the DSpace in Ecuador",
booktitle="Information for a Better World: Normality, Virtuality, Physicality, Inclusivity",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="343--359",
abstract="Due to the widespread use of the Internet, users have the ease of accessing collections of university academic documents stored in virtual libraries whose information is of an unstructured type. In recent years, the production and publication of scientific documents in Ecuador have increased considerably, so the search and classification of documents is a fundamental task within information retrieval computer systems. Intelligent search systems allow found information with a high degree of accuracy and similarity. For the development of this project, academic documents from the Ecuador Network of Open Access Repositories (RRAAE) were retrieved using a glossary of terms in the area of science and technology. For the recovery of documents, the web scraping technique was used and its results were stored in a cloud database in JSON format. In the recovered documents, NLP techniques were applied to clean and homogenize the unstructured information. Two similarity metrics were used to measure the divergence between the retrieved documents, and similarity matrices were generated based on the title, keywords, and abstract, which were then unified into a weighted matrix. The results of the system are displayed in a web interface that, through the use of graphs, shows the relationship between the linked documents. The operation of the similarity system was validated through functional tests through experimentation with a collection of 30 queries with indexed and non-indexed terms in the input of the information retrieval system. The experiments showed that for indexed terms, the system performs better.",
isbn="978-3-031-28032-0",
url={https://link.springer.com/chapter/10.1007/978-3-031-28032-0_28},
series={Information for a Better World: Normality, Virtuality, Physicality, Inclusivity. iConference 2023},
 keywords={ Vector cosine similarity , Web scraping ,Connected papers ,Jaccard ,Artificial intelligence , University repositories ,DSpace , Graphs }

}


@article{101136amiajnl2011000183,
    author = {D'Avolio, Leonard W and Nguyen, Thien M and Goryachev, Sergey and Fiore, Louis D},
    title = "{Automated concept-level information extraction to reduce the need for custom software and rules development}",
    journal = {Journal of the American Medical Informatics Association},
    volume = {18},
    number = {5},
    pages = {607-613},
    year = {2011},
    month = {06},
    abstract = "{Objective Despite at least 40 years of promising empirical performance, very few clinical natural language processing (NLP) or information extraction systems currently contribute to medical science or care. The authors address this gap by reducing the need for custom software and rules development with a graphical user interface-driven, highly generalizable approach to concept-level retrieval.Materials and methods A ‘learn by example’ approach combines features derived from open-source NLP pipelines with open-source machine learning classifiers to automatically and iteratively evaluate top-performing configurations. The Fourth i2b2/VA Shared Task Challenge's concept extraction task provided the data sets and metrics used to evaluate performance.Results Top F-measure scores for each of the tasks were medical problems (0.83), treatments (0.82), and tests (0.83). Recall lagged precision in all experiments. Precision was near or above 0.90 in all tasks.Discussion With no customization for the tasks and less than 5 min of end-user time to configure and launch each experiment, the average F-measure was 0.83, one point behind the mean F-measure of the 22 entrants in the competition. Strong precision scores indicate the potential of applying the approach for more specific clinical information extraction tasks. There was not one best configuration, supporting an iterative approach to model creation.Conclusion Acceptable levels of performance can be achieved using fully automated and generalizable approaches to concept-level information extraction. The described implementation and related documentation is available for download.}",
    issn = {1067-5027},
    doi = {10.1136/amiajnl-2011-000183},
    url = {https://doi.org/10.1136/amiajnl-2011-000183},
    eprint = {https://academic.oup.com/jamia/article-pdf/18/5/607/5964646/18-5-607.pdf},
series={Journal of the American Medical Informatics Association, Volume 18},
keywords={ Clinical Natural Language Processing, Information Extraction, Concept-level Retrieval, Machine Learning Classifiers, Medical Concept Extraction}
}



@article{Singh2018NaturalLP,
  title={Natural Language Processing for Information Extraction},
  author={Sonit Singh},
  journal={ArXiv},
  year={2018},
  volume={abs/1807.02383},
  url={https://api.semanticscholar.org/CorpusID:49653505},
  doi={10.48550/arXiv.1807.02383},
series={ArXiv abs/1807.02383 (2018)},
keywords={ Information Extraction, Information Retrieval, Named Entity Recognition, Natural Language Processing, Unstructured Data Processing }

}


@article{pirnau2024content,
  title={Content Analysis Using Specific Natural Language Processing Methods for Big Data},
  author={Pirnau, Mironela and Botezatu, Mihai Alexandru and Priescu, Iustin and Hosszu, Alexandra and Tabusca, Alexandru and Coculescu, Cristina and Oncioiu, Ionica},
  journal={Electronics},
  volume={13},
  number={3},
  pages={584},
  year={2024},
  publisher={MDPI},
  doi={10.3390/electronics13030584},
series={Electronics 13, no. 3 (2024)},
keywords={ natural language processing, big data, sentiment analysis,similarity analysis, word dictionary, word cloud }

}



@article{10117714738716211038898,
author = {Mohammad Alharbi and Matthew Roach and Tom Cheesman and Robert S Laramee},
title ={VNLP: Visible natural language processing},

journal = {Information Visualization},
volume = {20},
number = {4},
pages = {245-262},
year = {2021},
doi = {10.1177/14738716211038898},

URL = { 
    
        https://doi.org/10.1177/14738716211038898
    
    

},
eprint = { 
    
        https://doi.org/10.1177/14738716211038898
    
    

},
keywords={ Text alignment, parallel translations, text visualization }

,
    abstract = { In general, Natural Language Processing (NLP) algorithms exhibit black-box behavior. Users input text and output are provided with no explanation of how the results are obtained. In order to increase understanding and trust, users value transparent processing which may explain derived results and enable understanding of the underlying routines. Many approaches take an opaque approach by default when designing NLP tools and do not incorporate a means to steer and manipulate the intermediate NLP steps. We present an interactive, customizable, visual framework that enables users to observe and participate in the NLP pipeline processes, explicitly manipulate the parameters of each step, and explore the result visually based on user preferences. The visible NLP (VNLP) pipeline design is then applied to a text similarity application to demonstrate the utility and advantages of a visible and transparent NLP pipeline in supporting users to understand and justify both the process and results. We also report feedback on our framework from a modern languages expert. },
series={Information Visualization, 20(4), 245-262 (2021)}
}



@inproceedings{Mohammad2020NLPSA,
  title={NLP Scholar: An Interactive Visual Explorer for Natural Language Processing Literature},
  author={Saif M. Mohammad},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:219179245},
  doi={10.48550/arXiv.2006.01131},
series={arXiv preprint arXiv:2006.01131 (2020)},
keywords={ NLP Scholar Project, Unified Dataset, Interactive Visualizations, Citation Analysis, ACL Anthology }

}


@article{Shah2021TweeNLPAT,
  title={TweeNLP: A Twitter Exploration Portal for Natural Language Processing},
  author={Viraj Shah and Shruti Singh and Mayank Kumar Singh},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.10512},
  url={https://api.semanticscholar.org/CorpusID:235489949},
  doi={10.48550/arXiv.2106.10512},
series={arXiv preprint arXiv:2106.10512 (2021)},
keywords={ Twitter NLP Data, Visualization Platform, TweetExplorer, NLP Conferences, Research Paper Discovery }

}


@article{Rijn2017HyperparameterIA,
  title={Hyperparameter Importance Across Datasets},
  author={Jan N. van Rijn and Frank Hutter},
  journal={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:26878950},
  doi={10.48550/arXiv.1710.04725},
series={Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery & data mining},
keywords={ Hyperparameter Optimization, Hyperparameter Importance, metalearning }

}


@inproceedings{10555530155443015551,
author = {Ridd, Parker and Giraud-Carrier, Christophe},
title = {Using metalearning to predict when parameter optimization is likely to improve classification accuracy},
year = {2014},
isbn = {16130073},
publisher = {CEUR-WS.org},
address = {Aachen, DEU},
abstract = {Work on metalearning for algorithm selection has often been criticized because it mostly considers only the default parameter settings of the candidate base learning algorithms. Many have indeed argued that the choice of parameter values can have a significant impact on accuracy. Yet little empirical evidence exists to provide definitive support for that argument. Recent experiments do suggest that parameter optimization may indeed have an impact. However, the distribution of performance differences has a long tail, suggesting that in most cases parameter optimization has little effect on accuracy. In this paper, we revisit some of these results and use metalearning to characterize the situations when parameter optimization is likely to cause a significant increase in accuracy. In so doing, we show that 1) a relatively simple and efficient landmarker carries significant predictive power, and 2) metalearning for algorithm selection should be effected in two phases, the first in which one determines whether parameter optimization is likely to increase accuracy, and the second in which algorithm selection actually takes place.},
booktitle = {Proceedings of the 2014 International Conference on Meta-Learning and Algorithm Selection - Volume 1201},
pages = {18–23},
numpages = {6},
location = {Prague, Czech Republic},
series = {MLAS'14},
doi = {10.5555/3015544.3015551},
keywords={ Metalearning, Algorithm Selection, Parameter Optimization, Classification Learning, Model Accuracy }

}


@inproceedings{Vashishth2018RESIDEID,
  title={RESIDE: Improving Distantly-Supervised Neural Relation Extraction using Side Information},
  author={Shikhar Vashishth and Rishabh Joshi and Sai Suman Prayaga and Chiranjib Bhattacharyya and Partha Pratim Talukdar},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2018},
  url={https://api.semanticscholar.org/CorpusID:53064621},
  doi={10.48550/arXiv.1812.04361},
series={arXiv preprint arXiv:1812.04361},
keywords={ Relation Extraction, Distant Supervision, Knowledge Bases, Side Information, RESIDE Model }

}


@article{AN2018217,
title = {Deriving technology intelligence from patents: Preposition-based semantic analysis},
journal = {Journal of Informetrics},
volume = {12},
number = {1},
pages = {217-236},
year = {2018},
issn = {1751-1577},
doi = {https://doi.org/10.1016/j.joi.2018.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S1751157716303777},
author = {Jaehyeong An and Kyuwoong Kim and Letizia Mortara and Sungjoo Lee},
keywords = {Technology intelligence, Technology search, Technology trends, Patent analysis, Semantic, Preposition, Text mining, Key-words, Text mining},
abstract = {Patents are one of the most reliable sources of technology intelligence, and the true value of patent analysis stems from its capability of describing the content of technology based on the relationships between keywords. To date a number of techniques for analyzing the information contained in patent documents that focus on the relationships between keywords have been suggested. However, a drawback of the existing keyword approaches is that they cannot yet determine the types of relationships between the keywords. This study proposes a novel approach based on preposition semantic analysis network which overcomes the limitations of the existing keywords-based network analysis and demonstrates its potential through an application. A preposition is a word that defines the relationship between two neighboring words, and, in the case of patents, prepositions aid in revealing the relationships between keywords related to technologies. To demonstrate the approach, patents regarding an electric vehicle were employed. 13 prepositions were identified which could be used to define 5 relationships between neighboring technological terms: “inclusion (utilization),” “objective (purpose),” “effect,” “process,” and “likeness.” The proposed approach is expected to improve the usability of keyword-based patent analyses and support more elaborate studies on patent documents.},
series={Journal of Informetrics, 12(1), 217-236 (2018)}
}


@INPROCEEDINGS{4746749,
  author={Krapivin, Mikalai and Marchese, Maurizio and Yadrantsau, Andrei and Liang, Yanchun},
  booktitle={2008 Third International Conference on Digital Information Management}, 
  title={Unsupervised key-phrases extraction from scientific papers using domain and linguistic knowledge}, 
  year={2008},
  volume={},
  number={},
  pages={105-112},
  keywords={Data mining,Software libraries,Navigation,Machine learning,Support vector machines,Support vector machine classification,Natural language processing,Robustness,Computer science,Bayesian methods},
  doi={10.1109/ICDIM.2008.4746749},
series={2008 Third International Conference on Digital Information Management}}


@article{chandola2015online,
  title={Online resume parsing system using text analytics},
  author={Chandola, Divyanshu and Garg, Aditya and Maurya, Ankit and Kushwaha, Amit},
  journal={Journal of Multi-Disciplinary Engineering Technologies},
  volume={9},
  year={2015},
url ={http://jmdet.com/wp-content/uploads/2015/08/CR9.pdf},
series={Journal of Multi-Disciplinary Engineering Technologies, 9},
keywords={ Text Analytics, Sentiment Analysis, Natural Language Processing, Text Mining, Lexical Analysis }

}


@article{sadjadi2021two,
  title={A two-level semi-supervised clustering technique for news articles},
  author={Sadjadi, SM and Mashayekhi, H and Hassanpour, H},
  journal={International Journal of Engineering},
  volume={34},
  number={12},
  pages={2648--2657},
  doi = {10.5829/ije.2021.34.12C.10},
  year={2021},
  url = {https://www.ije.ir/article_137466.html},
abstract = {The web and social media are overcrowded with news pieces in terms of amount and diversity. Document clustering is a useful technique that is widely used in organizing and managing data into smaller groups. One of the factors influencing the quality of clustering is the way documents are represented. Some traditional methods of document representation depend on word frequencies and create sparse and large-sized document vectors. These methods cannot preserve proximity information between documents. In addition, neural network-based methods that preserve proximity information suffer from poor interpretability. Conceptual text representation methods have overcome the shortcomings of previous methods, but semi-supervised text clustering does not currently use concept-based document representation. This paper presents a two-level semi-supervised text clustering method that uses labeled and unlabeled data simultaneously to achieve higher clustering quality. In the first level, documents are represented based on the concepts extracted from the raw corpus. Second, the semi-supervised clustering process applies unlabeled data to capture the overall structure of the clusters and a small amount of labeled data to adjust the center of the clusters. Experiments on the Reuters-21578 data collection show that the proposed model is superior to other semi-supervised approaches in both text classification and text clustering.},
keywords = {News Clustering,Two-level clustering,Semi-supervised,word embedding,Document clustering},
  publisher={Materials and Energy Research Center},
series={International Journal of Engineering, 34(12), pp. 2648-2657 (2021)}
}


@INPROCEEDINGS{5587779,
  author={Kumar, Pawan and Kumar Rathaur, Arun and Ahmad, Rashid and Sinha, Mukul K and Sangal, Rajeev},
  booktitle={Proceedings of the 6th International Conference on Natural Language Processing and Knowledge Engineering(NLPKE-2010)}, 
  title={Dashboard: An integration and testing platform based on backboard architecture for NLP applications}, 
  year={2010},
  volume={},
  number={},
  pages={1-8},
  keywords={Strontium;Magnetic resonance imaging;Erbium},
  doi={10.1109/NLPKE.2010.5587779},
series={6th International Conference on Natural Language Processing and Knowledge Engineering (NLPKE-2010)},
}


@inproceedings{manning2014stanford,
  title={The Stanford CoreNLP natural language processing toolkit},
  author={Manning, Christopher D and Surdeanu, Mihai and Bauer, John and Finkel, Jenny Rose and Bethard, Steven and McClosky, David},
  booktitle={Proceedings of 52nd annual meeting of the association for computational linguistics: system demonstrations},
  pages={55--60},
  year={2014},
  doi={10.3115/v1/P14-5010},
url={https://aclanthology.org/P14-5010/},
series={52nd annual meeting of the association for computational linguistics: system demonstrations, pp. 55-60. 2014},
keywords={ Stanford CoreNLP, Natural Language Processing Toolkit, Annotation Pipeline, Design and Development, Core NLP Steps, Usage Patterns }

}


@inproceedings{Tenney2020TheLI,
  title={The Language Interpretability Tool: Extensible, Interactive Visualizations and Analysis for NLP Models},
  author={Ian Tenney and James Wexler and Jasmijn Bastings and Tolga Bolukbasi and Andy Coenen and Sebastian Gehrmann and Ellen Jiang and Mahima Pushkarna and Carey Radebaugh and Emily Reif and Ann Yuan},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:225423556},
  doi={10.48550/arXiv.2008.05122},
series={arXiv preprint arXiv:2008.05122 (2020)},
keywords={ Model Understanding, Visualization Platform, Error Analysis, Local Explanations, Aggregate Analysis, Counterfactual Generation }

}
